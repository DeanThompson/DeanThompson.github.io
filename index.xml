<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>李林克斯 on 李林克斯 </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://liyangliang.me/</link>
    <language>zh-CN</language>
    <author>Yangliang Li</author>
    
    <updated>Sat, 02 Mar 2019 16:40:45 CST</updated>
    
    <item>
      <title> Designing Data-Intensive Applications 读书笔记（1） —— 数据编码</title>
      <link>http://liyangliang.me/posts/2019/03/data-encoding/</link>
      <pubDate>Sat, 02 Mar 2019 16:40:45 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/03/data-encoding/</guid>
      <description>&lt;p&gt;最近一段时间都在读 &lt;em&gt;Designing Data-Intensive Applications&lt;/em&gt; 这本书，中文名叫《数据密集型应用系统设计》。进度比较慢，但感觉很有意思，获益匪浅。在读第四章 &lt;em&gt;Encoding and Evolution&lt;/em&gt; （数据编码与演化）时，脑海里时常浮现出自己的开发经历，颇有共鸣。因此准备结合书本内容和自身体验，总结成文字作为记录。这一篇主要讨论编码。&lt;/p&gt;

&lt;h2 id=&#34;编码和解码&#34;&gt;编码和解码&lt;/h2&gt;

&lt;p&gt;在程序世界里，数据通常有两种不同的表现形式：内存和文件（网络）。在内存中，数据保存在对象、结构体、列表、哈希表等结构中，这些数据结构针对 CPU 的高效访问和操作进行了优化。而把数据写入文件或通过网络发送时，需要将其转换成字节序列。&lt;/p&gt;

&lt;p&gt;从内存中的表示到字节序列的转化称为编码或序列化，反之称为解码或反序列化。&lt;/p&gt;

&lt;h2 id=&#34;编码格式&#34;&gt;编码格式&lt;/h2&gt;

&lt;p&gt;只要程序发生 IO 或其他程序进行数据交换时，就需要进行编解码。每种场景的需求和特点各异，随着时间推移，诞生了很多中编码格式。从通用性的角度来看，可以划分为两大类：语言特定的格式和通用格式。&lt;/p&gt;

&lt;h3 id=&#34;语言特定的格式&#34;&gt;语言特定的格式&lt;/h3&gt;

&lt;p&gt;很多语言都有特定的编码格式，并且以标准库的形式提供编码和解码功能。我使用过的有 Python 的 pickle 和 Go 的 gob. 这些库的主要好处是使用方便，功能强大。以 Python 的 pickle 为例，不仅能处理常见的数据格式，&lt;a href=&#34;https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled&#34;&gt;还能处理函数、类和对象&lt;/a&gt;. 但也存在一些问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;跨语言共享非常困难。语言特定的格式就类似于一种私有加密算法，其他程序（语言）基本上无法理解。2013 年曾做过用 Go 重构一个 Python 应用的项目。项目里用到了 Redis，但是缓存的数据都是用 pickle 序列化的，Go 语言无法解码。当时刚参加工作，经验不足，不知道 pickle 是 Python 特有的，刚开始还找了很久 Go 的解码库（当然没找到）。后来经老大提醒，把缓存全部改成 JSON.&lt;/li&gt;
&lt;li&gt;存在安全隐患。为了在相同的对象类型中恢复数据，解码过程要能实例化任意的类，就有可能执行一些危险的代码。&lt;a href=&#34;https://www.synopsys.com/blogs/software-security/python-pickling/&#34;&gt;Understanding Python pickling and how to use it securely&lt;/a&gt; 用例子讲述了 Python pickle 的安全隐患和一些可行的放缓措施。&lt;/li&gt;
&lt;li&gt;书中还提到了多版本的兼容性和编解码效率问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;通用格式&#34;&gt;通用格式&lt;/h3&gt;

&lt;p&gt;计算机上运行的程序由各种各样的编程语言实现，因此必然需要一些通用和标准格式来支持不同语言之间的数据交换。这些格式可以分为两种：文本格式和二进制格式。&lt;/p&gt;

&lt;h4 id=&#34;文本格式&#34;&gt;文本格式&lt;/h4&gt;

&lt;p&gt;常见的文本格式有 JSON、XML 和 CSV，其中 CSV 可以泛化为分隔符文本文件。这些编码格式应用非常广泛，基本上所有语言都能正确编码和解码。而且可读性良好， 很适合人类阅读理解。&lt;/p&gt;

&lt;p&gt;这些格式解决了跨语言的障碍，但也有一些的问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对数字的处理存在缺陷。XML 和 CSV 无法区分数字和碰巧由数字组成的字符串；JSON 有字符串和数字类型，但不区分整数和浮点数。书里还提到 JavaScript 在处理大于 &lt;code&gt;2**53&lt;/code&gt; 的数字时会有精度丢失的现象，但这只能说时 JavaScript 语言的问题，不是 JSON 的不足（JSON 只是一种文本格式）。不过我确实在实际工作中被这个问题坑过一次：从 TiDB 同步数据到 ElasticSearch，在 Kibana 查看时总是会有些 BIGINT (int64) 类型的数据和 TiDB 对应不上（ElasticSearch 存储的是对的）。查明原因后，为了方便查看，不得不把类型转换成字符串再重新同步。&lt;/li&gt;
&lt;li&gt;不支持二进制数据。用 Python 开发了一个异构数据源的数据同步系统（项目代号为 pigeon），为了方便扩展和解耦，把同步过程拆成了 dump 和 load 两个步骤，用 CSV 文件作为数据交换格式。在大部分情况下这种设计能很好的工作，但最大的缺陷就是不支持二进制数据。各种数据库系统都有二进制类型，而且也非常有用（存储图片、压缩或加密的数据等）。一种可行的方案是用 base64 把二进制字符串编码成文本字符串，但会带来 33% 的数据膨胀。&lt;/li&gt;
&lt;li&gt;XML 和 JSON 的每条记录都要保存元素标记、字段名等信息，导致大量冗余。CSV 相对来说更加紧凑，最多用第一行保存每一列的字段名称。但不管是否有冗余，相对二进制格式而言，都会占用大量磁盘空间，当数据量大时，就要使用压缩算法进行压缩保存。&lt;/li&gt;
&lt;li&gt;CSV 没有模式，其实就是一种分隔符文件，当数据内部存在分隔符就可能会带来麻烦。虽然可以使用转义字符和 quoting，但并不是所有解析器都能正确解析。使用 pigeon 的时候就发现，MySQL 对 CSV 的容错性似乎不如 Python 的标准库 &lt;code&gt;csv&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;用 Python 写入 CSV 时，会把 &lt;code&gt;None&lt;/code&gt; 编码成空字符串，从而导致解码时无法区分。因此在 pigeon 里大部分场景下会把 &lt;code&gt;None&lt;/code&gt; 编码为 &lt;code&gt;NULL&lt;/code&gt; 或 &lt;code&gt;\N&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;尽管存在这些或那些缺陷，JSON、XML 和 CSV 的应用非常广泛，编解码工具也很成熟丰富。在 Web 开发领域，传统的 Web Service 大量使用 XML，随着 Web 技术的发展和， JSON 变得越来越流行. 在数据库和数据分析领域，则经常使用 CSV 来作为数据交换格式，基本上常见的数据库都原生支持导入 CSV 文件（这也是 pigeon 选择 CSV 的重要原因之一）。&lt;/p&gt;

&lt;h4 id=&#34;二进制格式&#34;&gt;二进制格式&lt;/h4&gt;

&lt;h5 id=&#34;json-和-xml-的二进制变体&#34;&gt;JSON 和 XML 的二进制变体&lt;/h5&gt;

&lt;p&gt;因为以上原因，也催生了很多这些文本格式的二进制变体。如 JSON 系的 MessagePack、BSON、BJSON、UBJSON、BISON，XML 系的 WBXML 和 Fast Infoset. 这些格式被很多细分领域所采用，但都没有 JSON 和 XML 那样广泛。&lt;/p&gt;

&lt;p&gt;MessagePack（和其他同类二进制编码）对空间缩减有限（书中的例子是 81 字节到 66 字节），而且牺牲了可读性，作者似乎认为这并不值得。不过另一个好处是，一般二进制的解析速度会更快，还有一些格式扩展了数据类型，比如可以区分整数和浮点数，或者增加了对二进制字符串的支持。&lt;/p&gt;

&lt;h5 id=&#34;thrift-和-protocol-buffers&#34;&gt;Thrift 和 Protocol Buffers&lt;/h5&gt;

&lt;p&gt;&lt;a href=&#34;https://thrift.apache.org/&#34;&gt;Apache Thrift&lt;/a&gt; 和 &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt; 分别诞生自 Facebook 和 Google，都在 2007~2008 期间贡献到开源社区。两种格式都需要定义 schema (IDL, Interface definition language)，而且都有对应的代码生成工具，可以自动生成多种语言的解析代码。&lt;/p&gt;

&lt;p&gt;Thrift 和 Protocol Buffers 类似，每个字段用标签（tag, 数字 1, 2, 3&amp;hellip;）表示，所以更加紧凑，可以节省大量空间。由于编码不会引用字段名，所以只要保证标签不变， schema 里的字段名可以随意更改（JSON 和 XML 不行）。此外每个字段都有明确的数据类型，还有 &lt;code&gt;optional&lt;/code&gt; 和 &lt;code&gt;required&lt;/code&gt; 约束，可以用于数据合法性校验。&lt;/p&gt;

&lt;p&gt;Thrift 有 BinaryProtocol 和 CompactProtocol 两种编码格式，书中的例子生成的二进制序列分别是 59 字节和 34 字节。Protocol Buffers 的结果是 33 字节。&lt;/p&gt;

&lt;p&gt;因为这些编码格式更紧凑、高效，能自动生成客户端和服务端代码，往往用于实现高性能的 RPC 服务。其实 Thrift 本身就是一个 RPC 框架，Hadoop 生态里的组件就大量使用 Thrift. Protocol Buffers 没有实现 RPC 框架，但 Google 基于此开发了 &lt;a href=&#34;https://grpc.io/&#34;&gt;gRPC&lt;/a&gt;，应用也十分广泛，比如 TiDB 组件的内部通信就用了 gRPC.&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;跟其他技术（比如数据库）一样，每种格式都有各自的优点和缺陷，抛开使用场景单纯讨论优劣是没有意义的。下表是结合书中内容和自己的理解，从几个维度定性的比较了这些格式的特点。不一定对，仅供参考。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;编码格式&lt;/th&gt;
&lt;th&gt;可读性&lt;/th&gt;
&lt;th&gt;schema&lt;/th&gt;
&lt;th&gt;性能&lt;/th&gt;
&lt;th&gt;空间&lt;/th&gt;
&lt;th&gt;代码生成&lt;/th&gt;
&lt;th&gt;复杂度&lt;/th&gt;
&lt;th&gt;适用场景举例&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;JSON&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;td&gt;有，复杂&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;大&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;很低&lt;/td&gt;
&lt;td&gt;Web&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;XML&lt;/td&gt;
&lt;td&gt;较好&lt;/td&gt;
&lt;td&gt;有，复杂&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;很大&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;配置, UI, SOAP&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CSV&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;关系型数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;MessagePack&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;较高&lt;/td&gt;
&lt;td&gt;较小&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;Web&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Thrift&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;很高&lt;/td&gt;
&lt;td&gt;很小&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;RPC&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Protocol Buffers&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;很高&lt;/td&gt;
&lt;td&gt;很小&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;RPC&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>放假</title>
      <link>http://liyangliang.me/posts/2019/01/2018-holiday/</link>
      <pubDate>Wed, 30 Jan 2019 23:24:51 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/01/2018-holiday/</guid>
      <description>&lt;p&gt;原本准备 6 点下班，离开公司已经超过 8 点了；约好的篮球活动没有去成。&lt;/p&gt;

&lt;p&gt;下班路上吃了个羊肉粉，回到家里胃有点不舒服。&lt;/p&gt;

&lt;p&gt;躺在沙发上看了一下手机，阳台上有风吹进，慢慢有些凉意。&lt;/p&gt;

&lt;p&gt;放下手机起身收拾行李，假期已经开始，我并没有因此感到兴奋.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python 日期和时间处理</title>
      <link>http://liyangliang.me/posts/2018/06/python-date-time/</link>
      <pubDate>Sat, 02 Jun 2018 16:03:26 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/06/python-date-time/</guid>
      <description>

&lt;p&gt;2012 年大四的时候写过一篇 &lt;a href=&#34;http://liyangliang.me/posts/2012/10/python-timestamp-to-timestr&#34;&gt;Python 时间戳和日期相互转换&lt;/a&gt;，当时是初学 Python，对标准库也理解不深；随便找到一种解决方案就记录下来并发到博客上了。现在回看起来，其实太过繁琐了。然而从 Google Analytics 后台看，这竟然是点击率第二的文章，着实让我感到诧异。本着对读者负责的态度，有必要结合这些年的开发经验，再写一篇日期和时间处理的博客。&lt;/p&gt;

&lt;p&gt;首先再次回答「Python 时间戳和日期相互转换」的问题。&lt;/p&gt;

&lt;h2 id=&#34;时间戳转日期&#34;&gt;时间戳转日期&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime
import time

t = time.time()
print(&#39;Timestamp&#39;, t)

dt = datetime.datetime.fromtimestamp(t)
print(&#39;Datetime&#39;, dt)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Timestamp 1527927420.684622
Datetime 2018-06-02 16:17:00.684622
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;日期转时间戳&#34;&gt;日期转时间戳&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime

now = datetime.datetime.now()
print(&#39;Datetime&#39;, now)
print(&#39;Timestamp&#39;, now.timestamp())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Datetime 2018-06-02 16:18:42.170874
Timestamp 1527927522.170874
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>CentOS 7 FirewallD</title>
      <link>http://liyangliang.me/posts/2018/06/centos7-firewalld/</link>
      <pubDate>Sat, 02 Jun 2018 15:11:15 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/06/centos7-firewalld/</guid>
      <description>&lt;h2 id=&#34;背景故事&#34;&gt;背景故事&lt;/h2&gt;

&lt;p&gt;线上服务器一直没有开启防火墙，没有约束用起来倒也省事。部署 Hadoop 集群（CDH 发行版）的时候，所有网上看过的教程和笔记（包括 CDH 官方文档），全部都提到了部署过程中要关闭防火墙；极少数教程会提到如果有需要，可以在部署完成后再开启；然而没有任何教程在最后真正开启了防火墙。&lt;/p&gt;

&lt;p&gt;因为没有防火墙，其实也发生过几次安全事故：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;某天某台服务器 CPU 利用率很高，后来发现是因为被人利用 rundeck 的漏洞植入了一个挖矿程序；&lt;/li&gt;
&lt;li&gt;某天有个跑在 Docker 里的 Redis 出现故障，经查也是被植入了挖矿程序&lt;/li&gt;
&lt;li&gt;某天发现有台机器上有个废弃的 MySQL 跑在公网上，日志里面几乎全是尝试登录的记录&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这几次事故虽然没有导致财产损失，但是公网太可怕，没有防火墙就是在外面裸奔，随时可能受到攻击。Hadoop 集群所有服务都是绑定到 &lt;code&gt;0.0.0.0&lt;/code&gt;，加上没有开启认证，很容易被拖库。&lt;/p&gt;

&lt;h2 id=&#34;firewalld&#34;&gt;FirewallD&lt;/h2&gt;

&lt;p&gt;最先想到的是用 iptables，之前也有使用经历，然而这玩意儿实在太复杂，概念、规则太多，一直没弄懂。CentOS 7 默认安装了 &lt;a href=&#34;http://www.firewalld.org/&#34;&gt;FirewallD&lt;/a&gt;，使用起来非常方便，也很好理解。网上的介绍和教程很多，不赘述。直接介绍我的使用策略。&lt;/p&gt;

&lt;p&gt;FirewallD 有很多种 zone policy，直接使用默认的 &lt;code&gt;public&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;首先内网之间必须能相互访问，否则各种集群的节点之间无法通信，会导致集群无法使用。我们有两套内网环境，一个是机房服务器之间，IP 网段是 &lt;code&gt;172.16.24.0/24&lt;/code&gt;；另一个是本地和服务器之间，通过 openvpn 连接，有两个 IP 段 &lt;code&gt;10.8.0.0/24&lt;/code&gt; 和 &lt;code&gt;10.8.1.0/24&lt;/code&gt;. 参考 &lt;a href=&#34;http://xuxping.com/2017/04/04/hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/&#34;&gt;这篇文章&lt;/a&gt;进行配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=172.16.24.0/24 accept&#39;
sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=10.8.0.0/24 accept&#39;
sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=10.8.1.0/24 accept&#39;
sudo firewall-cmd  --reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其次常用服务、端口也需要开启：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --permanent --add-service=openvpn

sudo firewall-cmd --permanent --add-port=5000
sudo firewall-cmd --permanent --add-port=8080
sudo firewall-cmd --permanent --add-port=8088
sudo firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置完成之后可以查看 &lt;code&gt;/etc/firewalld/zones/public.xml&lt;/code&gt; 文件进一步确认开启的 service、source 和 port. 挑个端口用 &lt;code&gt;telnet&lt;/code&gt; 测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; telnet &amp;lt;public-ip&amp;gt; 21050

Trying &amp;lt;public-ip&amp;gt;...
telnet: connect to address &amp;lt;public-ip&amp;gt;: Connection refused
telnet: Unable to connect to remote host

&amp;gt; telnet 172.16.24.123 21050

Trying 172.16.24.123...
Connected to 172.16.24.123.
Escape character is &#39;^]&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;firewalld-docker&#34;&gt;FirewallD &amp;amp; Docker&lt;/h2&gt;

&lt;p&gt;如果先运行 &lt;code&gt;dockerd&lt;/code&gt; 再运行 &lt;code&gt;firewalld&lt;/code&gt;, 会导致 Docker 无法正常工作，用 Docker 部署的程序无法访问了。这个问题在网上有很多讨论，Docker 的 GitHub 主页就有&lt;a href=&#34;https://github.com/moby/moby/issues/16137&#34;&gt;一个 issue&lt;/a&gt;.
我是这么解决的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --zone=trusted --change-interface=docker0
sudo firewall-cmd --reload
sudo service docker restard
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是把 &lt;code&gt;docker0&lt;/code&gt; 网卡添加到 &lt;code&gt;trusted&lt;/code&gt; zone，再重启 &lt;code&gt;dockerd&lt;/code&gt;. 操作完成后 Docker 服务恢复正常，但是 &lt;code&gt;firewalld&lt;/code&gt; 进程却意外退出了，大量这种日志：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -n -L DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -n -L DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -n -L DOCKER-ISOLATION&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C DOCKER-ISOLATION -j RETURN&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C POSTROUTING -m addrtype --src-type LOCAL -o docker0 -j MASQUERADE&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -D FORWARD -i docker0 -o docker0 -j DROP&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -i docker0 -o docker0 -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -i docker0 ! -o docker0 -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C PREROUTING -m addrtype --dst-type LOCAL -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C OUTPUT -m addrtype --dst-type LOCAL -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -o docker0 -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -j DOCKER-ISOLATION&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -D FORWARD -i docker0 -o docker0 -j DROP&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参照 &lt;a href=&#34;https://github.com/moby/moby/issues/16137#issuecomment-271615192&#34;&gt;这个&lt;/a&gt; 和 &lt;a href=&#34;https://stackoverflow.com/questions/33600154/docker-not-starting-could-not-delete-the-default-bridge-network-network-bridg/33604859#33604859&#34;&gt;这个&lt;/a&gt; 做法均无法消除这种错误日志，但是配置的防火墙规则都生效了。&lt;/p&gt;

&lt;h2 id=&#34;ansible-role&#34;&gt;Ansible Role&lt;/h2&gt;

&lt;p&gt;把以上配置写成 Ansible 任务进行自动化：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;---

- name: stop iptables and disable iptables on boot
  service: name=iptables state=stopped enabled=no
  ignore_errors: true

- name: ensure firewalld installed
  yum: name=firewalld state=present

- name: enable firewalld
  service: name=firewalld state=started enabled=yes

- name: set public as default zone policy
  command: firewall-cmd --set-default-zone=public

- name: ensure private network is not blocked
  firewalld:
    rich_rule: &#39;rule family=ipv4 source address={{ item }} accept&#39;
    permanent: true
    state: enabled
  with_items:
      - 172.16.24.0/24
      - 10.8.0.0/24
      - 10.8.1.0/24

- name: enable common services
  firewalld:
    service: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - http
    - https
    - ssh
    - ntp
    - openvpn

- name: enable ports
  firewalld:
    port: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - 58890/tcp
    - 58880/tcp
    - 5000/tcp
    - 8080/tcp
    - 8088/tcp
    - 8888/tcp

- name: enable docker interface
  firewalld:
    zone: trusted
    interface: docker0
    permanent: true
    state: enabled

- name: enable docker ports
  firewalld:
    port: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - 4243/tcp

# 有些机器可能没有运行 dockerd，简单的通过 ignore_errors 来跳过
- name: restart docker daemon
  service: name=docker state=restarted
  ignore_errors: true

- name: reload firewalld
  service: name=firewalld state=reloaded

# 有时候会出现 firewalld 进程意外退出的情况，具体原因待查
- name: enable firewalld
  service: name=firewalld state=started enabled=yes
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.firewalld.org/&#34;&gt;FirewallD 官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-firewalld-on-centos-7&#34;&gt;DigitalOcean: How To Set Up a Firewall Using FirewallD on CentOS 7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linode.com/docs/security/firewalls/introduction-to-firewalld-on-centos/&#34;&gt;Linode: Introduction to FirewallD on CentOS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/moby/moby/issues/16137&#34;&gt;GitHub: Docker vs. firewalld on CentOS 7 #16137&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/modules/firewalld_module.html&#34;&gt;Ansible firewalld&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Redshift Snippets</title>
      <link>http://liyangliang.me/posts/2018/02/redshift-snippets/</link>
      <pubDate>Sun, 04 Feb 2018 19:36:03 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/02/redshift-snippets/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;查询所有 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM stv_sessions;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;终止 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT pg_terminate_backend(32281);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即，调用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 函数，传入 process_id。&lt;/p&gt;

&lt;p&gt;权限：普通用户只能终止自己的 session，超级用户能终止任意 session.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查询正在运行的 queries&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类似 MySQL 的 &lt;code&gt;SHOW PROCESSLIST&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT stv_recents.userid, stv_recents.status, stv_recents.starttime,
       stv_recents.duration, stv_recents.user_name, stv_recents.db_name,
       stv_recents.query, stv_recents.pid
FROM stv_recents
WHERE stv_recents.status = &#39;Running&#39;::bpchar;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;创建数据库时报错：&lt;code&gt;source database &amp;quot;template1&amp;quot; is being accessed by other users&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：&lt;code&gt;template1&lt;/code&gt; 数据库被其他 session 占用，锁住了。&lt;/p&gt;

&lt;p&gt;解决方法：先从 &lt;code&gt;stv_sessions&lt;/code&gt; 表查找 &lt;code&gt;template1&lt;/code&gt; 相关的 session，然后用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 杀掉。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;备份数据到 S3&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UNLOAD (&#39;SELECT * FROM public.category&#39;) TO &#39;s3://redshift-backup/unload/public/category/category_&#39;
access_key_id &#39;&amp;lt;access_key_id&amp;gt;&#39; secret_access_key &#39;&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; ADDQUOTES ESCAPE ALLOWOVERWRITE;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;从 S3 加载数据&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY public.category FROM &#39;s3://redshift-backup/unload/public/category&#39;
CREDENTIALS &#39;aws_access_key_id=&amp;lt;access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; REMOVEQUOTES ESCAPE REGION &#39;cn-north-1&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;定义 Python UDF&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文档: &lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE FUNCTION f_hash(value varchar) returns varchar immutable as $$
    def sha256_hash(value):
        import hashlib, base64
        return base64.urlsafe_b64encode(hashlib.sha256(value or &#39;&#39;).digest())
    return sha256_hash(value)
$$ language plpythonu;

SELECT address, mobile_no, f_hash(address), f_hash(mobile_no)
FROM leqi_orders LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;查看表所占磁盘等信息&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT BTRIM(pgdb.datname::character varying::text) AS &amp;quot;database&amp;quot;,
       BTRIM(a.name::character varying::text) AS &amp;quot;table&amp;quot;,
       (b.mbytes::numeric::numeric(18,0) / part.total::numeric::numeric(18,0) * 100::numeric::numeric(18,0))::numeric(5,2) AS pct_of_total,
       a.&amp;quot;rows&amp;quot;,
       b.mbytes,
       b.unsorted_mbytes
FROM stv_tbl_perm a
  JOIN pg_database pgdb ON pgdb.oid = a.db_id::oid
  JOIN (
    SELECT stv_blocklist.tbl,
           SUM(
             CASE
               WHEN stv_blocklist.unsorted = 1 OR stv_blocklist.unsorted IS NULL AND 1 IS NULL THEN 1
               ELSE 0
             END
           ) AS unsorted_mbytes,
           COUNT(*) AS mbytes
    FROM stv_blocklist
    GROUP BY stv_blocklist.tbl
  ) b ON a.id = b.tbl
  JOIN (
    SELECT SUM(stv_partitions.capacity) AS total
    FROM stv_partitions
    WHERE stv_partitions.part_begin = 0
  ) part ON 1 = 1
WHERE a.slice = 0
ORDER BY b.mbytes DESC, a.db_id, a.name;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查询结果样例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;database  table pct_of_total  rows  mbytes  unsorted_mbytes
roma	mda_price_idx	0	50005	10	10
roma	mda_vendor	0	4	10	10
roma	mda_vendor	0	8	10	7
roma	sku_bodytype	0	9	10	7
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Pyenv 使用笔记</title>
      <link>http://liyangliang.me/posts/2017/06/pyenv-notes/</link>
      <pubDate>Tue, 20 Jun 2017 15:09:27 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/06/pyenv-notes/</guid>
      <description>&lt;p&gt;应用使用虚拟环境是每个 Python 程序员都应该要掌握的技能。
&lt;a href=&#34;https://github.com/pyenv/pyenv&#34;&gt;pyenv&lt;/a&gt; 是一个非常好用的 Python 环境管理工具。有这些主要特性：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;方便的安装、管理不同版本的 Python，而且不需要 sudo 权限，不会污染系统的 Python 版本&lt;/li&gt;
&lt;li&gt;可以修改当前用户使用的默认 Python 版本&lt;/li&gt;
&lt;li&gt;集成 virtualenv，自动安装、激活&lt;/li&gt;
&lt;li&gt;命令行自动补全&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;详细内容见 &lt;a href=&#34;https://github.com/pyenv/pyenv&#34;&gt;Github - pyenv/pyenv&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;安装-pyenv&#34;&gt;安装 pyenv&lt;/h2&gt;

&lt;p&gt;最简单的方式是使用 &lt;a href=&#34;https://github.com/pyenv/pyenv-installer&#34;&gt;pyenv-installer&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在 &lt;code&gt;~/.bashrc&lt;/code&gt; 或 &lt;code&gt;~/.zshrc&lt;/code&gt; 中添加如下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=&amp;quot;~/.pyenv/bin:$PATH&amp;quot;
eval &amp;quot;$(pyenv init -)&amp;quot;
eval &amp;quot;$(pyenv virtualenv-init -)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;常用命令&#34;&gt;常用命令&lt;/h2&gt;

&lt;p&gt;完整的命令行列表可以参考 &lt;a href=&#34;https://github.com/pyenv/pyenv/blob/master/COMMANDS.md&#34;&gt;pyenv/COMMANDS.md&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;安装 Python&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv install 3.6.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会为当前用户下载和安装 3.6.0，安装过程可以使用镜像加速，详见下文。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新建虚拟环境&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv virtualenv 3.6.0 py36
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;设置当前路径使用的 Python 环境&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv local py36
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会在当前路径创建一个 &lt;code&gt;.python-version&lt;/code&gt; 文件，文件内容就是 &lt;code&gt;py36&lt;/code&gt;，即环境名称。所以一般需要把 &lt;code&gt;.python-version&lt;/code&gt; 添加到 gitignore.&lt;/p&gt;

&lt;p&gt;下次进入该目录时，会自动激活虚拟环境；离开后自动退出。&lt;/p&gt;

&lt;h2 id=&#34;搭建镜像&#34;&gt;搭建镜像&lt;/h2&gt;

&lt;p&gt;pyenv 默认从 Python 官网下载安装包，比较慢；也支持镜像网站，可以自己搭建。&lt;/p&gt;

&lt;h3 id=&#34;搭建镜像-1&#34;&gt;搭建镜像&lt;/h3&gt;

&lt;p&gt;其实就是把安装包下载好，放到服务器上，用 Nginx 搭建一个下载服务。但安装包的文件名必须是文件的 SHA256 值。
如 Python-3.6.0.tar.xz 安装包应该保存为 b0c5f904f685e32d9232f7bdcbece9819a892929063b6e385414ad2dd6a23622&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建目录 &lt;code&gt;/data/pythons&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;下载安装包，从 &lt;a href=&#34;http://mirrors.sohu.com/python/&#34;&gt;搜狐的开源镜像&lt;/a&gt; 下载 &lt;code&gt;.tar.xz&lt;/code&gt; 格式的安装包。&lt;/li&gt;
&lt;li&gt;计算 SHA256（可以使用 &lt;code&gt;sha256sum&lt;/code&gt; 命令），重命名文件&lt;/li&gt;
&lt;li&gt;配置 Nginx&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
    listen 8000;
    root /data/pythons;
    autoindex on;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果没有或不想使用 Nginx，也可以用 Python 运行一个简易的 HTTP 服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python3 -m http.server
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用镜像&#34;&gt;使用镜像&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;export PYTHON_BUILD_MIRROR_URL=http://localhost:8000
pyenv install 3.6.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以把 &lt;code&gt;export PYTHON_BUILD_MIRROR_URL=http://localhost:8000&lt;/code&gt; 添加到 &lt;code&gt;~/.bashrc&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;安装其他版本时，pyenv 会回退到从官网下载。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Centos 7 安装配置 Rundeck</title>
      <link>http://liyangliang.me/posts/2017/06/centos7-install-rundeck/</link>
      <pubDate>Tue, 20 Jun 2017 14:59:27 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/06/centos7-install-rundeck/</guid>
      <description>&lt;h2 id=&#34;通过-yum-安装&#34;&gt;通过 yum 安装：&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install java-1.8.0
$ sudo rpm -Uvh http://repo.rundeck.org/latest.rpm
$ sudo yum install rundeck
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果已经安装了 Java，第一步可以略过。安装过程中有几个步骤需要确认，一路同意（输入 y）即可。&lt;/p&gt;

&lt;p&gt;安装完成后可以立即运行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service rundeckd start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但生产环境还是要修改一些默认配置。上面的安装过程会添加一个名为 rundeck 的用户和组。配置文件位于 &lt;code&gt;/etc/rundeck&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo su - rundeck
$ cd /etc/rundeck/
$ ll
-rw-r-----. 1 rundeck rundeck  738 Apr 20 07:47 admin.aclpolicy
-rw-r-----. 1 rundeck rundeck 1104 Apr 20 07:47 apitoken.aclpolicy
-rw-r-----. 1 rundeck rundeck  511 Apr 20 07:47 cli-log4j.properties
-rw-r-----. 1 rundeck rundeck 1438 Jun 19 16:52 framework.properties
-rw-r-----. 1 rundeck rundeck  136 Apr 20 07:47 jaas-loginmodule.conf
-rw-r-----. 1 rundeck rundeck 7538 Apr 20 07:47 log4j.properties
-rw-r-----. 1 rundeck rundeck 2889 Apr 20 07:47 profile
-rw-r-----. 1 rundeck rundeck  549 Apr 20 07:47 project.properties
-rw-r-----. 1 rundeck rundeck 1065 Jun 20 11:54 realm.properties
-rw-r-----. 1 rundeck rundeck  579 Jun 20 11:56 rundeck-config.properties
drwxr-x---. 2 rundeck rundeck   27 Jun 19 16:52 ssl
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;修改-admin-用户密码&#34;&gt;修改 admin 用户密码&lt;/h2&gt;

&lt;p&gt;用户信息在 &lt;code&gt;realm.properities&lt;/code&gt; 文件，默认有一个 admin 用户，密码也是 admin. 配置格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;username&amp;gt;: &amp;lt;password&amp;gt;[,&amp;lt;rolename&amp;gt; ...]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;默认的配置是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin:admin,user,admin,architect,deploy,build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改密码，并使用 MD5 替换明文密码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ java -cp /var/lib/rundeck/bootstrap/jetty-all-9.0.7.v20131107.jar org.eclipse.jetty.util.security.Password admin Abcd1234
Abcd1234
OBF:1cb01ini1ink1inm1iks1iku1ikw1caa
MD5:325a2cc052914ceeb8c19016c091d2ac
CRYPT:adMpLenKdpR12
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令会生成几种算法加密后的密码，添加到 &lt;code&gt;realm.properities&lt;/code&gt; 文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin:MD5:325a2cc052914ceeb8c19016c091d2ac,user,admin,architect,deploy,build
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;配置使用-mysql-数据库&#34;&gt;配置使用 MySQL 数据库&lt;/h2&gt;

&lt;p&gt;首先得要有个 MySQL 实例，安装过程不赘述。&lt;/p&gt;

&lt;p&gt;配置过程详见 &lt;a href=&#34;http://rundeck.org/docs/administration/setting-up-an-rdb-datasource.html&#34;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建 rundeck 用户和数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ mysql -u root -p

mysql&amp;gt; create database rundeck;
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; grant ALL on rundeck.* to &#39;rundeckuser&#39;@&#39;localhost&#39; identified by &#39;rundeckpassword&#39;;
Query OK, 1 row affected (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后可以使用 &lt;code&gt;rundeckuser&lt;/code&gt; 登录，测试是否能正常连接。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;修改 Rundeck 配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编辑 &lt;code&gt;rundeck-config.properties&lt;/code&gt; 文件，修改后的内容如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#dataSource.url = jdbc:h2:file:/var/lib/rundeck/data/rundeckdb;MVCC=true
dataSource.url = jdbc:mysql://localhost/rundeck?autoReconnect=true
dataSource.username = rundeckuser
dataSource.password = rundeckpassword
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;修改-grails-serverurl&#34;&gt;修改 &lt;code&gt;grails.serverURL&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service rundeckd start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行 Rundeck 服务，打开 &lt;a href=&#34;http://your-server-host:4440/&#34;&gt;http://your-server-host:4440/&lt;/a&gt; 并用 admin 用户登录。登录成功后，被跳转到了 &lt;a href=&#34;http://localhost:4440/menu/home&#34;&gt;http://localhost:4440/menu/home&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;编辑 &lt;code&gt;rundeck-config.properties&lt;/code&gt; 文件，把 &lt;code&gt;grails.serverURL&lt;/code&gt; 改成正确的地址即可。&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/manual/index.html&#34;&gt;User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/administration/index.html&#34;&gt;Administrator Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/api/index.html&#34;&gt;API Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Flask 应用国际化</title>
      <link>http://liyangliang.me/posts/2017/05/flask-i18n/</link>
      <pubDate>Wed, 10 May 2017 17:48:17 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/flask-i18n/</guid>
      <description>&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Babel is an integrated collection of utilities that assist in internationalizing and localizing Python applications, with an emphasis on web-based applications.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;文档：&lt;a href=&#34;http://babel.pocoo.org/en/latest/&#34;&gt;http://babel.pocoo.org/en/latest/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码：&lt;a href=&#34;https://github.com/python-babel/babel&#34;&gt;https://github.com/python-babel/babel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;flask-babel&#34;&gt;Flask-Babel&lt;/h2&gt;

&lt;p&gt;Flask 的 i18n 扩展，集成 babel、pytz 等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文档：&lt;a href=&#34;https://pythonhosted.org/Flask-Babel/&#34;&gt;https://pythonhosted.org/Flask-Babel/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码：&lt;a href=&#34;https://github.com/python-babel/flask-babel&#34;&gt;https://github.com/python-babel/flask-babel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装：&lt;code&gt;pip install Flask-Babel&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;babel 配置文件：babel.cfg&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[python: **.py]
[jinja2: **.html]
extensions=jinja2.ext.autoescape,jinja2.ext.with_,webassets.ext.jinja2.AssetsExtension
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Flask-Babel 配置：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;BABEL_DEFAULT_LOCALE = &#39;zh_CN’                  # locale 选项，默认 &#39;en&#39;
BABEL_DEFAULT_TIMEZONE = &#39;Asia/Shanghai&#39;        # 时区，默认 &#39;UTC&#39;
BABEL_TRANSLATION_DIRECTORIES = &#39;translations&#39;  # 翻译文件所在目录，默认 &#39;translations&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;生成翻译文件模版：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -o messages.pot .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果使用了 &lt;code&gt;lazy_gettext()&lt;/code&gt; 这样的函数，需要在上面的命令行参数指定：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -k lazy_gettext -o messages.pot .
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;生成翻译文件:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel init -i messages.pot -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;编辑 translations/zh_CN/LC_MESSAGES/messages.po 文件，手动翻译。po 文件内容形如：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#: forms.py:65 forms.py:78
#: templates/flask_user/emails/invite_child_user_message.html:9
msgid &amp;quot;Username&amp;quot;
msgstr &amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中：
  - &lt;code&gt;#:&lt;/code&gt; 注释内容是 ‘文件名:行号’，即所有出现过的地方
  - &lt;code&gt;msgid&lt;/code&gt; 是需要翻译的内容
  - &lt;code&gt;msgstr&lt;/code&gt; 是翻译后的内容，如果留空，则会显示原文，即 msgid&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更新翻译文件（一般只需要 init 一次）：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel update -i messages.pot -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;编译&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel compile -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;工作流&#34;&gt;工作流&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -o messages.pot .
$ pybabel init -i messages.pot -d translations     # 第一次
$ pybabel update -i messages.pot -d translations   # 更新
# 手动翻译
$ pybabel compile -d translations
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>EC2 挂载 EBS</title>
      <link>http://liyangliang.me/posts/2017/05/mount-ebs-to-ec2/</link>
      <pubDate>Wed, 10 May 2017 17:41:54 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/mount-ebs-to-ec2/</guid>
      <description>&lt;p&gt;创建 EC2 实例的时候可以选择添加 EBS 卷，在实例运行后，需要手动挂载上去。&lt;/p&gt;

&lt;p&gt;详情见 &lt;a href=&#34;http://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ebs-using-volumes.html&#34;&gt;EBS 的文档&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;用-lsblk-命令查看所有可用的磁盘及其安装点&#34;&gt;用 &lt;code&gt;lsblk&lt;/code&gt; 命令查看所有可用的磁盘及其安装点&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
`-xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  30G  0 disk
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;xvda1&lt;/code&gt; 是根设备，挂载到了 &lt;code&gt;/&lt;/code&gt;；&lt;code&gt;xvdb&lt;/code&gt; 是刚才添加的 EBS 卷，还没有挂载。&lt;/p&gt;

&lt;h2 id=&#34;确定是否需要在卷上创建文件系统&#34;&gt;确定是否需要在卷上创建文件系统。&lt;/h2&gt;

&lt;p&gt;如果是新的 EBS，是一个原始的块存储设备，需要先创建文件系统才能安装使用。从快照还原的卷可能已经含有文件系统。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo file -s /dev/xvdb
/dev/xvdb: data

$ sudo file -s /dev/xvda1
/dev/xvda1: Linux rev 1.0 ext4 filesystem data, UUID=9fbb7c51-0409-4b50-ad40-068dcfe4bc89, volume name &amp;quot;cloudimg-rootfs&amp;quot; (needs journal recovery) (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到 &lt;code&gt;/dev/xvdb&lt;/code&gt; 上面还没有文件系统，需要手动创建:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkfs -t ext4 /dev/xvdb
mke2fs 1.42.13 (17-May-2015)
Creating filesystem with 7864320 4k blocks and 1966080 inodes
Filesystem UUID: 2a0dae23-7b6e-42ec-95e1-df58f29520a4
Superblock backups stored on blocks:
     32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
     4096000

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

$ sudo file -s /dev/xvdb
/dev/xvdb: Linux rev 1.0 ext4 filesystem data, UUID=2a0dae23-7b6e-42ec-95e1-df58f29520a4 (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意：&lt;code&gt;mkfs&lt;/code&gt; 会格式化卷，删除所有数据。&lt;/p&gt;

&lt;h2 id=&#34;创建安装点-也就是要挂载的位置&#34;&gt;创建安装点，也就是要挂载的位置:&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir /data
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;挂载&#34;&gt;挂载&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sudo mount /dev/xvdb /data/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;用-df-命令磁盘空间&#34;&gt;用 &lt;code&gt;df&lt;/code&gt; 命令磁盘空间&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            489M     0  489M   0% /dev
tmpfs           100M  3.1M   97M   4% /run
/dev/xvda1      7.8G  1.9G  5.5G  26% /
tmpfs           496M     0  496M   0% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           496M     0  496M   0% /sys/fs/cgroup
tmpfs           100M     0  100M   0% /run/user/1000
/dev/xvdb        30G   44M   28G   1% /data
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>MySQL 数据导入到 Redshift</title>
      <link>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift/</link>
      <pubDate>Wed, 10 May 2017 17:36:29 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift/</guid>
      <description>&lt;h2 id=&#34;设计表&#34;&gt;设计表&lt;/h2&gt;

&lt;p&gt;首先是设计表结构。建表语法差别不大，有一些地方可以注意一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Redshift 貌似没有无符号类型，所以要把 unsigned 类型的字段修改成相应的 INT 或 BIGINT 类型。&lt;/li&gt;
&lt;li&gt;FLOAT 类型改成 REAL 或 FLOAT4&lt;/li&gt;
&lt;li&gt;把索引语句去掉，保留主键、外键、唯一性约束，Redshift 不会检查这些约束，但是查询时会用于优化。&lt;/li&gt;
&lt;li&gt;Redshift 的 CHAR 类型只能包含单字节 ASCII 字符，对于非 ASCII 数据需要把 CHAR 改成 VARCHAR 类型&lt;/li&gt;
&lt;li&gt;有可能 MySQL 中存的是 unicode，而 Redshift 中存的是 bytes，所以 VARCHAR 的长度也要调整，避免溢出。最简单的，可以用 MySQL 的字段长度 * 3.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于 sort key, dist key 等设计，只属于 Redshift 范畴，参考官网文档即可。&lt;/p&gt;

&lt;h2 id=&#34;加载数据&#34;&gt;加载数据&lt;/h2&gt;

&lt;p&gt;因为 Redshift 推荐使用 &lt;code&gt;COPY&lt;/code&gt; 命令从 S3 加载数据，所以首先得要从 MySQL 中导出数据，然后上传到 CSV.&lt;/p&gt;

&lt;p&gt;以导出 CSV 为例，需要注意使用 &lt;code&gt;&amp;quot;&lt;/code&gt; 符号作为转义字符，而不是 &lt;code&gt;\&lt;/code&gt;. 另外最好用 &lt;code&gt;&amp;quot;&lt;/code&gt; 把每个值都 wrap 起来，免得有些多行字符串导致出错。导出后可以压缩成 gzip 格式，在上传 S3 的时候可以快一些。&lt;/p&gt;

&lt;p&gt;Redshift 的 &lt;code&gt;COPY&lt;/code&gt; 例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY syns_bigdata
FROM &#39;s3://some-bucket/some_filename.csv.gz&#39;
credentials &#39;aws_access_key_id=&amp;lt;aws_access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;aws_secret_access_key&amp;gt;&#39;
region &#39;cn-north-1&#39; CSV GZIP NULL AS &#39;NULL&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;语法很简单，需要注意的有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;aws_access_key_id&lt;/code&gt; 和 &lt;code&gt;aws_secret_access_key&lt;/code&gt; 要有访问 S3 的权限&lt;/li&gt;
&lt;li&gt;指定 region&lt;/li&gt;
&lt;li&gt;指定文件格式，&lt;code&gt;CSV GZIP&lt;/code&gt; 表示是 gzip 压缩的 CSV 文件&lt;/li&gt;
&lt;li&gt;可以用 &lt;code&gt;NULL AS&lt;/code&gt; 语句指定 NULL 值&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>在 AWS 上安装 Tableau Server</title>
      <link>http://liyangliang.me/posts/2017/05/install-tableau-server-on-aws-ec2/</link>
      <pubDate>Wed, 10 May 2017 17:23:55 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/install-tableau-server-on-aws-ec2/</guid>
      <description>&lt;h2 id=&#34;启动-ec2-实例&#34;&gt;启动 EC2 实例&lt;/h2&gt;

&lt;p&gt;先根据 Tableau Server 的使用情况确定需要的配置，从而确定实例类型。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AMI: Microsoft Windows Server 2012 R2 Base（简体中文）&lt;/li&gt;
&lt;li&gt;类型: m4.4xlarge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动、配置步骤略去不表，有两点需要注意：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VPC 需要开启 3389 端口用于远程登录（RDP）&lt;/li&gt;
&lt;li&gt;密钥对会用于解密登录密码&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安装-tableau-server&#34;&gt;安装 Tableau Server&lt;/h2&gt;

&lt;p&gt;从 Tableau 官网下载然后安装，配置、激活过程比较简单，略去不表。&lt;/p&gt;

&lt;h2 id=&#34;可选-安装-mysql-驱动&#34;&gt;（可选）安装 MySQL 驱动&lt;/h2&gt;

&lt;p&gt;在 &lt;a href=&#34;https://www.tableau.com/zh-cn/support/drivers&#34;&gt;这个页面&lt;/a&gt;可以找到所有数据源需要的驱动程序.&lt;/p&gt;

&lt;p&gt;下载好驱动程序，如 mysql-connector-odbc-5.3.7-winx64.msi，双击安装，提示错误。搜索了一番，应该是缺少 Visual C++ 的运行库。试过 Visual C++ Redistributable for Visual Studio 2012 Update 4 和 Visual C++ Redistributable Packages for Visual Studio 2013，最后发现后者才有用。&lt;/p&gt;

&lt;p&gt;安装完 &lt;a href=&#34;https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=40784&#34;&gt;Visual C++ Redistributable Packages for Visual Studio 2013&lt;/a&gt; 之后，可以成功安装mysql-connector-odbc-5.3.7-winx64.msi 。&lt;/p&gt;

&lt;h2 id=&#34;安装-aws-命令行程序&#34;&gt;安装 AWS 命令行程序&lt;/h2&gt;

&lt;p&gt;从这里下载：&lt;a href=&#34;https://s3.amazonaws.com/aws-cli/AWSCLI64.msi&#34;&gt;https://s3.amazonaws.com/aws-cli/AWSCLI64.msi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装完后打开 cmd，运行 &lt;code&gt;aws configure&lt;/code&gt; 进行配置，要有上传 S3 的权限。完成后可以运行 &lt;code&gt;aws s3 ls&lt;/code&gt; 验证。&lt;/p&gt;

&lt;h2 id=&#34;编写备份脚本&#34;&gt;编写备份脚本&lt;/h2&gt;

&lt;p&gt;自动备份并且把备份文件上传到 S3。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@echo OFF
set Binpath=&amp;quot;C:\Program Files\Tableau\Tableau Server\10.2\bin&amp;quot;
set Backuppath=&amp;quot;C:\Backups\Tablea Server\nightly&amp;quot;
echo %date% %time%: *** Housekeeping started ***

rmdir %Backuppath% /S /Q

%Binpath%\tabadmin backup %Backuppath%\ts_backup -d --no-config
timeout 5

%Binpath%\tabadmin cleanup

echo %date% %time%: Uploading to S3

aws s3 cp %Backuppath% s3://tableau-server-backup/ --recursive --exclude &amp;quot;*&amp;quot; --include &amp;quot;ts_backup-*.tsbak&amp;quot;

echo %date% %time%: *** Housekeeping completed ***
timeout 5
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;从备份恢复&#34;&gt;从备份恢复&lt;/h2&gt;

&lt;p&gt;如果是从其他的 Tableau Server 迁移过来，可以使用备份文件迁移数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Users\Administrator&amp;gt;&amp;quot;C:\Program Files\Tableau\Tableau Server\10.2\bin\tabadmi
n.bat&amp;quot; restore --no-config Downloads\ts_backup-2017-04-05.tsbak
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;restore 操作会关闭 Tableau Server，恢复完成后需要手动开启。&lt;/p&gt;

&lt;h2 id=&#34;自动备份&#34;&gt;自动备份&lt;/h2&gt;

&lt;p&gt;使用 Task Scheduler 实现，详情见官方文档：&lt;a href=&#34;http://technet.microsoft.com/en-us/library/cc766428.aspx&#34;&gt;http://technet.microsoft.com/en-us/library/cc766428.aspx&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Python 多进程导入数据到 MySQL</title>
      <link>http://liyangliang.me/posts/2017/02/load-data-into-mysql-using-python-multiprocessing/</link>
      <pubDate>Sat, 25 Feb 2017 16:16:14 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/02/load-data-into-mysql-using-python-multiprocessing/</guid>
      <description>&lt;p&gt;前段时间帮同事处理了一个把 CSV 数据导入到 MySQL 的需求。两个很大的 CSV 文件，
分别有 3GB、2100 万条记录和 7GB、3500 万条记录。对于这个量级的数据，用简单的单进程／单线程导入
会耗时很久，最终用了多进程的方式来实现。具体过程不赘述，记录一下几个要点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;批量插入而不是逐条插入&lt;/li&gt;
&lt;li&gt;为了加快插入速度，先不要建索引&lt;/li&gt;
&lt;li&gt;生产者和消费者模型，主进程读文件，多个 worker 进程执行插入&lt;/li&gt;
&lt;li&gt;注意控制 worker 的数量，避免对 MySQL 造成太大的压力&lt;/li&gt;
&lt;li&gt;注意处理脏数据导致的异常&lt;/li&gt;
&lt;li&gt;原始数据是 GBK 编码，所以还要注意转换成 UTF-8&lt;/li&gt;
&lt;li&gt;用 &lt;a href=&#34;http://click.pocoo.org/5/&#34;&gt;click&lt;/a&gt; 封装命令行工具&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;具体的代码实现如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
# -*- coding: utf-8 -*-

import codecs
import csv
import logging
import multiprocessing
import os
import warnings

import click
import MySQLdb
import sqlalchemy

warnings.filterwarnings(&#39;ignore&#39;, category=MySQLdb.Warning)

# 批量插入的记录数量
BATCH = 5000

DB_URI = &#39;mysql://root@localhost:3306/example?charset=utf8&#39;

engine = sqlalchemy.create_engine(DB_URI)


def get_table_cols(table):
    sql = &#39;SELECT * FROM `{table}` LIMIT 0&#39;.format(table=table)
    res = engine.execute(sql)
    return res.keys()


def insert_many(table, cols, rows, cursor):
    sql = &#39;INSERT INTO `{table}` ({cols}) VALUES ({marks})&#39;.format(
            table=table,
            cols=&#39;, &#39;.join(cols),
            marks=&#39;, &#39;.join([&#39;%s&#39;] * len(cols)))
    cursor.execute(sql, *rows)
    logging.info(&#39;process %s inserted %s rows into table %s&#39;, os.getpid(), len(rows), table)


def insert_worker(table, cols, queue):
    rows = []
    # 每个子进程创建自己的 engine 对象
    cursor = sqlalchemy.create_engine(DB_URI)
    while True:
        row = queue.get()
        if row is None:
            if rows:
                insert_many(table, cols, rows, cursor)
            break

        rows.append(row)
        if len(rows) == BATCH:
            insert_many(table, cols, rows, cursor)
            rows = []


def insert_parallel(table, reader, w=10):
    cols = get_table_cols(table)

    # 数据队列，主进程读文件并往里写数据，worker 进程从队列读数据
    # 注意一下控制队列的大小，避免消费太慢导致堆积太多数据，占用过多内存
    queue = multiprocessing.Queue(maxsize=w*BATCH*2)
    workers = []
    for i in range(w):
        p = multiprocessing.Process(target=insert_worker, args=(table, cols, queue))
        p.start()
        workers.append(p)
        logging.info(&#39;starting # %s worker process, pid: %s...&#39;, i + 1, p.pid)

    dirty_data_file = &#39;./{}_dirty_rows.csv&#39;.format(table)
    xf = open(dirty_data_file, &#39;w&#39;)
    writer = csv.writer(xf, delimiter=reader.dialect.delimiter)

    for line in reader:
        # 记录并跳过脏数据: 键值数量不一致
        if len(line) != len(cols):
            writer.writerow(line)
            continue

        # 把 None 值替换为 &#39;NULL&#39;
        clean_line = [None if x == &#39;NULL&#39; else x for x in line]

        # 往队列里写数据
        queue.put(tuple(clean_line))
        if reader.line_num % 500000 == 0:
            logging.info(&#39;put %s tasks into queue.&#39;, reader.line_num)

    xf.close()

    # 给每个 worker 发送任务结束的信号
    logging.info(&#39;send close signal to worker processes&#39;)
    for i in range(w):
        queue.put(None)

    for p in workers:
        p.join()


def convert_file_to_utf8(f, rv_file=None):
    if not rv_file:
        name, ext = os.path.splitext(f)
        if isinstance(name, unicode):
            name = name.encode(&#39;utf8&#39;)
        rv_file = &#39;{}_utf8{}&#39;.format(name, ext)
    logging.info(&#39;start to process file %s&#39;, f)
    with open(f) as infd:
        with open(rv_file, &#39;w&#39;) as outfd:
            lines = []
            loop = 0
            chunck = 200000
            first_line = infd.readline().strip(codecs.BOM_UTF8).strip() + &#39;\n&#39;
            lines.append(first_line)
            for line in infd:
                clean_line = line.decode(&#39;gb18030&#39;).encode(&#39;utf8&#39;)
                clean_line = clean_line.rstrip() + &#39;\n&#39;
                lines.append(clean_line)
                if len(lines) == chunck:
                    outfd.writelines(lines)
                    lines = []
                    loop += 1
                    logging.info(&#39;processed %s lines.&#39;, loop * chunck)

            outfd.writelines(lines)
            logging.info(&#39;processed %s lines.&#39;, loop * chunck + len(lines))


@click.group()
def cli():
    logging.basicConfig(level=logging.INFO,
                        format=&#39;%(asctime)s - %(levelname)s - %(name)s - %(message)s&#39;)


@cli.command(&#39;gbk_to_utf8&#39;)
@click.argument(&#39;f&#39;)
def convert_gbk_to_utf8(f):
    convert_file_to_utf8(f)


@cli.command(&#39;load&#39;)
@click.option(&#39;-t&#39;, &#39;--table&#39;, required=True, help=&#39;表名&#39;)
@click.option(&#39;-i&#39;, &#39;--filename&#39;, required=True, help=&#39;输入文件&#39;)
@click.option(&#39;-w&#39;, &#39;--workers&#39;, default=10, help=&#39;worker 数量，默认 10&#39;)
def load_fac_day_pro_nos_sal_table(table, filename, workers):
    with open(filename) as fd:
        fd.readline()   # skip header
        reader = csv.reader(fd)
        insert_parallel(table, reader, w=workers)


if __name__ == &#39;__main__&#39;:
    cli()
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>在 Flask 项目的 celery 中使用 gevent</title>
      <link>http://liyangliang.me/posts/2016/05/using-celery-with-flask-and-gevent/</link>
      <pubDate>Tue, 17 May 2016 16:42:37 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/05/using-celery-with-flask-and-gevent/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://liyangliang.me/posts/2015/11/using-celery-with-flask/&#34;&gt;在 Flask 项目中使用 Celery&lt;/a&gt; 这篇文章谈到了如何在 Flask 项目中集成 Celery，也讲了在 celery 任务中引用 Flask 的 application context 的方法。一般情况下那样使用是没问题的，但是如果需要在 task 中使用 gevent，就需要一些额外的改进。至少有两点。&lt;/p&gt;

&lt;h2 id=&#34;1-使用-gevent-并发模型&#34;&gt;1. 使用 gevent 并发模型&lt;/h2&gt;

&lt;p&gt;如果在 task 中要使用 gevent，就必须使用 gevent 并发模型。这很好处理，只需要修改启动选项就行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ celery worker -A celery_worker.celery -P gevent -c 10 -l INFO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令，&lt;code&gt;-P&lt;/code&gt; 选项指定 pool，默认是 prefork，这里是 gevent; &lt;code&gt;-c&lt;/code&gt; 设置并发数。&lt;/p&gt;

&lt;h2 id=&#34;2-引用-flask-的-application-context&#34;&gt;2. 引用 Flask 的 application context&lt;/h2&gt;

&lt;p&gt;这个问题也是在 &lt;a href=&#34;http://liyangliang.me/posts/2015/11/using-celery-with-flask/&#34;&gt;在 Flask 项目中使用 Celery&lt;/a&gt; 中重点讨论的，在这种场景下，上文的解决方法起不到作用，仍然会报错（具体原因不太懂，知道的朋友请不吝赐教）。解决方案就是，把需要引用 Flask app 的地方（如 app.config），放到 Flask 的 application context 里执行，如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;with app.app_context():
    print app.config.get(&#39;SOME_CONFIG_KEY&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在实际应用中，我最后写了个装饰器来实现这个目的。简单介绍一下场景，项目用到了 Flask-Cache，项目启动时会创建全局单例 &lt;code&gt;cache&lt;/code&gt;，并在 &lt;code&gt;create_app&lt;/code&gt; 中进行初始化。在 Flask-Cache 初始化时，会把当前的 Flask app 对象绑定到实例 &lt;code&gt;cache&lt;/code&gt; 中，所以可以尝试从这里获取 app 对象。&lt;/p&gt;

&lt;p&gt;代码的目录结构与之前一样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── README.md
├── app
│   ├── __init__.py
│   ├── config.py
│   ├── forms
│   ├── models
│   ├── tasks
│   │   ├── __init__.py
│   │   └── email.py
│   └── views
│   │   ├── __init__.py
│   │   └── account.py
├── celery_worker.py
├── manage.py
└── wsgi.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;装饰器：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def with_app_context(task):
    memo = {&#39;app&#39;: None}

    @functools.wraps(task)
    def _wrapper(*args, **kwargs):
        if not memo[&#39;app&#39;]:
            try:
                # 尝试从 cache 中获取 app 对象，如果得到的不是 None，就不需要重复创建了
                app = cache.app
                _ = app.name
            except Exception:
                from app import create_app

                app = create_app()
            memo[&#39;app&#39;] = app
        else:
            app = memo[&#39;app&#39;]

        # 把 task 放到 application context 环境中运行
        with app.app_context():
            return task(*args, **kwargs)

    return _wrapper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@celery.task()
@with_app_context
def add(x, y):
    print app.config.get(&#39;SOME_CONFIG_KEY&#39;)
    return x + y
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>MongoDB Replica Set 重新同步</title>
      <link>http://liyangliang.me/posts/2016/04/mongodb-replica-set-resync/</link>
      <pubDate>Fri, 15 Apr 2016 11:47:00 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/04/mongodb-replica-set-resync/</guid>
      <description>&lt;p&gt;生产环境上用了 MongoDB，三个节点组成的 ReplicaSet（复制集）。部署好后，应用一直没出过问题，所以平时也没管过。今天早上突然想上服务器看看，于是登录了 primary 节点查看日志，发现这条日志不断重复：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016-04-15T03:02:39.470+0000 W NETWORK  [ReplExecNetThread-28676] Failed to connect to 172.31.168.48:11102, reason: errno:111 Connection refused
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实就是有个 secondary 节点一直连接不上。不太可能是网络问题，所以很可能是那个节点的 mongod 进程挂掉了。登录上 secondary 节点，mongod 进程果然不在运行；查看日志发现最后一条是在 2016-03-21. 一时间有两个疑问涌上心头：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么会挂掉？&lt;/li&gt;
&lt;li&gt;如何修复？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;当务之急是先修复集群，这一点官方文档有说明：&lt;a href=&#34;https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/&#34;&gt;Resync a Member of a Replica Set&lt;/a&gt;. 其实就是删除数据文件，然后通过 initial sync 来重新同步。有两种 initial sync 的方式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;清空数据目录，重启 mongod 实例，让MongoDB进行正常的初始化同步。这是个简单的方式，但是耗时较长。&lt;/li&gt;
&lt;li&gt;为该机器从其他节点上复制一份最近的数据文件，并重启。操作步骤较多，但是最为快速。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;考虑到数据量并没有很多，所以决定使用第一种比较简单的方式。重启好后，发现数据目录很快就新建了很多文件。和 primary 节点对比，文件名和大小均一致；primary 节点和另一个 secondary 节点也不再出现连接失败的日志。&lt;/p&gt;

&lt;p&gt;遗憾的是，挂掉的原因却一直没有找到。日志文件里没有发现异常，&lt;code&gt;history&lt;/code&gt; 也没发现有 &lt;code&gt;kill&lt;/code&gt; 的记录。
幸运的是，集群很快就恢复了，应用不受影响，数据也没丢失。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nginx AWS ELB 域名解析</title>
      <link>http://liyangliang.me/posts/2016/04/nginx-aws-elb-name-resolution/</link>
      <pubDate>Thu, 14 Apr 2016 15:33:52 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/04/nginx-aws-elb-name-resolution/</guid>
      <description>&lt;p&gt;最近生产环境上出现了一个奇怪的问题。某日下午，APP 向某个域名发出的所有请求没有响应，服务端也没收到请求；而向另一个域名的请求却没有问题。先记录一下背景：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;两个域名：api.example.com, web.example.com&lt;/li&gt;
&lt;li&gt;环境：AWS + ELB + Nginx&lt;/li&gt;
&lt;li&gt;后端：Python + Django + Gunicorn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;出问题的是 api.example.com （下文简称 API）这个域名，所以 web.example.com 就不细说。由于一些历史原因，API 的请求链路大概是这样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                      proxy_pass         backends                      proxy_pass
APP -----&amp;gt; API Nginx -------------&amp;gt; ELB -----------&amp;gt; Backend Nginx(s) ------------&amp;gt; Gunicorn(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 API 的 Nginx 配置大概是这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;location /test {
    proxy_pass http://name.of.elb.aws.com;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文章开头描述的现象就是，在 API 的 Nginx 能看到 access log，但是 Backend 的 Nginx 没有接收到请求。所以问题可能出在代理这一步。奇怪的地方在于，刚上线时一切正常，运行了一段时间后才突然出现。猜测有可能是 DNS 解析的问题，但没有根据，也不知道如何解决。&lt;/p&gt;

&lt;p&gt;后来 Google 了一番，发现确实是 DNS 的问题。Nginx 会在启动的时候进行域名查找，然后把 IP 地址缓存起来，后续就直接使用这些 IP 地址。而 AWS 的 ELB 所指向的 IP 地址是不固定的，会经常更新；所以这会导致 Nginx 缓存的 IP 地址实际上已经失效。定位出了问题，也参考网上的做法，把 API 的 Nginx 配置稍作修改：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;location /test {
    resolver 233.5.5.5 valid=30s;
    proxy_pass http://name.of.elb.aws.com;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;a href=&#34;http://nginx.org/en/docs/http/ngx_http_core_module.html#resolver&#34;&gt;resolver&lt;/a&gt; 就是 Nginx 用于把域名转换为 IP 地址的域名服务器。后面的第一个参数是域名服务器，valid 指定了缓存有效期，这里是 30s （默认 5min）. 加上这个配置后，Nginx 会用指定的域名服务器来解析域名，并定期把缓存失效。这样就能避免 ELB 地址更新带来的问题。&lt;/p&gt;

&lt;p&gt;刚开始以为只需要加上 resolver 这一行配置就可以，后来看 &lt;a href=&#34;[http://serverfault.com/a/562518/192152&#34;&gt;这个 serverfault 上的回答&lt;/a&gt;，还需要把 proxy_pass 的地址定义成一个变量。于是最终的配置变成了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;location /test {
    resolver 233.5.5.5 valid=30s;
    set $backends &amp;quot;http://name.of.elb.aws.com&amp;quot;;
    proxy_pass $backends;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改配置，reload，一两天后如果无响应的现象不再出现，说明问题已经解决。&lt;/p&gt;

&lt;p&gt;参考材料：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nginx.org/en/docs/http/ngx_http_core_module.html#resolver&#34;&gt;Nginx 文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tenzer.dk/nginx-with-dynamic-upstreams/&#34;&gt;Nginx with dynamic upstreams&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gc-taylor.com/blog/2011/11/10/nginx-aws-elb-name-resolution-resolvers&#34;&gt;nginx AWS ELB name resolution with resolvers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://serverfault.com/questions/560632/some-nginx-reverse-proxy-configs-stops-working-once-a-day&#34;&gt;serverfault - Some nginx reverse proxy configs stops working once a day&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>
