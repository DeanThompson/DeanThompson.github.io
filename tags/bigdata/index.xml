<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bigdata on 李林克斯</title>
    <link>https://liyangliang.me/tags/bigdata/</link>
    <description>Recent content in bigdata on 李林克斯</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <managingEditor>yanglianglee@gmail.com (Yangliang Li)</managingEditor>
    <webMaster>yanglianglee@gmail.com (Yangliang Li)</webMaster>
    <lastBuildDate>Fri, 21 Aug 2020 13:48:05 +0800</lastBuildDate>
    
	<atom:link href="https://liyangliang.me/tags/bigdata/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>记一次 ClickHouse 数据迁移</title>
      <link>https://liyangliang.me/posts/2020/08/clickhouse-migration/</link>
      <pubDate>Fri, 21 Aug 2020 13:48:05 +0800</pubDate>
      <author>yanglianglee@gmail.com (Yangliang Li)</author>
      <guid>https://liyangliang.me/posts/2020/08/clickhouse-migration/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;大约在 2018 年 8 月份开始正式接触 ClickHouse，当时机房没有合适的服务器，就在 Azure 开了一台虚拟机来部署。平稳运行了两年，支撑了 YiDrone 和 YiSonar 两个重要的产品的底层数据存储和查询。前段时间采购服务器的时候预留了一些资源，加上 Azure 的免费订阅即将到期，于是准备把 ClickHouse 迁回到机房。数据量不大，只有一个节点，硬盘上的数据加起来 500G 左右。&lt;/p&gt;
&lt;h2 id=&#34;方案调研&#34;&gt;方案调研&lt;/h2&gt;
&lt;p&gt;迁移集群实际上就是要把所有数据库（system 除外）的表结构和数据完整的复制一遍。ClickHouse 官方和社区有一些现成的解决方案，也可以自己实现。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Impala 添加和使用 UDF</title>
      <link>https://liyangliang.me/posts/2019/10/impala-udf/</link>
      <pubDate>Fri, 11 Oct 2019 14:09:28 +0800</pubDate>
      <author>yanglianglee@gmail.com (Yangliang Li)</author>
      <guid>https://liyangliang.me/posts/2019/10/impala-udf/</guid>
      <description>&lt;p&gt;Impala 支持 C++ 和 Java 编写的 UDF, 把对应的 so 或 jar 文件放到 HDFS，再注册一下就能使用。官方推荐使用 C++ 编写 UDF，相比 Java 的实现有 10 倍性能提升。Hive 有丰富的函数，可以添加到 Impala 里。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先在 HDFS 创建目录保存 UDF 文件，并把 Hive 的 jar 包上传进去&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;hdfs dfs -mkdir /user/hive/udfs

hdfs dfs -copyFromLocal /opt/cloudera/parcels/CDH/lib/hive/lib/hive-exec-1.1.0-cdh5.14.2.jar /user/hive/udfs/hive-builtins.jar
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>HDFS 异构存储调研</title>
      <link>https://liyangliang.me/posts/2019/05/hdfs-heterogeneous-storage/</link>
      <pubDate>Tue, 07 May 2019 15:47:04 +0800</pubDate>
      <author>yanglianglee@gmail.com (Yangliang Li)</author>
      <guid>https://liyangliang.me/posts/2019/05/hdfs-heterogeneous-storage/</guid>
      <description>&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;HDFS 支持配置多个数据目录，同一节点默认按照 Round Robin 策略写入。硬盘不做 RAID，每块盘单独挂载。&lt;/li&gt;
&lt;li&gt;HDFS 支持异构存储，即不同的存储类型和存储策略，可用于实现冷热分级，从而降低成本&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;存储类型&#34;&gt;存储类型&lt;/h2&gt;
&lt;p&gt;按访问速度降序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RAM_DISK: 即内存&lt;/li&gt;
&lt;li&gt;SSD: SSD，OLTP 类场景（如 HBase）可以考虑使用&lt;/li&gt;
&lt;li&gt;DISK: 普通硬盘&lt;/li&gt;
&lt;li&gt;ARCHIVE: 归档存储，可使用廉价、高容量存储（甚至单机超百 T）&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>一个轻量级通用的数据同步方案</title>
      <link>https://liyangliang.me/posts/2019/04/lightweight-data-sync-solution/</link>
      <pubDate>Sat, 27 Apr 2019 14:02:16 +0800</pubDate>
      <author>yanglianglee@gmail.com (Yangliang Li)</author>
      <guid>https://liyangliang.me/posts/2019/04/lightweight-data-sync-solution/</guid>
      <description>&lt;p&gt;在不同的数据库系统之间做数据同步是大数据领域里常见的需求。一个典型的场景是，业务系统因为需要事务和随机查询，一般会使用 MySQL 这种数据库；数据仓库使用 Hive；ETL 之后的结果再放到 MySQL、AWS Redshift 等系统给 BI 和报表工具使用。&lt;/p&gt;
&lt;p&gt;首先梳理一下需求和目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实时性：非实时，离线同步，一般为 T+1，或最细到小时粒度&lt;/li&gt;
&lt;li&gt;扩展性：需要支持多种异构数据源，如 MySQL, Hive, ElasticSearch 等&lt;/li&gt;
&lt;li&gt;性能要求：因为是离线系统，对性能要求无严格要求，但最好尽可能快，并有可能调优&lt;/li&gt;
&lt;li&gt;复杂度：复杂度低，依赖少，易使用，易运维&lt;/li&gt;
&lt;li&gt;功能要求：要满足全量同步和增量数据同步&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>