<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Redshift on 李林克斯 </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://liyangliang.me/tags/redshift/index.xml</link>
    <language>zh-CN</language>
    <author>Yangliang Li</author>
    
    <updated>Mon, 01 Jan 0001 00:00:00 UTC</updated>
    
    <item>
      <title>Redshift Snippets</title>
      <link>http://liyangliang.me/posts/2018/02/redshift-snippets</link>
      <pubDate>Sun, 04 Feb 2018 19:36:03 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/02/redshift-snippets</guid>
      <description>&lt;ul&gt;
&lt;li&gt;查询所有 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM stv_sessions;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;终止 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT pg_terminate_backend(32281);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即，调用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 函数，传入 process_id。&lt;/p&gt;

&lt;p&gt;权限：普通用户只能终止自己的 session，超级用户能终止任意 session.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查询正在运行的 queries&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类似 MySQL 的 &lt;code&gt;SHOW PROCESSLIST&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT stv_recents.userid, stv_recents.status, stv_recents.starttime,
       stv_recents.duration, stv_recents.user_name, stv_recents.db_name,
       stv_recents.query, stv_recents.pid
FROM stv_recents
WHERE stv_recents.status = &#39;Running&#39;::bpchar;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建数据库时报错：&lt;code&gt;source database &amp;quot;template1&amp;quot; is being accessed by other users&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：&lt;code&gt;template1&lt;/code&gt; 数据库被其他 session 占用，锁住了。&lt;/p&gt;

&lt;p&gt;解决方法：先从 &lt;code&gt;stv_sessions&lt;/code&gt; 表查找 &lt;code&gt;template1&lt;/code&gt; 相关的 session，然后用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 杀掉。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;备份数据到 S3&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UNLOAD (&#39;SELECT * FROM public.category&#39;) TO &#39;s3://redshift-backup/unload/public/category/category_&#39;
access_key_id &#39;&amp;lt;access_key_id&amp;gt;&#39; secret_access_key &#39;&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; ADDQUOTES ESCAPE ALLOWOVERWRITE;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;从 S3 加载数据&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY public.category FROM &#39;s3://redshift-backup/unload/public/category&#39;
CREDENTIALS &#39;aws_access_key_id=&amp;lt;access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; REMOVEQUOTES ESCAPE REGION &#39;cn-north-1&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;定义 Python UDF&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文档: &lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE FUNCTION f_hash(value varchar) returns varchar immutable as $$
    def sha256_hash(value):
        import hashlib, base64
        return base64.urlsafe_b64encode(hashlib.sha256(value or &#39;&#39;).digest())
    return sha256_hash(value)
$$ language plpythonu;

SELECT address, mobile_no, f_hash(address), f_hash(mobile_no)
FROM leqi_orders LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;查看表所占磁盘等信息&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT BTRIM(pgdb.datname::character varying::text) AS &amp;quot;database&amp;quot;,
       BTRIM(a.name::character varying::text) AS &amp;quot;table&amp;quot;,
       (b.mbytes::numeric::numeric(18,0) / part.total::numeric::numeric(18,0) * 100::numeric::numeric(18,0))::numeric(5,2) AS pct_of_total,
       a.&amp;quot;rows&amp;quot;,
       b.mbytes,
       b.unsorted_mbytes
FROM stv_tbl_perm a
  JOIN pg_database pgdb ON pgdb.oid = a.db_id::oid
  JOIN (
    SELECT stv_blocklist.tbl,
           SUM(
             CASE
               WHEN stv_blocklist.unsorted = 1 OR stv_blocklist.unsorted IS NULL AND 1 IS NULL THEN 1
               ELSE 0
             END
           ) AS unsorted_mbytes,
           COUNT(*) AS mbytes
    FROM stv_blocklist
    GROUP BY stv_blocklist.tbl
  ) b ON a.id = b.tbl
  JOIN (
    SELECT SUM(stv_partitions.capacity) AS total
    FROM stv_partitions
    WHERE stv_partitions.part_begin = 0
  ) part ON 1 = 1
WHERE a.slice = 0
ORDER BY b.mbytes DESC, a.db_id, a.name;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查询结果样例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;database  table pct_of_total  rows  mbytes  unsorted_mbytes
roma	mda_price_idx	0	50005	10	10
roma	mda_vendor	0	4	10	10
roma	mda_vendor	0	8	10	7
roma	sku_bodytype	0	9	10	7
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>MySQL 数据导入到 Redshift</title>
      <link>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift</link>
      <pubDate>Wed, 10 May 2017 17:36:29 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift</guid>
      <description>&lt;h2 id=&#34;设计表&#34;&gt;设计表&lt;/h2&gt;

&lt;p&gt;首先是设计表结构。建表语法差别不大，有一些地方可以注意一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Redshift 貌似没有无符号类型，所以要把 unsigned 类型的字段修改成相应的 INT 或 BIGINT 类型。&lt;/li&gt;
&lt;li&gt;FLOAT 类型改成 REAL 或 FLOAT4&lt;/li&gt;
&lt;li&gt;把索引语句去掉，保留主键、外键、唯一性约束，Redshift 不会检查这些约束，但是查询时会用于优化。&lt;/li&gt;
&lt;li&gt;Redshift 的 CHAR 类型只能包含单字节 ASCII 字符，对于非 ASCII 数据需要把 CHAR 改成 VARCHAR 类型&lt;/li&gt;
&lt;li&gt;有可能 MySQL 中存的是 unicode，而 Redshift 中存的是 bytes，所以 VARCHAR 的长度也要调整，避免溢出。最简单的，可以用 MySQL 的字段长度 * 3.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于 sort key, dist key 等设计，只属于 Redshift 范畴，参考官网文档即可。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;加载数据&#34;&gt;加载数据&lt;/h2&gt;

&lt;p&gt;因为 Redshift 推荐使用 &lt;code&gt;COPY&lt;/code&gt; 命令从 S3 加载数据，所以首先得要从 MySQL 中导出数据，然后上传到 CSV.&lt;/p&gt;

&lt;p&gt;以导出 CSV 为例，需要注意使用 &lt;code&gt;&amp;quot;&lt;/code&gt; 符号作为转义字符，而不是 &lt;code&gt;\&lt;/code&gt;. 另外最好用 &lt;code&gt;&amp;quot;&lt;/code&gt; 把每个值都 wrap 起来，免得有些多行字符串导致出错。导出后可以压缩成 gzip 格式，在上传 S3 的时候可以快一些。&lt;/p&gt;

&lt;p&gt;Redshift 的 &lt;code&gt;COPY&lt;/code&gt; 例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY syns_bigdata
FROM &#39;s3://some-bucket/some_filename.csv.gz&#39;
credentials &#39;aws_access_key_id=&amp;lt;aws_access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;aws_secret_access_key&amp;gt;&#39;
region &#39;cn-north-1&#39; CSV GZIP NULL AS &#39;NULL&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;语法很简单，需要注意的有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;aws_access_key_id&lt;/code&gt; 和 &lt;code&gt;aws_secret_access_key&lt;/code&gt; 要有访问 S3 的权限&lt;/li&gt;
&lt;li&gt;指定 region&lt;/li&gt;
&lt;li&gt;指定文件格式，&lt;code&gt;CSV GZIP&lt;/code&gt; 表示是 gzip 压缩的 CSV 文件&lt;/li&gt;
&lt;li&gt;可以用 &lt;code&gt;NULL AS&lt;/code&gt; 语句指定 NULL 值&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>
