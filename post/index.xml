<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Posts on 李林克斯 </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://liyangliang.me/post/index.xml</link>
    <language>zh-CN</language>
    <author>Yangliang Li</author>
    
    <updated>Sat, 02 Jun 2018 16:03:26 CST</updated>
    
    <item>
      <title>Python 日期和时间处理</title>
      <link>http://liyangliang.me/posts/2018/06/python-date-time</link>
      <pubDate>Sat, 02 Jun 2018 16:03:26 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/06/python-date-time</guid>
      <description>

&lt;p&gt;2012 年大四的时候写过一篇 &lt;a href=&#34;http://liyangliang.me/posts/2012/10/python-timestamp-to-timestr&#34;&gt;Python 时间戳和日期相互转换&lt;/a&gt;，当时是初学 Python，对标准库也理解不深；随便找到一种解决方案就记录下来并发到博客上了。现在回看起来，其实太过繁琐了。然而从 Google Analytics 后台看，这竟然是点击率第二的文章，着实让我感到诧异。本着对读者负责的态度，有必要结合这些年的开发经验，再写一篇日期和时间处理的博客。&lt;/p&gt;

&lt;p&gt;首先再次回答「Python 时间戳和日期相互转换」的问题。&lt;/p&gt;

&lt;h2 id=&#34;时间戳转日期&#34;&gt;时间戳转日期&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime
import time

t = time.time()
print(&#39;Timestamp&#39;, t)

dt = datetime.datetime.fromtimestamp(t)
print(&#39;Datetime&#39;, dt)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Timestamp 1527927420.684622
Datetime 2018-06-02 16:17:00.684622
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;日期转时间戳&#34;&gt;日期转时间戳&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime

now = datetime.datetime.now()
print(&#39;Datetime&#39;, now)
print(&#39;Timestamp&#39;, now.timestamp())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Datetime 2018-06-02 16:18:42.170874
Timestamp 1527927522.170874
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>CentOS 7 FirewallD</title>
      <link>http://liyangliang.me/posts/2018/06/centos7-firewalld</link>
      <pubDate>Sat, 02 Jun 2018 15:11:15 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/06/centos7-firewalld</guid>
      <description>&lt;h2 id=&#34;背景故事&#34;&gt;背景故事&lt;/h2&gt;

&lt;p&gt;线上服务器一直没有开启防火墙，没有约束用起来倒也省事。部署 Hadoop 集群（CDH 发行版）的时候，所有网上看过的教程和笔记（包括 CDH 官方文档），全部都提到了部署过程中要关闭防火墙；极少数教程会提到如果有需要，可以在部署完成后再开启；然而没有任何教程在最后真正开启了防火墙。&lt;/p&gt;

&lt;p&gt;因为没有防火墙，其实也发生过几次安全事故：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;某天某台服务器 CPU 利用率很高，后来发现是因为被人利用 rundeck 的漏洞植入了一个挖矿程序；&lt;/li&gt;
&lt;li&gt;某天有个跑在 Docker 里的 Redis 出现故障，经查也是被植入了挖矿程序&lt;/li&gt;
&lt;li&gt;某天发现有台机器上有个废弃的 MySQL 跑在公网上，日志里面几乎全是尝试登录的记录&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这几次事故虽然没有导致财产损失，但是公网太可怕，没有防火墙就是在外面裸奔，随时可能受到攻击。Hadoop 集群所有服务都是绑定到 &lt;code&gt;0.0.0.0&lt;/code&gt;，加上没有开启认证，很容易被拖库。&lt;/p&gt;

&lt;h2 id=&#34;firewalld&#34;&gt;FirewallD&lt;/h2&gt;

&lt;p&gt;最先想到的是用 iptables，之前也有使用经历，然而这玩意儿实在太复杂，概念、规则太多，一直没弄懂。CentOS 7 默认安装了 &lt;a href=&#34;http://www.firewalld.org/&#34;&gt;FirewallD&lt;/a&gt;，使用起来非常方便，也很好理解。网上的介绍和教程很多，不赘述。直接介绍我的使用策略。&lt;/p&gt;

&lt;p&gt;FirewallD 有很多种 zone policy，直接使用默认的 &lt;code&gt;public&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;首先内网之间必须能相互访问，否则各种集群的节点之间无法通信，会导致集群无法使用。我们有两套内网环境，一个是机房服务器之间，IP 网段是 &lt;code&gt;172.16.24.0/24&lt;/code&gt;；另一个是本地和服务器之间，通过 openvpn 连接，有两个 IP 段 &lt;code&gt;10.8.0.0/24&lt;/code&gt; 和 &lt;code&gt;10.8.1.0/24&lt;/code&gt;. 参考 &lt;a href=&#34;http://xuxping.com/2017/04/04/hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/&#34;&gt;这篇文章&lt;/a&gt;进行配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=172.16.24.0/24 accept&#39;
sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=10.8.0.0/24 accept&#39;
sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=10.8.1.0/24 accept&#39;
sudo firewall-cmd  --reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其次常用服务、端口也需要开启：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --permanent --add-service=openvpn

sudo firewall-cmd --permanent --add-port=5000
sudo firewall-cmd --permanent --add-port=8080
sudo firewall-cmd --permanent --add-port=8088
sudo firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置完成之后可以查看 &lt;code&gt;/etc/firewalld/zones/public.xml&lt;/code&gt; 文件进一步确认开启的 service、source 和 port. 挑个端口用 &lt;code&gt;telnet&lt;/code&gt; 测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; telnet &amp;lt;public-ip&amp;gt; 21050

Trying &amp;lt;public-ip&amp;gt;...
telnet: connect to address &amp;lt;public-ip&amp;gt;: Connection refused
telnet: Unable to connect to remote host

&amp;gt; telnet 172.16.24.123 21050

Trying 172.16.24.123...
Connected to 172.16.24.123.
Escape character is &#39;^]&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;firewalld-docker&#34;&gt;FirewallD &amp;amp; Docker&lt;/h2&gt;

&lt;p&gt;如果先运行 &lt;code&gt;dockerd&lt;/code&gt; 再运行 &lt;code&gt;firewalld&lt;/code&gt;, 会导致 Docker 无法正常工作，用 Docker 部署的程序无法访问了。这个问题在网上有很多讨论，Docker 的 GitHub 主页就有&lt;a href=&#34;https://github.com/moby/moby/issues/16137&#34;&gt;一个 issue&lt;/a&gt;.
我是这么解决的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --zone=trusted --change-interface=docker0
sudo firewall-cmd --reload
sudo service docker restard
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是把 &lt;code&gt;docker0&lt;/code&gt; 网卡添加到 &lt;code&gt;trusted&lt;/code&gt; zone，再重启 &lt;code&gt;dockerd&lt;/code&gt;. 操作完成后 Docker 服务恢复正常，但是 &lt;code&gt;firewalld&lt;/code&gt; 进程却意外退出了，大量这种日志：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -n -L DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -n -L DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -n -L DOCKER-ISOLATION&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C DOCKER-ISOLATION -j RETURN&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C POSTROUTING -m addrtype --src-type LOCAL -o docker0 -j MASQUERADE&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -D FORWARD -i docker0 -o docker0 -j DROP&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -i docker0 -o docker0 -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -i docker0 ! -o docker0 -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C PREROUTING -m addrtype --dst-type LOCAL -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C OUTPUT -m addrtype --dst-type LOCAL -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -o docker0 -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -j DOCKER-ISOLATION&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -D FORWARD -i docker0 -o docker0 -j DROP&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参照 &lt;a href=&#34;https://github.com/moby/moby/issues/16137#issuecomment-271615192&#34;&gt;这个&lt;/a&gt; 和 &lt;a href=&#34;https://stackoverflow.com/questions/33600154/docker-not-starting-could-not-delete-the-default-bridge-network-network-bridg/33604859#33604859&#34;&gt;这个&lt;/a&gt; 做法均无法消除这种错误日志，但是配置的防火墙规则都生效了。&lt;/p&gt;

&lt;h2 id=&#34;ansible-role&#34;&gt;Ansible Role&lt;/h2&gt;

&lt;p&gt;把以上配置写成 Ansible 任务进行自动化：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;---

- name: stop iptables and disable iptables on boot
  service: name=iptables state=stopped enabled=no
  ignore_errors: true

- name: ensure firewalld installed
  yum: name=firewalld state=present

- name: enable firewalld
  service: name=firewalld state=started enabled=yes

- name: set public as default zone policy
  command: firewall-cmd --set-default-zone=public

- name: ensure private network is not blocked
  firewalld:
    rich_rule: &#39;rule family=ipv4 source address={{ item }} accept&#39;
    permanent: true
    state: enabled
  with_items:
      - 172.16.24.0/24
      - 10.8.0.0/24
      - 10.8.1.0/24

- name: enable common services
  firewalld:
    service: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - http
    - https
    - ssh
    - ntp
    - openvpn

- name: enable ports
  firewalld:
    port: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - 58890/tcp
    - 58880/tcp
    - 5000/tcp
    - 8080/tcp
    - 8088/tcp
    - 8888/tcp

- name: enable docker interface
  firewalld:
    zone: trusted
    interface: docker0
    permanent: true
    state: enabled

- name: enable docker ports
  firewalld:
    port: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - 4243/tcp

# 有些机器可能没有运行 dockerd，简单的通过 ignore_errors 来跳过
- name: restart docker daemon
  service: name=docker state=restarted
  ignore_errors: true

- name: reload firewalld
  service: name=firewalld state=reloaded

# 有时候会出现 firewalld 进程意外退出的情况，具体原因待查
- name: enable firewalld
  service: name=firewalld state=started enabled=yes
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.firewalld.org/&#34;&gt;FirewallD 官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-firewalld-on-centos-7&#34;&gt;DigitalOcean: How To Set Up a Firewall Using FirewallD on CentOS 7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linode.com/docs/security/firewalls/introduction-to-firewalld-on-centos/&#34;&gt;Linode: Introduction to FirewallD on CentOS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/moby/moby/issues/16137&#34;&gt;GitHub: Docker vs. firewalld on CentOS 7 #16137&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/modules/firewalld_module.html&#34;&gt;Ansible firewalld&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Redshift Snippets</title>
      <link>http://liyangliang.me/posts/2018/02/redshift-snippets</link>
      <pubDate>Sun, 04 Feb 2018 19:36:03 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/02/redshift-snippets</guid>
      <description>&lt;ul&gt;
&lt;li&gt;查询所有 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM stv_sessions;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;终止 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT pg_terminate_backend(32281);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即，调用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 函数，传入 process_id。&lt;/p&gt;

&lt;p&gt;权限：普通用户只能终止自己的 session，超级用户能终止任意 session.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查询正在运行的 queries&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类似 MySQL 的 &lt;code&gt;SHOW PROCESSLIST&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT stv_recents.userid, stv_recents.status, stv_recents.starttime,
       stv_recents.duration, stv_recents.user_name, stv_recents.db_name,
       stv_recents.query, stv_recents.pid
FROM stv_recents
WHERE stv_recents.status = &#39;Running&#39;::bpchar;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建数据库时报错：&lt;code&gt;source database &amp;quot;template1&amp;quot; is being accessed by other users&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：&lt;code&gt;template1&lt;/code&gt; 数据库被其他 session 占用，锁住了。&lt;/p&gt;

&lt;p&gt;解决方法：先从 &lt;code&gt;stv_sessions&lt;/code&gt; 表查找 &lt;code&gt;template1&lt;/code&gt; 相关的 session，然后用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 杀掉。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;备份数据到 S3&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UNLOAD (&#39;SELECT * FROM public.category&#39;) TO &#39;s3://redshift-backup/unload/public/category/category_&#39;
access_key_id &#39;&amp;lt;access_key_id&amp;gt;&#39; secret_access_key &#39;&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; ADDQUOTES ESCAPE ALLOWOVERWRITE;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;从 S3 加载数据&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY public.category FROM &#39;s3://redshift-backup/unload/public/category&#39;
CREDENTIALS &#39;aws_access_key_id=&amp;lt;access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; REMOVEQUOTES ESCAPE REGION &#39;cn-north-1&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;定义 Python UDF&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文档: &lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE FUNCTION f_hash(value varchar) returns varchar immutable as $$
    def sha256_hash(value):
        import hashlib, base64
        return base64.urlsafe_b64encode(hashlib.sha256(value or &#39;&#39;).digest())
    return sha256_hash(value)
$$ language plpythonu;

SELECT address, mobile_no, f_hash(address), f_hash(mobile_no)
FROM leqi_orders LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;查看表所占磁盘等信息&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT BTRIM(pgdb.datname::character varying::text) AS &amp;quot;database&amp;quot;,
       BTRIM(a.name::character varying::text) AS &amp;quot;table&amp;quot;,
       (b.mbytes::numeric::numeric(18,0) / part.total::numeric::numeric(18,0) * 100::numeric::numeric(18,0))::numeric(5,2) AS pct_of_total,
       a.&amp;quot;rows&amp;quot;,
       b.mbytes,
       b.unsorted_mbytes
FROM stv_tbl_perm a
  JOIN pg_database pgdb ON pgdb.oid = a.db_id::oid
  JOIN (
    SELECT stv_blocklist.tbl,
           SUM(
             CASE
               WHEN stv_blocklist.unsorted = 1 OR stv_blocklist.unsorted IS NULL AND 1 IS NULL THEN 1
               ELSE 0
             END
           ) AS unsorted_mbytes,
           COUNT(*) AS mbytes
    FROM stv_blocklist
    GROUP BY stv_blocklist.tbl
  ) b ON a.id = b.tbl
  JOIN (
    SELECT SUM(stv_partitions.capacity) AS total
    FROM stv_partitions
    WHERE stv_partitions.part_begin = 0
  ) part ON 1 = 1
WHERE a.slice = 0
ORDER BY b.mbytes DESC, a.db_id, a.name;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查询结果样例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;database  table pct_of_total  rows  mbytes  unsorted_mbytes
roma	mda_price_idx	0	50005	10	10
roma	mda_vendor	0	4	10	10
roma	mda_vendor	0	8	10	7
roma	sku_bodytype	0	9	10	7
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Pyenv 使用笔记</title>
      <link>http://liyangliang.me/posts/2017/06/pyenv-notes</link>
      <pubDate>Tue, 20 Jun 2017 15:09:27 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/06/pyenv-notes</guid>
      <description>&lt;p&gt;应用使用虚拟环境是每个 Python 程序员都应该要掌握的技能。
&lt;a href=&#34;https://github.com/pyenv/pyenv&#34;&gt;pyenv&lt;/a&gt; 是一个非常好用的 Python 环境管理工具。有这些主要特性：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;方便的安装、管理不同版本的 Python，而且不需要 sudo 权限，不会污染系统的 Python 版本&lt;/li&gt;
&lt;li&gt;可以修改当前用户使用的默认 Python 版本&lt;/li&gt;
&lt;li&gt;集成 virtualenv，自动安装、激活&lt;/li&gt;
&lt;li&gt;命令行自动补全&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;详细内容见 &lt;a href=&#34;https://github.com/pyenv/pyenv&#34;&gt;Github - pyenv/pyenv&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;安装-pyenv&#34;&gt;安装 pyenv&lt;/h2&gt;

&lt;p&gt;最简单的方式是使用 &lt;a href=&#34;https://github.com/pyenv/pyenv-installer&#34;&gt;pyenv-installer&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在 &lt;code&gt;~/.bashrc&lt;/code&gt; 或 &lt;code&gt;~/.zshrc&lt;/code&gt; 中添加如下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=&amp;quot;~/.pyenv/bin:$PATH&amp;quot;
eval &amp;quot;$(pyenv init -)&amp;quot;
eval &amp;quot;$(pyenv virtualenv-init -)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;常用命令&#34;&gt;常用命令&lt;/h2&gt;

&lt;p&gt;完整的命令行列表可以参考 &lt;a href=&#34;https://github.com/pyenv/pyenv/blob/master/COMMANDS.md&#34;&gt;pyenv/COMMANDS.md&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;安装 Python&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv install 3.6.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会为当前用户下载和安装 3.6.0，安装过程可以使用镜像加速，详见下文。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新建虚拟环境&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv virtualenv 3.6.0 py36
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;设置当前路径使用的 Python 环境&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv local py36
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会在当前路径创建一个 &lt;code&gt;.python-version&lt;/code&gt; 文件，文件内容就是 &lt;code&gt;py36&lt;/code&gt;，即环境名称。所以一般需要把 &lt;code&gt;.python-version&lt;/code&gt; 添加到 gitignore.&lt;/p&gt;

&lt;p&gt;下次进入该目录时，会自动激活虚拟环境；离开后自动退出。&lt;/p&gt;

&lt;h2 id=&#34;搭建镜像&#34;&gt;搭建镜像&lt;/h2&gt;

&lt;p&gt;pyenv 默认从 Python 官网下载安装包，比较慢；也支持镜像网站，可以自己搭建。&lt;/p&gt;

&lt;h3 id=&#34;搭建镜像-1&#34;&gt;搭建镜像&lt;/h3&gt;

&lt;p&gt;其实就是把安装包下载好，放到服务器上，用 Nginx 搭建一个下载服务。但安装包的文件名必须是文件的 SHA256 值。
如 Python-3.6.0.tar.xz 安装包应该保存为 b0c5f904f685e32d9232f7bdcbece9819a892929063b6e385414ad2dd6a23622&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建目录 &lt;code&gt;/data/pythons&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;下载安装包，从 &lt;a href=&#34;http://mirrors.sohu.com/python/&#34;&gt;搜狐的开源镜像&lt;/a&gt; 下载 &lt;code&gt;.tar.xz&lt;/code&gt; 格式的安装包。&lt;/li&gt;
&lt;li&gt;计算 SHA256（可以使用 &lt;code&gt;sha256sum&lt;/code&gt; 命令），重命名文件&lt;/li&gt;
&lt;li&gt;配置 Nginx&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
    listen 8000;
    root /data/pythons;
    autoindex on;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果没有或不想使用 Nginx，也可以用 Python 运行一个简易的 HTTP 服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python3 -m http.server
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用镜像&#34;&gt;使用镜像&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;export PYTHON_BUILD_MIRROR_URL=http://localhost:8000
pyenv install 3.6.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以把 &lt;code&gt;export PYTHON_BUILD_MIRROR_URL=http://localhost:8000&lt;/code&gt; 添加到 &lt;code&gt;~/.bashrc&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;安装其他版本时，pyenv 会回退到从官网下载。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Centos 7 安装配置 Rundeck</title>
      <link>http://liyangliang.me/posts/2017/06/centos7-install-rundeck</link>
      <pubDate>Tue, 20 Jun 2017 14:59:27 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/06/centos7-install-rundeck</guid>
      <description>&lt;h2 id=&#34;通过-yum-安装&#34;&gt;通过 yum 安装：&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install java-1.8.0
$ sudo rpm -Uvh http://repo.rundeck.org/latest.rpm
$ sudo yum install rundeck
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果已经安装了 Java，第一步可以略过。安装过程中有几个步骤需要确认，一路同意（输入 y）即可。&lt;/p&gt;

&lt;p&gt;安装完成后可以立即运行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service rundeckd start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但生产环境还是要修改一些默认配置。上面的安装过程会添加一个名为 rundeck 的用户和组。配置文件位于 &lt;code&gt;/etc/rundeck&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo su - rundeck
$ cd /etc/rundeck/
$ ll
-rw-r-----. 1 rundeck rundeck  738 Apr 20 07:47 admin.aclpolicy
-rw-r-----. 1 rundeck rundeck 1104 Apr 20 07:47 apitoken.aclpolicy
-rw-r-----. 1 rundeck rundeck  511 Apr 20 07:47 cli-log4j.properties
-rw-r-----. 1 rundeck rundeck 1438 Jun 19 16:52 framework.properties
-rw-r-----. 1 rundeck rundeck  136 Apr 20 07:47 jaas-loginmodule.conf
-rw-r-----. 1 rundeck rundeck 7538 Apr 20 07:47 log4j.properties
-rw-r-----. 1 rundeck rundeck 2889 Apr 20 07:47 profile
-rw-r-----. 1 rundeck rundeck  549 Apr 20 07:47 project.properties
-rw-r-----. 1 rundeck rundeck 1065 Jun 20 11:54 realm.properties
-rw-r-----. 1 rundeck rundeck  579 Jun 20 11:56 rundeck-config.properties
drwxr-x---. 2 rundeck rundeck   27 Jun 19 16:52 ssl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;修改-admin-用户密码&#34;&gt;修改 admin 用户密码&lt;/h2&gt;

&lt;p&gt;用户信息在 &lt;code&gt;realm.properities&lt;/code&gt; 文件，默认有一个 admin 用户，密码也是 admin. 配置格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;username&amp;gt;: &amp;lt;password&amp;gt;[,&amp;lt;rolename&amp;gt; ...]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;默认的配置是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin:admin,user,admin,architect,deploy,build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改密码，并使用 MD5 替换明文密码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ java -cp /var/lib/rundeck/bootstrap/jetty-all-9.0.7.v20131107.jar org.eclipse.jetty.util.security.Password admin Abcd1234
Abcd1234
OBF:1cb01ini1ink1inm1iks1iku1ikw1caa
MD5:325a2cc052914ceeb8c19016c091d2ac
CRYPT:adMpLenKdpR12
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令会生成几种算法加密后的密码，添加到 &lt;code&gt;realm.properities&lt;/code&gt; 文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin:MD5:325a2cc052914ceeb8c19016c091d2ac,user,admin,architect,deploy,build
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;配置使用-mysql-数据库&#34;&gt;配置使用 MySQL 数据库&lt;/h2&gt;

&lt;p&gt;首先得要有个 MySQL 实例，安装过程不赘述。&lt;/p&gt;

&lt;p&gt;配置过程详见 &lt;a href=&#34;http://rundeck.org/docs/administration/setting-up-an-rdb-datasource.html&#34;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建 rundeck 用户和数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ mysql -u root -p

mysql&amp;gt; create database rundeck;
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; grant ALL on rundeck.* to &#39;rundeckuser&#39;@&#39;localhost&#39; identified by &#39;rundeckpassword&#39;;
Query OK, 1 row affected (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后可以使用 &lt;code&gt;rundeckuser&lt;/code&gt; 登录，测试是否能正常连接。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;修改 Rundeck 配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编辑 &lt;code&gt;rundeck-config.properties&lt;/code&gt; 文件，修改后的内容如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#dataSource.url = jdbc:h2:file:/var/lib/rundeck/data/rundeckdb;MVCC=true
dataSource.url = jdbc:mysql://localhost/rundeck?autoReconnect=true
dataSource.username = rundeckuser
dataSource.password = rundeckpassword
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;修改-grails-serverurl&#34;&gt;修改 &lt;code&gt;grails.serverURL&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service rundeckd start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行 Rundeck 服务，打开 &lt;a href=&#34;http://your-server-host:4440/&#34;&gt;http://your-server-host:4440/&lt;/a&gt; 并用 admin 用户登录。登录成功后，被跳转到了 &lt;a href=&#34;http://localhost:4440/menu/home&#34;&gt;http://localhost:4440/menu/home&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;编辑 &lt;code&gt;rundeck-config.properties&lt;/code&gt; 文件，把 &lt;code&gt;grails.serverURL&lt;/code&gt; 改成正确的地址即可。&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/manual/index.html&#34;&gt;User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/administration/index.html&#34;&gt;Administrator Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/api/index.html&#34;&gt;API Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Flask 应用国际化</title>
      <link>http://liyangliang.me/posts/2017/05/flask-i18n</link>
      <pubDate>Wed, 10 May 2017 17:48:17 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/flask-i18n</guid>
      <description>&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Babel is an integrated collection of utilities that assist in internationalizing and localizing Python applications, with an emphasis on web-based applications.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;文档：&lt;a href=&#34;http://babel.pocoo.org/en/latest/&#34;&gt;http://babel.pocoo.org/en/latest/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码：&lt;a href=&#34;https://github.com/python-babel/babel&#34;&gt;https://github.com/python-babel/babel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;flask-babel&#34;&gt;Flask-Babel&lt;/h2&gt;

&lt;p&gt;Flask 的 i18n 扩展，集成 babel、pytz 等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文档：&lt;a href=&#34;https://pythonhosted.org/Flask-Babel/&#34;&gt;https://pythonhosted.org/Flask-Babel/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码：&lt;a href=&#34;https://github.com/python-babel/flask-babel&#34;&gt;https://github.com/python-babel/flask-babel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装：&lt;code&gt;pip install Flask-Babel&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;babel 配置文件：babel.cfg&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[python: **.py]
[jinja2: **.html]
extensions=jinja2.ext.autoescape,jinja2.ext.with_,webassets.ext.jinja2.AssetsExtension
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flask-Babel 配置：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;BABEL_DEFAULT_LOCALE = &#39;zh_CN’                  # locale 选项，默认 &#39;en&#39;
BABEL_DEFAULT_TIMEZONE = &#39;Asia/Shanghai&#39;        # 时区，默认 &#39;UTC&#39;
BABEL_TRANSLATION_DIRECTORIES = &#39;translations&#39;  # 翻译文件所在目录，默认 &#39;translations&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;生成翻译文件模版：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -o messages.pot .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果使用了 &lt;code&gt;lazy_gettext()&lt;/code&gt; 这样的函数，需要在上面的命令行参数指定：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -k lazy_gettext -o messages.pot .
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;生成翻译文件:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel init -i messages.pot -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;编辑 translations/zh_CN/LC_MESSAGES/messages.po 文件，手动翻译。po 文件内容形如：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#: forms.py:65 forms.py:78
#: templates/flask_user/emails/invite_child_user_message.html:9
msgid &amp;quot;Username&amp;quot;
msgstr &amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中：
  - &lt;code&gt;#:&lt;/code&gt; 注释内容是 ‘文件名:行号’，即所有出现过的地方
  - &lt;code&gt;msgid&lt;/code&gt; 是需要翻译的内容
  - &lt;code&gt;msgstr&lt;/code&gt; 是翻译后的内容，如果留空，则会显示原文，即 msgid&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更新翻译文件（一般只需要 init 一次）：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel update -i messages.pot -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;编译&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel compile -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;工作流&#34;&gt;工作流&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -o messages.pot .
$ pybabel init -i messages.pot -d translations     # 第一次
$ pybabel update -i messages.pot -d translations   # 更新
# 手动翻译
$ pybabel compile -d translations
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>EC2 挂载 EBS</title>
      <link>http://liyangliang.me/posts/2017/05/mount-ebs-to-ec2</link>
      <pubDate>Wed, 10 May 2017 17:41:54 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/mount-ebs-to-ec2</guid>
      <description>&lt;p&gt;创建 EC2 实例的时候可以选择添加 EBS 卷，在实例运行后，需要手动挂载上去。&lt;/p&gt;

&lt;p&gt;详情见 &lt;a href=&#34;http://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ebs-using-volumes.html&#34;&gt;EBS 的文档&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;用-lsblk-命令查看所有可用的磁盘及其安装点&#34;&gt;用 &lt;code&gt;lsblk&lt;/code&gt; 命令查看所有可用的磁盘及其安装点&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
`-xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  30G  0 disk
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;xvda1&lt;/code&gt; 是根设备，挂载到了 &lt;code&gt;/&lt;/code&gt;；&lt;code&gt;xvdb&lt;/code&gt; 是刚才添加的 EBS 卷，还没有挂载。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;确定是否需要在卷上创建文件系统&#34;&gt;确定是否需要在卷上创建文件系统。&lt;/h2&gt;

&lt;p&gt;如果是新的 EBS，是一个原始的块存储设备，需要先创建文件系统才能安装使用。从快照还原的卷可能已经含有文件系统。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo file -s /dev/xvdb
/dev/xvdb: data

$ sudo file -s /dev/xvda1
/dev/xvda1: Linux rev 1.0 ext4 filesystem data, UUID=9fbb7c51-0409-4b50-ad40-068dcfe4bc89, volume name &amp;quot;cloudimg-rootfs&amp;quot; (needs journal recovery) (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到 &lt;code&gt;/dev/xvdb&lt;/code&gt; 上面还没有文件系统，需要手动创建:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkfs -t ext4 /dev/xvdb
mke2fs 1.42.13 (17-May-2015)
Creating filesystem with 7864320 4k blocks and 1966080 inodes
Filesystem UUID: 2a0dae23-7b6e-42ec-95e1-df58f29520a4
Superblock backups stored on blocks:
     32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
     4096000

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

$ sudo file -s /dev/xvdb
/dev/xvdb: Linux rev 1.0 ext4 filesystem data, UUID=2a0dae23-7b6e-42ec-95e1-df58f29520a4 (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意：&lt;code&gt;mkfs&lt;/code&gt; 会格式化卷，删除所有数据。&lt;/p&gt;

&lt;h2 id=&#34;创建安装点-也就是要挂载的位置&#34;&gt;创建安装点，也就是要挂载的位置:&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir /data
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;挂载&#34;&gt;挂载&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sudo mount /dev/xvdb /data/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;用-df-命令磁盘空间&#34;&gt;用 &lt;code&gt;df&lt;/code&gt; 命令磁盘空间&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            489M     0  489M   0% /dev
tmpfs           100M  3.1M   97M   4% /run
/dev/xvda1      7.8G  1.9G  5.5G  26% /
tmpfs           496M     0  496M   0% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           496M     0  496M   0% /sys/fs/cgroup
tmpfs           100M     0  100M   0% /run/user/1000
/dev/xvdb        30G   44M   28G   1% /data
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>MySQL 数据导入到 Redshift</title>
      <link>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift</link>
      <pubDate>Wed, 10 May 2017 17:36:29 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift</guid>
      <description>&lt;h2 id=&#34;设计表&#34;&gt;设计表&lt;/h2&gt;

&lt;p&gt;首先是设计表结构。建表语法差别不大，有一些地方可以注意一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Redshift 貌似没有无符号类型，所以要把 unsigned 类型的字段修改成相应的 INT 或 BIGINT 类型。&lt;/li&gt;
&lt;li&gt;FLOAT 类型改成 REAL 或 FLOAT4&lt;/li&gt;
&lt;li&gt;把索引语句去掉，保留主键、外键、唯一性约束，Redshift 不会检查这些约束，但是查询时会用于优化。&lt;/li&gt;
&lt;li&gt;Redshift 的 CHAR 类型只能包含单字节 ASCII 字符，对于非 ASCII 数据需要把 CHAR 改成 VARCHAR 类型&lt;/li&gt;
&lt;li&gt;有可能 MySQL 中存的是 unicode，而 Redshift 中存的是 bytes，所以 VARCHAR 的长度也要调整，避免溢出。最简单的，可以用 MySQL 的字段长度 * 3.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于 sort key, dist key 等设计，只属于 Redshift 范畴，参考官网文档即可。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;加载数据&#34;&gt;加载数据&lt;/h2&gt;

&lt;p&gt;因为 Redshift 推荐使用 &lt;code&gt;COPY&lt;/code&gt; 命令从 S3 加载数据，所以首先得要从 MySQL 中导出数据，然后上传到 CSV.&lt;/p&gt;

&lt;p&gt;以导出 CSV 为例，需要注意使用 &lt;code&gt;&amp;quot;&lt;/code&gt; 符号作为转义字符，而不是 &lt;code&gt;\&lt;/code&gt;. 另外最好用 &lt;code&gt;&amp;quot;&lt;/code&gt; 把每个值都 wrap 起来，免得有些多行字符串导致出错。导出后可以压缩成 gzip 格式，在上传 S3 的时候可以快一些。&lt;/p&gt;

&lt;p&gt;Redshift 的 &lt;code&gt;COPY&lt;/code&gt; 例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY syns_bigdata
FROM &#39;s3://some-bucket/some_filename.csv.gz&#39;
credentials &#39;aws_access_key_id=&amp;lt;aws_access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;aws_secret_access_key&amp;gt;&#39;
region &#39;cn-north-1&#39; CSV GZIP NULL AS &#39;NULL&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;语法很简单，需要注意的有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;aws_access_key_id&lt;/code&gt; 和 &lt;code&gt;aws_secret_access_key&lt;/code&gt; 要有访问 S3 的权限&lt;/li&gt;
&lt;li&gt;指定 region&lt;/li&gt;
&lt;li&gt;指定文件格式，&lt;code&gt;CSV GZIP&lt;/code&gt; 表示是 gzip 压缩的 CSV 文件&lt;/li&gt;
&lt;li&gt;可以用 &lt;code&gt;NULL AS&lt;/code&gt; 语句指定 NULL 值&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>在 AWS 上安装 Tableau Server</title>
      <link>http://liyangliang.me/posts/2017/05/install-tableau-server-on-aws-ec2</link>
      <pubDate>Wed, 10 May 2017 17:23:55 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/install-tableau-server-on-aws-ec2</guid>
      <description>&lt;h2 id=&#34;启动-ec2-实例&#34;&gt;启动 EC2 实例&lt;/h2&gt;

&lt;p&gt;先根据 Tableau Server 的使用情况确定需要的配置，从而确定实例类型。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AMI: Microsoft Windows Server 2012 R2 Base（简体中文）&lt;/li&gt;
&lt;li&gt;类型: m4.4xlarge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动、配置步骤略去不表，有两点需要注意：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VPC 需要开启 3389 端口用于远程登录（RDP）&lt;/li&gt;
&lt;li&gt;密钥对会用于解密登录密码&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安装-tableau-server&#34;&gt;安装 Tableau Server&lt;/h2&gt;

&lt;p&gt;从 Tableau 官网下载然后安装，配置、激活过程比较简单，略去不表。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;可选-安装-mysql-驱动&#34;&gt;（可选）安装 MySQL 驱动&lt;/h2&gt;

&lt;p&gt;在 &lt;a href=&#34;https://www.tableau.com/zh-cn/support/drivers&#34;&gt;这个页面&lt;/a&gt;可以找到所有数据源需要的驱动程序.&lt;/p&gt;

&lt;p&gt;下载好驱动程序，如 mysql-connector-odbc-5.3.7-winx64.msi，双击安装，提示错误。搜索了一番，应该是缺少 Visual C++ 的运行库。试过 Visual C++ Redistributable for Visual Studio 2012 Update 4 和 Visual C++ Redistributable Packages for Visual Studio 2013，最后发现后者才有用。&lt;/p&gt;

&lt;p&gt;安装完 &lt;a href=&#34;https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=40784&#34;&gt;Visual C++ Redistributable Packages for Visual Studio 2013&lt;/a&gt; 之后，可以成功安装mysql-connector-odbc-5.3.7-winx64.msi 。&lt;/p&gt;

&lt;h2 id=&#34;安装-aws-命令行程序&#34;&gt;安装 AWS 命令行程序&lt;/h2&gt;

&lt;p&gt;从这里下载：&lt;a href=&#34;https://s3.amazonaws.com/aws-cli/AWSCLI64.msi&#34;&gt;https://s3.amazonaws.com/aws-cli/AWSCLI64.msi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装完后打开 cmd，运行 &lt;code&gt;aws configure&lt;/code&gt; 进行配置，要有上传 S3 的权限。完成后可以运行 &lt;code&gt;aws s3 ls&lt;/code&gt; 验证。&lt;/p&gt;

&lt;h2 id=&#34;编写备份脚本&#34;&gt;编写备份脚本&lt;/h2&gt;

&lt;p&gt;自动备份并且把备份文件上传到 S3。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@echo OFF
set Binpath=&amp;quot;C:\Program Files\Tableau\Tableau Server\10.2\bin&amp;quot;
set Backuppath=&amp;quot;C:\Backups\Tablea Server\nightly&amp;quot;
echo %date% %time%: *** Housekeeping started ***

rmdir %Backuppath% /S /Q

%Binpath%\tabadmin backup %Backuppath%\ts_backup -d --no-config
timeout 5

%Binpath%\tabadmin cleanup

echo %date% %time%: Uploading to S3

aws s3 cp %Backuppath% s3://tableau-server-backup/ --recursive --exclude &amp;quot;*&amp;quot; --include &amp;quot;ts_backup-*.tsbak&amp;quot;

echo %date% %time%: *** Housekeeping completed ***
timeout 5
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;从备份恢复&#34;&gt;从备份恢复&lt;/h2&gt;

&lt;p&gt;如果是从其他的 Tableau Server 迁移过来，可以使用备份文件迁移数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Users\Administrator&amp;gt;&amp;quot;C:\Program Files\Tableau\Tableau Server\10.2\bin\tabadmi
n.bat&amp;quot; restore --no-config Downloads\ts_backup-2017-04-05.tsbak
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;restore 操作会关闭 Tableau Server，恢复完成后需要手动开启。&lt;/p&gt;

&lt;h2 id=&#34;自动备份&#34;&gt;自动备份&lt;/h2&gt;

&lt;p&gt;使用 Task Scheduler 实现，详情见官方文档：&lt;a href=&#34;http://technet.microsoft.com/en-us/library/cc766428.aspx&#34;&gt;http://technet.microsoft.com/en-us/library/cc766428.aspx&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Python 多进程导入数据到 MySQL</title>
      <link>http://liyangliang.me/posts/2017/02/load-data-into-mysql-using-python-multiprocessing</link>
      <pubDate>Sat, 25 Feb 2017 16:16:14 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/02/load-data-into-mysql-using-python-multiprocessing</guid>
      <description>&lt;p&gt;前段时间帮同事处理了一个把 CSV 数据导入到 MySQL 的需求。两个很大的 CSV 文件，
分别有 3GB、2100 万条记录和 7GB、3500 万条记录。对于这个量级的数据，用简单的单进程／单线程导入
会耗时很久，最终用了多进程的方式来实现。具体过程不赘述，记录一下几个要点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;批量插入而不是逐条插入&lt;/li&gt;
&lt;li&gt;为了加快插入速度，先不要建索引&lt;/li&gt;
&lt;li&gt;生产者和消费者模型，主进程读文件，多个 worker 进程执行插入&lt;/li&gt;
&lt;li&gt;注意控制 worker 的数量，避免对 MySQL 造成太大的压力&lt;/li&gt;
&lt;li&gt;注意处理脏数据导致的异常&lt;/li&gt;
&lt;li&gt;原始数据是 GBK 编码，所以还要注意转换成 UTF-8&lt;/li&gt;
&lt;li&gt;用 &lt;a href=&#34;http://click.pocoo.org/5/&#34;&gt;click&lt;/a&gt; 封装命令行工具&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;具体的代码实现如下：&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
# -*- coding: utf-8 -*-

import codecs
import csv
import logging
import multiprocessing
import os
import warnings

import click
import MySQLdb
import sqlalchemy

warnings.filterwarnings(&#39;ignore&#39;, category=MySQLdb.Warning)

# 批量插入的记录数量
BATCH = 5000

DB_URI = &#39;mysql://root@localhost:3306/example?charset=utf8&#39;

engine = sqlalchemy.create_engine(DB_URI)


def get_table_cols(table):
    sql = &#39;SELECT * FROM `{table}` LIMIT 0&#39;.format(table=table)
    res = engine.execute(sql)
    return res.keys()


def insert_many(table, cols, rows, cursor):
    sql = &#39;INSERT INTO `{table}` ({cols}) VALUES ({marks})&#39;.format(
            table=table,
            cols=&#39;, &#39;.join(cols),
            marks=&#39;, &#39;.join([&#39;%s&#39;] * len(cols)))
    cursor.execute(sql, *rows)
    logging.info(&#39;process %s inserted %s rows into table %s&#39;, os.getpid(), len(rows), table)


def insert_worker(table, cols, queue):
    rows = []
    # 每个子进程创建自己的 engine 对象
    cursor = sqlalchemy.create_engine(DB_URI)
    while True:
        row = queue.get()
        if row is None:
            if rows:
                insert_many(table, cols, rows, cursor)
            break

        rows.append(row)
        if len(rows) == BATCH:
            insert_many(table, cols, rows, cursor)
            rows = []


def insert_parallel(table, reader, w=10):
    cols = get_table_cols(table)

    # 数据队列，主进程读文件并往里写数据，worker 进程从队列读数据
    # 注意一下控制队列的大小，避免消费太慢导致堆积太多数据，占用过多内存
    queue = multiprocessing.Queue(maxsize=w*BATCH*2)
    workers = []
    for i in range(w):
        p = multiprocessing.Process(target=insert_worker, args=(table, cols, queue))
        p.start()
        workers.append(p)
        logging.info(&#39;starting # %s worker process, pid: %s...&#39;, i + 1, p.pid)

    dirty_data_file = &#39;./{}_dirty_rows.csv&#39;.format(table)
    xf = open(dirty_data_file, &#39;w&#39;)
    writer = csv.writer(xf, delimiter=reader.dialect.delimiter)

    for line in reader:
        # 记录并跳过脏数据: 键值数量不一致
        if len(line) != len(cols):
            writer.writerow(line)
            continue

        # 把 None 值替换为 &#39;NULL&#39;
        clean_line = [None if x == &#39;NULL&#39; else x for x in line]

        # 往队列里写数据
        queue.put(tuple(clean_line))
        if reader.line_num % 500000 == 0:
            logging.info(&#39;put %s tasks into queue.&#39;, reader.line_num)

    xf.close()

    # 给每个 worker 发送任务结束的信号
    logging.info(&#39;send close signal to worker processes&#39;)
    for i in range(w):
        queue.put(None)

    for p in workers:
        p.join()


def convert_file_to_utf8(f, rv_file=None):
    if not rv_file:
        name, ext = os.path.splitext(f)
        if isinstance(name, unicode):
            name = name.encode(&#39;utf8&#39;)
        rv_file = &#39;{}_utf8{}&#39;.format(name, ext)
    logging.info(&#39;start to process file %s&#39;, f)
    with open(f) as infd:
        with open(rv_file, &#39;w&#39;) as outfd:
            lines = []
            loop = 0
            chunck = 200000
            first_line = infd.readline().strip(codecs.BOM_UTF8).strip() + &#39;\n&#39;
            lines.append(first_line)
            for line in infd:
                clean_line = line.decode(&#39;gb18030&#39;).encode(&#39;utf8&#39;)
                clean_line = clean_line.rstrip() + &#39;\n&#39;
                lines.append(clean_line)
                if len(lines) == chunck:
                    outfd.writelines(lines)
                    lines = []
                    loop += 1
                    logging.info(&#39;processed %s lines.&#39;, loop * chunck)

            outfd.writelines(lines)
            logging.info(&#39;processed %s lines.&#39;, loop * chunck + len(lines))


@click.group()
def cli():
    logging.basicConfig(level=logging.INFO,
                        format=&#39;%(asctime)s - %(levelname)s - %(name)s - %(message)s&#39;)


@cli.command(&#39;gbk_to_utf8&#39;)
@click.argument(&#39;f&#39;)
def convert_gbk_to_utf8(f):
    convert_file_to_utf8(f)


@cli.command(&#39;load&#39;)
@click.option(&#39;-t&#39;, &#39;--table&#39;, required=True, help=&#39;表名&#39;)
@click.option(&#39;-i&#39;, &#39;--filename&#39;, required=True, help=&#39;输入文件&#39;)
@click.option(&#39;-w&#39;, &#39;--workers&#39;, default=10, help=&#39;worker 数量，默认 10&#39;)
def load_fac_day_pro_nos_sal_table(table, filename, workers):
    with open(filename) as fd:
        fd.readline()   # skip header
        reader = csv.reader(fd)
        insert_parallel(table, reader, w=workers)


if __name__ == &#39;__main__&#39;:
    cli()
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>在 Flask 项目的 celery 中使用 gevent</title>
      <link>http://liyangliang.me/posts/2016/05/using-celery-with-flask-and-gevent</link>
      <pubDate>Tue, 17 May 2016 16:42:37 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/05/using-celery-with-flask-and-gevent</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://liyangliang.me/posts/2015/11/using-celery-with-flask/&#34;&gt;在 Flask 项目中使用 Celery&lt;/a&gt; 这篇文章谈到了如何在 Flask 项目中集成 Celery，也讲了在 celery 任务中引用 Flask 的 application context 的方法。一般情况下那样使用是没问题的，但是如果需要在 task 中使用 gevent，就需要一些额外的改进。至少有两点。&lt;/p&gt;

&lt;h2 id=&#34;1-使用-gevent-并发模型&#34;&gt;1. 使用 gevent 并发模型&lt;/h2&gt;

&lt;p&gt;如果在 task 中要使用 gevent，就必须使用 gevent 并发模型。这很好处理，只需要修改启动选项就行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ celery worker -A celery_worker.celery -P gevent -c 10 -l INFO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令，&lt;code&gt;-P&lt;/code&gt; 选项指定 pool，默认是 prefork，这里是 gevent; &lt;code&gt;-c&lt;/code&gt; 设置并发数。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;2-引用-flask-的-application-context&#34;&gt;2. 引用 Flask 的 application context&lt;/h2&gt;

&lt;p&gt;这个问题也是在 &lt;a href=&#34;http://liyangliang.me/posts/2015/11/using-celery-with-flask/&#34;&gt;在 Flask 项目中使用 Celery&lt;/a&gt; 中重点讨论的，在这种场景下，上文的解决方法起不到作用，仍然会报错（具体原因不太懂，知道的朋友请不吝赐教）。解决方案就是，把需要引用 Flask app 的地方（如 app.config），放到 Flask 的 application context 里执行，如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;with app.app_context():
    print app.config.get(&#39;SOME_CONFIG_KEY&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在实际应用中，我最后写了个装饰器来实现这个目的。简单介绍一下场景，项目用到了 Flask-Cache，项目启动时会创建全局单例 &lt;code&gt;cache&lt;/code&gt;，并在 &lt;code&gt;create_app&lt;/code&gt; 中进行初始化。在 Flask-Cache 初始化时，会把当前的 Flask app 对象绑定到实例 &lt;code&gt;cache&lt;/code&gt; 中，所以可以尝试从这里获取 app 对象。&lt;/p&gt;

&lt;p&gt;代码的目录结构与之前一样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── README.md
├── app
│   ├── __init__.py
│   ├── config.py
│   ├── forms
│   ├── models
│   ├── tasks
│   │   ├── __init__.py
│   │   └── email.py
│   └── views
│   │   ├── __init__.py
│   │   └── account.py
├── celery_worker.py
├── manage.py
└── wsgi.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;装饰器：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def with_app_context(task):
    memo = {&#39;app&#39;: None}

    @functools.wraps(task)
    def _wrapper(*args, **kwargs):
        if not memo[&#39;app&#39;]:
            try:
                # 尝试从 cache 中获取 app 对象，如果得到的不是 None，就不需要重复创建了
                app = cache.app
                _ = app.name
            except Exception:
                from app import create_app

                app = create_app()
            memo[&#39;app&#39;] = app
        else:
            app = memo[&#39;app&#39;]

        # 把 task 放到 application context 环境中运行
        with app.app_context():
            return task(*args, **kwargs)

    return _wrapper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@celery.task()
@with_app_context
def add(x, y):
    print app.config.get(&#39;SOME_CONFIG_KEY&#39;)
    return x + y
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>MongoDB Replica Set 重新同步</title>
      <link>http://liyangliang.me/posts/2016/04/mongodb-replica-set-resync</link>
      <pubDate>Fri, 15 Apr 2016 11:47:00 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/04/mongodb-replica-set-resync</guid>
      <description>&lt;p&gt;生产环境上用了 MongoDB，三个节点组成的 ReplicaSet（复制集）。部署好后，应用一直没出过问题，所以平时也没管过。今天早上突然想上服务器看看，于是登录了 primary 节点查看日志，发现这条日志不断重复：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016-04-15T03:02:39.470+0000 W NETWORK  [ReplExecNetThread-28676] Failed to connect to 172.31.168.48:11102, reason: errno:111 Connection refused
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实就是有个 secondary 节点一直连接不上。不太可能是网络问题，所以很可能是那个节点的 mongod 进程挂掉了。登录上 secondary 节点，mongod 进程果然不在运行；查看日志发现最后一条是在 2016-03-21. 一时间有两个疑问涌上心头：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么会挂掉？&lt;/li&gt;
&lt;li&gt;如何修复？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;当务之急是先修复集群，这一点官方文档有说明：&lt;a href=&#34;https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/&#34;&gt;Resync a Member of a Replica Set&lt;/a&gt;. 其实就是删除数据文件，然后通过 initial sync 来重新同步。有两种 initial sync 的方式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;清空数据目录，重启 mongod 实例，让MongoDB进行正常的初始化同步。这是个简单的方式，但是耗时较长。&lt;/li&gt;
&lt;li&gt;为该机器从其他节点上复制一份最近的数据文件，并重启。操作步骤较多，但是最为快速。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;考虑到数据量并没有很多，所以决定使用第一种比较简单的方式。重启好后，发现数据目录很快就新建了很多文件。和 primary 节点对比，文件名和大小均一致；primary 节点和另一个 secondary 节点也不再出现连接失败的日志。&lt;/p&gt;

&lt;p&gt;遗憾的是，挂掉的原因却一直没有找到。日志文件里没有发现异常，&lt;code&gt;history&lt;/code&gt; 也没发现有 &lt;code&gt;kill&lt;/code&gt; 的记录。
幸运的是，集群很快就恢复了，应用不受影响，数据也没丢失。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nginx AWS ELB 域名解析</title>
      <link>http://liyangliang.me/posts/2016/04/nginx-aws-elb-name-resolution</link>
      <pubDate>Thu, 14 Apr 2016 15:33:52 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/04/nginx-aws-elb-name-resolution</guid>
      <description>&lt;p&gt;最近生产环境上出现了一个奇怪的问题。某日下午，APP 向某个域名发出的所有请求没有响应，服务端也没收到请求；而向另一个域名的请求却没有问题。先记录一下背景：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;两个域名：api.example.com, web.example.com&lt;/li&gt;
&lt;li&gt;环境：AWS + ELB + Nginx&lt;/li&gt;
&lt;li&gt;后端：Python + Django + Gunicorn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;出问题的是 api.example.com （下文简称 API）这个域名，所以 web.example.com 就不细说。由于一些历史原因，API 的请求链路大概是这样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                      proxy_pass         backends                      proxy_pass
APP -----&amp;gt; API Nginx -------------&amp;gt; ELB -----------&amp;gt; Backend Nginx(s) ------------&amp;gt; Gunicorn(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 API 的 Nginx 配置大概是这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;location /test {
    proxy_pass http://name.of.elb.aws.com;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;文章开头描述的现象就是，在 API 的 Nginx 能看到 access log，但是 Backend 的 Nginx 没有接收到请求。所以问题可能出在代理这一步。奇怪的地方在于，刚上线时一切正常，运行了一段时间后才突然出现。猜测有可能是 DNS 解析的问题，但没有根据，也不知道如何解决。&lt;/p&gt;

&lt;p&gt;后来 Google 了一番，发现确实是 DNS 的问题。Nginx 会在启动的时候进行域名查找，然后把 IP 地址缓存起来，后续就直接使用这些 IP 地址。而 AWS 的 ELB 所指向的 IP 地址是不固定的，会经常更新；所以这会导致 Nginx 缓存的 IP 地址实际上已经失效。定位出了问题，也参考网上的做法，把 API 的 Nginx 配置稍作修改：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;location /test {
    resolver 233.5.5.5 valid=30s;
    proxy_pass http://name.of.elb.aws.com;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;a href=&#34;http://nginx.org/en/docs/http/ngx_http_core_module.html#resolver&#34;&gt;resolver&lt;/a&gt; 就是 Nginx 用于把域名转换为 IP 地址的域名服务器。后面的第一个参数是域名服务器，valid 指定了缓存有效期，这里是 30s （默认 5min）. 加上这个配置后，Nginx 会用指定的域名服务器来解析域名，并定期把缓存失效。这样就能避免 ELB 地址更新带来的问题。&lt;/p&gt;

&lt;p&gt;刚开始以为只需要加上 resolver 这一行配置就可以，后来看 &lt;a href=&#34;[http://serverfault.com/a/562518/192152&#34;&gt;这个 serverfault 上的回答&lt;/a&gt;，还需要把 proxy_pass 的地址定义成一个变量。于是最终的配置变成了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;location /test {
    resolver 233.5.5.5 valid=30s;
    set $backends &amp;quot;http://name.of.elb.aws.com&amp;quot;;
    proxy_pass $backends;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改配置，reload，一两天后如果无响应的现象不再出现，说明问题已经解决。&lt;/p&gt;

&lt;p&gt;参考材料：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nginx.org/en/docs/http/ngx_http_core_module.html#resolver&#34;&gt;Nginx 文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tenzer.dk/nginx-with-dynamic-upstreams/&#34;&gt;Nginx with dynamic upstreams&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gc-taylor.com/blog/2011/11/10/nginx-aws-elb-name-resolution-resolvers&#34;&gt;nginx AWS ELB name resolution with resolvers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://serverfault.com/questions/560632/some-nginx-reverse-proxy-configs-stops-working-once-a-day&#34;&gt;serverfault - Some nginx reverse proxy configs stops working once a day&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>zhihu-go 源码解析：用 goquery 解析 HTML</title>
      <link>http://liyangliang.me/posts/2016/03/zhihu-go-insight-parsing-html-with-goquery</link>
      <pubDate>Wed, 30 Mar 2016 23:02:51 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/03/zhihu-go-insight-parsing-html-with-goquery</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://liyangliang.me/posts/2016/03/zhihu-go/&#34;&gt;上一篇博客&lt;/a&gt; 简单介绍了 &lt;a href=&#34;https://github.com/DeanThompson/zhihu-go&#34;&gt;zhihu-go&lt;/a&gt; 项目的缘起，本篇简单介绍一下关于处理 HTML 的细节。&lt;/p&gt;

&lt;p&gt;因为知乎没有开发 API，所以只能通过模拟浏览器操作的方式获取数据，这些数据有两种格式：普通的 HTML 文档和某些 Ajax 接口返回的 JSON（返回的数据实际上也是 HTML）。其实也就是爬虫了，抓取网页，然后提取数据。一般来说从 HTML 文档提取数据有这些做法：正则、XPath、CSS 选择器等。对我来说，正则写起来比较复杂，代码可读性差而且维护起来麻烦；XPath 没有详细了解，不过用起来应该不难，而且 Chrome 浏览器可以直接提取 XPath. zhihu-go 里用的是选择器的方式，使用了 &lt;a href=&#34;https://github.com/PuerkitoBio/goquery&#34;&gt;goquery&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;goquery 是 &amp;ldquo;a little like that j-thing, only in Go&amp;rdquo;，也就是用 jQuery 的方式去操作 DOM. jQuery 大家都很熟，API 也很简单明了。本文不详细介绍 goquery，下面选几个场景（API）讲讲在 zhihu-go 里的应用。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建-document-对象&#34;&gt;创建 Document 对象&lt;/h3&gt;

&lt;p&gt;goquery 暴露了两个结构体：&lt;code&gt;Document&lt;/code&gt; 和 &lt;code&gt;Selection&lt;/code&gt;. &lt;code&gt;Document&lt;/code&gt; 表示一个 HTML 文档，&lt;code&gt;Selection&lt;/code&gt; 用于像 jQuery 一样操作，支持链式调用。goquery 需要指定一个 HTML 文档才能继续后续的操作，有以下几个构造方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NewDocumentFromNode(root *html.Node) *Document&lt;/code&gt;: 传入 &lt;code&gt;*html.Node&lt;/code&gt; 对象，也就是根节点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NewDocument(url string) (*Document, error)&lt;/code&gt;: 传入 URL，内部用 &lt;code&gt;http.Get&lt;/code&gt; 获取网页。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NewDocumentFromReader(r io.Reader) (*Document, error)&lt;/code&gt;: 传入 &lt;code&gt;io.Reader&lt;/code&gt;，内部从 reader 中读取内容并解析。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NewDocumentFromResponse(res *http.Response) (*Document, error)&lt;/code&gt;: 传入 HTTP 响应，内部拿到 &lt;code&gt;res.Body&lt;/code&gt;(实现了 &lt;code&gt;io.Reader&lt;/code&gt;) 后的处理方式类似 &lt;code&gt;NewDocumentFromReader&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为知乎的页面需要登录才能访问（还需要伪造请求头），而且我们并不想手动解析 HTML 来获取 &lt;code&gt;*html.Node&lt;/code&gt;，最后用到了另外两个构造方法。大致的使用场景是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;请求 HTML 页面（如问题页面），调用 &lt;code&gt;NewDocumentFromResponse&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;请求 Ajax 接口，返回的 JSON 数据里是一些 HTML 片段，用 &lt;code&gt;NewDocumentFromReader&lt;/code&gt;，其中 &lt;code&gt;r = strings.NewReader(html)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了方便举例说明，下文采用这个定义: &lt;code&gt;var doc *goquery.Document&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;查找到指定节点&#34;&gt;查找到指定节点&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;Selection&lt;/code&gt; 有一系列类似 jQuery 的方法，&lt;code&gt;Document&lt;/code&gt; 结构体内嵌了 &lt;code&gt;*Selection&lt;/code&gt;，因此也能直接调用这些方法。主要的方法是 &lt;code&gt;Selection.Find(selector string)&lt;/code&gt;，传入一个选择器，返回一个新的，匹配到的 &lt;code&gt;*Selection&lt;/code&gt;，所以能够链式调用。&lt;/p&gt;

&lt;p&gt;比如在用户主页（如 &lt;a href=&#34;https://www.zhihu.com/people/jixin&#34;&gt;黄继新&lt;/a&gt;），要获取用户的 BIO. 首先用 Chrome 定位到对应的 HTML：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;span class=&amp;quot;bio&amp;quot; title=&amp;quot;和知乎在一起&amp;quot;&amp;gt;和知乎在一起&amp;lt;/span&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对应的 go 代码就是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;doc.Find(&amp;quot;span.bio&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果一个选择器对应多个结果，可以使用 &lt;code&gt;First()&lt;/code&gt;, &lt;code&gt;Last()&lt;/code&gt;, &lt;code&gt;Eq(index int)&lt;/code&gt;, &lt;code&gt;Slice(start, end int)&lt;/code&gt; 这些方法进一步定位。&lt;/p&gt;

&lt;p&gt;还是在用户主页，在用户资料栏的底下，从左往右展示了提问数、回答数、文章数、收藏数和公共编辑的次数。查看 HTML 源码后发现这几项的 class 是一样的，所以只能通过下标索引来区分。&lt;/p&gt;

&lt;p&gt;先看 HTML 源码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;div class=&amp;quot;profile-navbar clearfix&amp;quot;&amp;gt;
&amp;lt;a class=&amp;quot;item &amp;quot; href=&amp;quot;/people/jixin/asks&amp;quot;&amp;gt;提问&amp;lt;span class=&amp;quot;num&amp;quot;&amp;gt;1336&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;
&amp;lt;a class=&amp;quot;item &amp;quot; href=&amp;quot;/people/jixin/answers&amp;quot;&amp;gt;回答&amp;lt;span class=&amp;quot;num&amp;quot;&amp;gt;785&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;
&amp;lt;a class=&amp;quot;item &amp;quot; href=&amp;quot;/people/jixin/posts&amp;quot;&amp;gt;文章&amp;lt;span class=&amp;quot;num&amp;quot;&amp;gt;91&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;
&amp;lt;a class=&amp;quot;item &amp;quot; href=&amp;quot;/people/jixin/collections&amp;quot;&amp;gt;收藏&amp;lt;span class=&amp;quot;num&amp;quot;&amp;gt;44&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;
&amp;lt;a class=&amp;quot;item &amp;quot; href=&amp;quot;/people/jixin/logs&amp;quot;&amp;gt;公共编辑&amp;lt;span class=&amp;quot;num&amp;quot;&amp;gt;51648&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果要定位找到回答数，对应的 go 代码是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;doc.Find(&amp;quot;div.profile-navbar&amp;quot;).Find(&amp;quot;span.num&amp;quot;).Eq(1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;属性操作&#34;&gt;属性操作&lt;/h3&gt;

&lt;p&gt;经常需要获取一个标签的内容和某些属性值，使用 goquery 可以很容易做到。&lt;/p&gt;

&lt;p&gt;继续上面获取回答数的例子，用 &lt;code&gt;Text() string&lt;/code&gt; 方法可以获取标签内的文本内容，其中包含所有子标签。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;text := doc.Find(&amp;quot;div.profile-navbar&amp;quot;).Find(&amp;quot;span.num&amp;quot;).Eq(1).Text()    // &amp;quot;785&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要注意的是，&lt;code&gt;Text()&lt;/code&gt; 方法返回的字符串，可能前后有很多空白字符，可以视情况做清除。&lt;/p&gt;

&lt;p&gt;获取属性值也很容易，有两个方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Attr(attrName string) (val string, exists bool)&lt;/code&gt;: 返回属性值和该属性是否存在，类似从 &lt;code&gt;map&lt;/code&gt; 中取值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AttrOr(attrName, defaultValue string) string&lt;/code&gt;: 和上一个方法类似，区别在于如果属性不存在，则返回给定的默认值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;常见的使用场景就是获取一个 a 标签的链接。继续上面获取回答的例子，如果想要得到用户回答的主页，可以这么做：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;href, _ := doc.Find(&amp;quot;div.profile-navbar&amp;quot;).Find(&amp;quot;a.item&amp;quot;).Eq(1).Attr(&amp;quot;href&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还有其他设置属性、操作 class 的方法，就不展开讨论了。&lt;/p&gt;

&lt;h3 id=&#34;迭代&#34;&gt;迭代&lt;/h3&gt;

&lt;p&gt;很多场景需要返回列表数据，比如问题的关注者列表、所有回答，某个答案的点赞的用户列表等。这种情况下一般需要用到迭代，遍历所有的同类节点，做某些操作。&lt;/p&gt;

&lt;p&gt;goquery 提供了三个用于迭代的方法，都接受一个匿名函数作为参数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Each(f func(int, *Selection)) *Selection&lt;/code&gt;: 其中函数 &lt;code&gt;f&lt;/code&gt; 的第一个参数是当前的下标，第二个参数是当前的节点&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EachWithBreak(f func(int, *Selection) bool) *Selection&lt;/code&gt;: 和 &lt;code&gt;Each&lt;/code&gt; 类似，增加了中途跳出循环的能力，当 &lt;code&gt;f&lt;/code&gt; 返回 &lt;code&gt;false&lt;/code&gt; 时结束迭代&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Map(f func(int, *Selection) string) (result []string)&lt;/code&gt;: &lt;code&gt;f&lt;/code&gt; 的参数与上面一样，返回一个 string 类型，最终返回 []string.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;比如获取一个收藏夹（如 &lt;a href=&#34;https://www.zhihu.com/collection/19573315&#34;&gt;黄继新的收藏：关于知乎的思考&lt;/a&gt;）下所有的问题，可以这么做（见 &lt;a href=&#34;https://github.com/DeanThompson/zhihu-go/blob/master/collection.go&#34;&gt;zhihu-go/collections.go&lt;/a&gt;）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func getQuestionsFromDoc(doc *goquery.Document) []*Question {
	questions := make([]*Question, 0, pageSize)
	items := doc.Find(&amp;quot;div#zh-list-answer-wrap&amp;quot;).Find(&amp;quot;h2.zm-item-title&amp;quot;)
	items.Each(func(index int, sel *goquery.Selection) {
		a := sel.Find(&amp;quot;a&amp;quot;)
		qTitle := strip(a.Text())
		qHref, _ := a.Attr(&amp;quot;href&amp;quot;)
		thisQuestion := NewQuestion(makeZhihuLink(qHref), qTitle)
		questions = append(questions, thisQuestion)
	})
	return questions
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;EachWithBreak&lt;/code&gt; 在 zhihu-go 中也有用到，可以参见 &lt;code&gt;Answer.GetVotersN 方法&lt;/code&gt;：&lt;a href=&#34;https://github.com/DeanThompson/zhihu-go/blob/master/answer.go&#34;&gt;zhihu-go/answer.go&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;删除节点-插入-html-导出-html&#34;&gt;删除节点、插入 HTML、导出 HTML&lt;/h3&gt;

&lt;p&gt;有一个需求是把回答内容输出到 HTML，说白了其实就是修复和清洗 HTML，具体的细节可以看 &lt;a href=&#34;https://github.com/DeanThompson/zhihu-go/blob/master/answer.go#L222&#34;&gt;answer.go 里的 answerSelectionToHtml 函数&lt;/a&gt;. 其中用到了一些需要修改文档的操作。&lt;/p&gt;

&lt;p&gt;比如，调用 &lt;code&gt;Remove()&lt;/code&gt; 方法把一个节点删掉：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;sel.Find(&amp;quot;noscript&amp;quot;).Each(func(_ int, tag *goquery.Selection) {
    tag.Remove() // 把无用的 noscript 去掉
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在节点后插入一段 HTML:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;sel.Find(&amp;quot;img&amp;quot;).Each(func(_ int, tag *goquery.Selection) {
    var src string
    if tag.HasClass(&amp;quot;origin_image&amp;quot;) {
        src, _ = tag.Attr(&amp;quot;data-original&amp;quot;)
    } else {
        src, _ = tag.Attr(&amp;quot;data-actualsrc&amp;quot;)
    }
    tag.SetAttr(&amp;quot;src&amp;quot;, src)
    if tag.Next().Size() == 0 {
        tag.AfterHtml(&amp;quot;&amp;lt;br&amp;gt;&amp;quot;)   // 在 img 标签后插入一个换行
    }
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在标签尾部 append 一段内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;wrapper := `&amp;lt;html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;`
doc, _ := goquery.NewDocumentFromReader(strings.NewReader(wrapper))
doc.Find(&amp;quot;body&amp;quot;).AppendSelection(sel)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终输出为 html 文档：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;html, err := doc.Html()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;上面的例子基本涵盖了 zhihu-go 中关于 HTML 操作的场景，得益于 goquery 和 jQuery 的 API 风格，实现起来还是非常简单的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zhihu-go: 知乎非官方 API库 with Go</title>
      <link>http://liyangliang.me/posts/2016/03/zhihu-go</link>
      <pubDate>Mon, 28 Mar 2016 23:35:58 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2016/03/zhihu-go</guid>
      <description>&lt;p&gt;我是知乎重度用户，每天都会花点时间在知乎上面看点东西。有段时间时间线里经常出现爬虫相关的话题，也看到不少直接爬知乎信息的项目；其中一个就是 &lt;a href=&#34;https://github.com/egrcc/zhihu-python&#34;&gt;zhihu-python&lt;/a&gt;. 实际上 zhihu-python 不是一个完整的爬虫，正如其文档说明的那样，是一个 API 库，可以基于这些 API 实现一个爬虫应用。zhihu-python 实现了用户、问题、答案、收藏夹相关的信息获取类 API，对于大多数信息获取的目的已经足够。这个项目很受欢迎，然而说实话，代码质量一般，不过思路值得借鉴。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;恰巧我也是一个 &lt;a href=&#34;http://golang.org/&#34;&gt;Go 语言&lt;/a&gt; 爱好者，在之前的工作中也用 Go 写过项目。语法简单，开发效率高，性能很好。GitHub 上搜了一下，zhihu-python 或同类项目，并没有一个 Go 实现的版本。于是就想动手造个轮子，把 zhihu-python 移植到 Go，所以就有了标题里提到的 &lt;a href=&#34;https://github.com/DeanThompson/zhihu-go&#34;&gt;zhihu-go&lt;/a&gt;. 主要是出于练手的目的，最近一年都在做 Python 开发，Go 还有点生疏了。因为是移植，最初的设计和实现思路很大程度上参考或模仿了 zhihu-python，后来在开发过程中，新增了一些 API，也删除了少数几个我认为没什么用的 API. 开发过程中又看到了一个 Python 3 版本的实现 &lt;a href=&#34;https://github.com/7sDream/zhihu-py3&#34;&gt;zhihu-py3&lt;/a&gt;，这个库也是受启发于 zhihu-python，代码质量也要更好，而且实现了更丰富的 API，尤其是关于操作类的，如点赞、收藏答案等。zhihu-go 也参考了 zhihu-py3 的一些 API 设计。截止到现在，zhihu-go 的完成度应该和 zhihu-python 差不多，还多了一些 API；比 zhihu-py3 少了活动、评论及操作类的 API，这些在 TODO list 都列了出来。&lt;/p&gt;

&lt;p&gt;前几天在 V2EX 发了一个 &lt;a href=&#34;http://v2ex.com/t/266372&#34;&gt;推广的帖子&lt;/a&gt;，没想到反响还不错，收到不少支持和鼓励，GitHub 也在一两天内收获了 50 来个 star （个人最高）. 其实在这之前，还在 StuduGolang 发了 &lt;a href=&#34;http://studygolang.com/topics/1528&#34;&gt;一个主题&lt;/a&gt;，然而并没有人回复，带到 GitHub 的流量也很少，好像只有 1 个 star. golangtc 也发了，流量就更少了，可以忽略不计。&lt;/p&gt;

&lt;p&gt;后续有时间简单分析一下源码，分享一下开发过程和心得。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
