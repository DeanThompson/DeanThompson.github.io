<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>李林克斯 on 李林克斯 </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://liyangliang.me/</link>
    <language>zh-CN</language>
    <author>Yangliang Li</author>
    
    <updated>Fri, 11 Oct 2019 14:09:28 CST</updated>
    
    <item>
      <title>Impala 添加和使用 UDF</title>
      <link>http://liyangliang.me/posts/2019/10/impala-udf/</link>
      <pubDate>Fri, 11 Oct 2019 14:09:28 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/10/impala-udf/</guid>
      <description>&lt;p&gt;Impala 支持 C++ 和 Java 编写的 UDF, 把对应的 so 或 jar 文件放到 HDFS，再注册一下就能使用。官方推荐使用 C++ 编写 UDF，相比 Java 的实现有 10 倍性能提升。Hive 有丰富的函数，可以添加到 Impala 里。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先在 HDFS 创建目录保存 UDF 文件，并把 Hive 的 jar 包上传进去&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;hdfs dfs -mkdir /user/hive/udfs

hdfs dfs -copyFromLocal /opt/cloudera/parcels/CDH/lib/hive/lib/hive-exec-1.1.0-cdh5.14.2.jar /user/hive/udfs/hive-builtins.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;进入 Impala 注册函数&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE DATABASE udfs;

CREATE FUNCTION udfs.f_get_json_object(STRING, STRING) RETURNS STRING LOCATION &#39;/user/hive/udfs/hive-builtins.jar&#39; SYMBOL=&#39;org.apache.hadoop.hive.ql.udf.UDFJson&#39;;

REFRESH FUNCTIONS udfs;

SHOW FUNCTIONS IN udfs;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;使用&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;SELECT id,
       udfs.f_get_json_object(user_info, &#39;$.city&#39;) AS user_city
       user_info
FROM user
LIMIT 100
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;删除&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;DROP FUNCTION IF EXISTS udfs.f_get_json_object(STRING, STRING)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/5-14-x/topics/impala_udf.html&#34;&gt;Impala User-Defined Functions (UDFs)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF&#34;&gt;Hive Operators and User-Defined Functions (UDFs)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/5-14-x/topics/impala_drop_function.html&#34;&gt;DROP FUNCTION Statement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudera/impala-udf-samples&#34;&gt;cloudera/impala-udf-samples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>HDFS 异构存储调研</title>
      <link>http://liyangliang.me/posts/2019/05/hdfs-heterogeneous-storage/</link>
      <pubDate>Tue, 07 May 2019 15:47:04 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/05/hdfs-heterogeneous-storage/</guid>
      <description>&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;HDFS 支持配置多个数据目录，同一节点默认按照 Round Robin 策略写入。硬盘不做 RAID，每块盘单独挂载。&lt;/li&gt;
&lt;li&gt;HDFS 支持异构存储，即不同的存储类型和存储策略，可用于实现冷热分级，从而降低成本&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;存储类型&#34;&gt;存储类型&lt;/h2&gt;

&lt;p&gt;按访问速度降序：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RAM_DISK: 即内存&lt;/li&gt;
&lt;li&gt;SSD: SSD，OLTP 类场景（如 HBase）可以考虑使用&lt;/li&gt;
&lt;li&gt;DISK: 普通硬盘&lt;/li&gt;
&lt;li&gt;ARCHIVE: 归档存储，可使用廉价、高容量存储（甚至单机超百 T）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;存储策略&#34;&gt;存储策略&lt;/h2&gt;

&lt;p&gt;共有 6 种策略&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hot&lt;/strong&gt;: 即通常意义的热数据，需要经常使用。所有副本都存在 DISK. &lt;strong&gt;这是默认的策略。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cold&lt;/strong&gt;: 即通常意义的冷数据，很少使用，主要是归档备份。所有副本都存在 ARCHIVE.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Warm&lt;/strong&gt;: 介于冷热之间。一个副本放 DISK，其余的放 ARCHIVE.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;All_SSD&lt;/strong&gt;: 所有副本都在 SSD.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One_SSD&lt;/strong&gt;: 一个副本在 SSD，其余的放 DISK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lazy_Persist&lt;/strong&gt;: 适用于单副本数据，放在内存。先写到 RAM_DISK, 再持久化到 DISK.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;按访问速度从快到慢排列&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;策略&lt;/th&gt;
&lt;th&gt;块分布&lt;/th&gt;
&lt;th&gt;creationFallbacks&lt;/th&gt;
&lt;th&gt;replicationFallbacks&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Lazy_Persist&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;RAM_DISK: 1, DISK: n-1&lt;/td&gt;
&lt;td&gt;DISK&lt;/td&gt;
&lt;td&gt;DISK&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;All_SSD&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;SSD: n&lt;/td&gt;
&lt;td&gt;DISK&lt;/td&gt;
&lt;td&gt;DISK&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;One_SSD&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;SSD: 1, DISK: n-1&lt;/td&gt;
&lt;td&gt;SSD, DISK&lt;/td&gt;
&lt;td&gt;SSD, DISK&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Hot&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;DISK: n&lt;/td&gt;
&lt;td&gt;&amp;lt; none &amp;gt;&lt;/td&gt;
&lt;td&gt;ARCHIVE&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Warm&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;DISK: 1, ARCHIVE: n-1&lt;/td&gt;
&lt;td&gt;ARCHIVE, DISK&lt;/td&gt;
&lt;td&gt;ARCHIVE, DISK&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Cold&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;ARCHIVE: n&lt;/td&gt;
&lt;td&gt;&amp;lt; none &amp;gt;&lt;/td&gt;
&lt;td&gt;&amp;lt; none &amp;gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
&lt;p&gt;注：creationFallbacks 是对于第一个创建的 block 的 fallback 情况时的可选存储类型；replicationFallbacks 是 block 的其余副本的 fallback 情况时的可选存储类型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;配置&#34;&gt;配置&lt;/h2&gt;

&lt;p&gt;每个磁盘单独挂载到不同目录，需要注意加上 &lt;code&gt;noatime&lt;/code&gt; 选项。 首先配置 DataNode 的数据目录&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dfs.storage.policy.enabled&lt;/code&gt;: 设置为 &lt;code&gt;true&lt;/code&gt;，默认是 &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dfs.datanode.data.dir&lt;/code&gt;: 可配置多个路径，用 &lt;code&gt;,&lt;/code&gt; 分隔，每个路径加上存储类型标签作为前缀，如
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;[SSD]file:///dfs/dn1,[DISK]file:///dfs/dn2,[ARCHIVE]file:///dfs/dn3
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注: 通过 Cloudera Manager 配置不需要写 &lt;code&gt;file://&lt;/code&gt;，直接使用 &lt;code&gt;[DISK]/dfs/dn2&lt;/code&gt; 即可&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;使用 &lt;code&gt;hdfs storagepolicies&lt;/code&gt; 命令管理文件/目录的存储策略，共三个子命令。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;命令&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;hdfs storagepolicies -listPolicies&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;列出所有的块存储策略&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;hdfs storagepolicies -setStoragePolicy -path &amp;lt;path&amp;gt; -policy &amp;lt;policy&amp;gt;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;对指定路径设置存储策略，子目录会继承&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;hdfs storagepolicies -getStoragePolicy -path &amp;lt;path&amp;gt;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;获取指定路径的存储策略&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;mover&#34;&gt;Mover&lt;/h2&gt;

&lt;p&gt;Mover 是 HDFS 的一个数据迁移工具，类似 Balancer. 区别在于，Mover 的目的是把数据块按照存储策略迁移，Balancer 是在不同 DataNode 直接进行平衡。如果 DataNode 挂载了多种存储类型，Mover 优先尝试在本地迁移，避免网络 IO.&lt;/p&gt;

&lt;p&gt;使用方式: &lt;code&gt;hdfs mover -p &amp;lt;path&amp;gt;&lt;/code&gt;，如果想一次性迁移所有数据，可把 path 指定为根路径，不过需要的时间也更长。&lt;/p&gt;

&lt;h2 id=&#34;datanode-内的数据平衡&#34;&gt;DataNode 内的数据平衡&lt;/h2&gt;

&lt;p&gt;Balancer 可用于 DataNode 间数据平衡，但没法处理同一个 DataNode 内多块硬盘的分布不均衡情况。可以使用 &lt;code&gt;diskbalancer&lt;/code&gt; 命令解决。&lt;/p&gt;

&lt;p&gt;首先要开启 &lt;code&gt;dfs.disk.balancer.enabled&lt;/code&gt;，在 Cloudera Manager 上修改配置 &lt;strong&gt;HDFS Service Advanced Configuration Snippet (Safety Valve) for hdfs-site.xml&lt;/strong&gt;，设置 &lt;code&gt;dfs.disk.balancer.enabled&lt;/code&gt; 为 &lt;code&gt;true&lt;/code&gt;，重启 HDFS 生效。&lt;/p&gt;

&lt;p&gt;接下来是三部曲：plan, execute, query.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Plan 生成迁移计划&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;运行 &lt;code&gt;hdfs diskbalancer -plan &amp;lt;datanode-host&amp;gt;&lt;/code&gt;，如 &lt;code&gt;hdfs diskbalancer -plan hadoop-dn-16&lt;/code&gt;. 该命令会把计划配置以 JSON 文件输出到硬盘，具体路径看日志，以 &lt;code&gt;/system/diskbalancer/2016-Aug-19-18-04-01&lt;/code&gt; 为例。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Execute 执行迁移&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;hdfs diskbalancer -execute /system/diskbalancer/2016-Aug-17-17-03-56/172.26.10.16.plan.json&lt;/code&gt; 注意替换文件路径。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Query 查看进度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;hdfs diskbalancer -query hadoop-dn-16&lt;/code&gt; 查看进度，&lt;code&gt;PLAN_DONE&lt;/code&gt; 说明平衡结束。可用 &lt;code&gt;df -h&lt;/code&gt; 命令验证。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html&#34;&gt;Archival Storage, SSD &amp;amp; Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://issues.apache.org/jira/browse/HDFS-2832&#34;&gt;Enable support for heterogeneous storages in HDFS - DN as a collection of storages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/androidlushangderen/article/details/51105876&#34;&gt;HDFS异构存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudera.com/documentation/enterprise/5-14-x/topics/admin_heterogeneous_storage_oview.html&#34;&gt;Configuring Heterogeneous Storage in HDFS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudera.com/how-to-use-the-new-hdfs-intra-datanode-disk-balancer-in-apache-hadoop/&#34;&gt;How-to: Use the New HDFS Intra-DataNode Disk Balancer in Apache Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>一个轻量级通用的数据同步方案</title>
      <link>http://liyangliang.me/posts/2019/04/lightweight-data-sync-solution/</link>
      <pubDate>Sat, 27 Apr 2019 14:02:16 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/04/lightweight-data-sync-solution/</guid>
      <description>&lt;p&gt;在不同的数据库系统之间做数据同步是大数据领域里常见的需求。一个典型的场景是，业务系统因为需要事务和随机查询，一般会使用 MySQL 这种数据库；数据仓库使用 Hive；ETL 之后的结果再放到 MySQL、AWS Redshift 等系统给 BI 和报表工具使用。&lt;/p&gt;

&lt;p&gt;首先梳理一下需求和目标：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实时性：非实时，离线同步，一般为 T+1，或最细到小时粒度&lt;/li&gt;
&lt;li&gt;扩展性：需要支持多种异构数据源，如 MySQL, Hive, ElasticSearch 等&lt;/li&gt;
&lt;li&gt;性能要求：因为是离线系统，对性能要求无严格要求，但最好尽可能快，并有可能调优&lt;/li&gt;
&lt;li&gt;复杂度：复杂度低，依赖少，易使用，易运维&lt;/li&gt;
&lt;li&gt;功能要求：要满足全量同步和增量数据同步&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;p&gt;数据同步并不是一个特殊的问题，简化一下其实就是两个操作：读和写。与之类似的是数据库备份和恢复，很多数据库系统都自带这种工具，比如 MySQL 的 &lt;code&gt;mysqldump&lt;/code&gt; 和 &lt;code&gt;mysqlimport&lt;/code&gt;，MongoDB 的 &lt;code&gt;mongodump&lt;/code&gt; 和 &lt;code&gt;mongorestore&lt;/code&gt; 等。这些工具一般为了性能而使用特殊的编码格式，不会考虑通用性。但一个通用的数据同步系统，可以采用同样的思路来实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://i.loli.net/2019/04/27/5cc4196a589e6.png&#34; alt=&#34;pigeon_design.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图描述的就是本文的解决方案，即把读写拆分，通过 CSV 文件来过度。&lt;/p&gt;

&lt;h2 id=&#34;扩展性&#34;&gt;扩展性&lt;/h2&gt;

&lt;p&gt;这种设计的核心是把数据同步抽象成导出（读）和导入（写）两个过程，完全解耦，因此具有很好的扩展性。每种数据源只需要实现读写两种操作即可。以常见的数据源为例，看看分别如何实现从 CSV 导入数据（导出到 CSV 很容易，使用任意编程语言都可实现）。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据源&lt;/th&gt;
&lt;th&gt;导入 CSV&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;MySQL&lt;/td&gt;
&lt;td&gt;使用 &lt;code&gt;LOAD DATA LOCAL INFILE&lt;/code&gt; 批量加载，或读取文件运行 &lt;code&gt;INSERT&lt;/code&gt; 语句&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AWS Redshift&lt;/td&gt;
&lt;td&gt;以 AWS S3 为中转，使用 &lt;code&gt;COPY&lt;/code&gt; 命令批量加载&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hive&lt;/td&gt;
&lt;td&gt;建表时指定 Serde 为 &lt;code&gt;org.apache.hadoop.hive.serde2.OpenCSVSerde&lt;/code&gt;，或者在导入前把 CSV 先转换成默认的 &lt;code&gt;TEXTFILE&lt;/code&gt; 格式；然后使用 &lt;code&gt;LOAD DATA [LOCAL] INPATH&lt;/code&gt; 批量加载。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ElasticSearch&lt;/td&gt;
&lt;td&gt;读取文件，批量插入&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;FTP, AWS S3&lt;/td&gt;
&lt;td&gt;直接上传&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;性能问题&#34;&gt;性能问题&lt;/h2&gt;

&lt;p&gt;解耦的另一个好处就是性能优化，因为我们可以专注优化导出和导入，而不用担心两者相互影响。&lt;/p&gt;

&lt;h3 id=&#34;导出性能&#34;&gt;导出性能&lt;/h3&gt;

&lt;p&gt;导出性能优化通常是用并行化来实现，即对数据集进行分割，然后并行处理。&lt;/p&gt;

&lt;p&gt;以 MySQL 为例，如果表里有自增主键，首先查出上下边界，分成 N 片，然后起 M 个线程来消费（Sqoop 也是这种思路，通过调整 mapper 数量来控制）。每个线程可以写单独的文件最后再合并，也可以用一个单独的线程聚合起来写入；一般来讲第一种性能更好一点。&lt;/p&gt;

&lt;p&gt;这种优化的前提是能找到尽可能分割均匀的方式，如果有数据倾斜，可能提升并不明显，甚至退化到单线程。对数据库而言，用于分割的字段还需要有索引，一般会选择自增主键或带有索引的时间戳。并行度不能太高，否则可能对上游系统带来太大压力。另外一个实现上的细节，就是应该流式地获取数据和写入文件，而不是先全部拉到内存，否则可能导致内存占用过多，甚至 OOM.&lt;/p&gt;

&lt;p&gt;另外，考虑到导出过程可能异常中断，还可以考虑使用 checkpoint 机制，从失败处重试。&lt;/p&gt;

&lt;h3 id=&#34;导入性能&#34;&gt;导入性能&lt;/h3&gt;

&lt;p&gt;导入性能优化通常是用批量的思想实现。&lt;/p&gt;

&lt;p&gt;有些数据库，如 MySQL、Hive、Redshift 等，支持直接加载 CSV 文件，这种方式一般是最高效的。如果不支持批量加载，还可以调用批量导入的 API（如 ElasticSearch 的 &lt;code&gt;/_bulk&lt;/code&gt;，数据库的 &lt;code&gt;INSERT&lt;/code&gt; 语句通常都支持一次性插入多条记录 ）。有些数据源可能支持压缩文件（如 Redshift 支持 GZIP 等多种压缩格式），则可以在导入前先压缩以缩短传输时间和带宽消耗。&lt;/p&gt;

&lt;p&gt;导入过程的失败重试也可以使用 checkpoint 实现「断点续传」，另外还可以考虑去重机制，比如使用 bloom filter 进行检查。&lt;/p&gt;

&lt;h2 id=&#34;复杂度&#34;&gt;复杂度&lt;/h2&gt;

&lt;p&gt;从上文的设计图即可看出，这种方案的复杂度很低，流程清晰，容易实现。除了本地文件系统，基本上没有外部依赖。实现上需要注意日志和统计，方便跟踪进度，分析问题，定位故障。&lt;/p&gt;

&lt;h2 id=&#34;全量和增量&#34;&gt;全量和增量&lt;/h2&gt;

&lt;p&gt;从复杂度的角度来看，全量同步是最容易实现的，也更好保障数据的一致性。然而随着数据量的增加，每次全量同步需要的资源消耗和时间会越来越多。增量同步很有必要，也更复杂。&lt;/p&gt;

&lt;h3 id=&#34;增量导出&#34;&gt;增量导出&lt;/h3&gt;

&lt;p&gt;增量导出的前提是能识别出新增数据。最容易想到的是通过自增主键来判断，但这受限于数据库本身的特性。有些数据库不支持自增主键，有些数据库的自增主键不保证单调性（如 &lt;a href=&#34;https://pingcap.com/docs/sql/mysql-compatibility/#auto-increment-id&#34;&gt;TiDB&lt;/a&gt;，部署了多个 tidb-server 可能出现后插入的 ID 比之前的 ID 更小）  。更可靠的是通过时间来判断，时间天然自增且严格单调，另一个好处是对于周期性增量同步其实不用保存 checkpoint，可以直接计算得到。&lt;/p&gt;

&lt;p&gt;有单调递增的整数或时间字段（最好是时间）是增量导出的必要条件，另外为了更好的导出性能，这个字段还需要建索引。&lt;/p&gt;

&lt;h3 id=&#34;增量导入&#34;&gt;增量导入&lt;/h3&gt;

&lt;p&gt;增量导入要考虑更多情况，比如导入模式和幂等性。&lt;/p&gt;

&lt;p&gt;首先看导入模式，可以分为两种：合并（&lt;code&gt;MERGE&lt;/code&gt;）和追加（&lt;code&gt;APPEND&lt;/code&gt;）（其实还有一种特殊的增量导入，如导入到 Hive 的一个分区，跟全量导入（&lt;code&gt;OVERWRITE&lt;/code&gt;）是一样的）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;MERGE&lt;/code&gt;: 上游系统里新增和更新的记录，都要同步到目标系统，类比 &lt;code&gt;UPSERT&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;APPEND&lt;/code&gt;: 上游系统只会新增，不会更新，类比 &lt;code&gt;INSERT&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;APPEND&lt;/code&gt; 的实现比较简单，但如果导入多次，（没有唯一性约束时）容易产生重复数据（不幂等）。而实际上，&lt;code&gt;APPEND&lt;/code&gt; 是 &lt;code&gt;MERGE&lt;/code&gt; 的一种极端情况，因此可以转换成 &lt;code&gt;MERGE&lt;/code&gt; 来实现。&lt;/p&gt;

&lt;p&gt;实现 &lt;code&gt;MERGE&lt;/code&gt; 的前提是需要有字段能区分记录的唯一性，比如主键、唯一性约（只要逻辑上能区分即可）。不同数据源实现 &lt;code&gt;MERGE&lt;/code&gt; 的方式也比较多样。有些数据源支持 &lt;code&gt;UPSERT&lt;/code&gt; 操作，如 Phoenix, Kudu, MongoDB 等； ElasticSearch 索引文档时也类似 &lt;code&gt;UPSERT&lt;/code&gt; ；有些数据库支持 &lt;code&gt;REPLACE&lt;/code&gt; 操作；MySQL 还有 &lt;code&gt;INSERT ON DUPLICATE UPDATE&lt;/code&gt;。实际上，对于 MySQL, Redshift, Hive 这些关系型数据库，还有一种通用的方案：使用 &lt;code&gt;FULL JOIN&lt;/code&gt; 或 &lt;code&gt;LEFT JOIN + UNION ALL&lt;/code&gt;（在 &lt;a href=&#34;../../03/idempotence&#34;&gt;聊聊幂等&lt;/a&gt; 有详细阐述）。&lt;/p&gt;

&lt;p&gt;这种实现的增量导入有个局限性，即无法同步上游系统的物理删除操作。如果有这种需求，可以考虑改成软删除，或使用全量同步。&lt;/p&gt;

&lt;h3 id=&#34;导入流程&#34;&gt;导入流程&lt;/h3&gt;

&lt;p&gt;不管是全量还是增量，导入过程至少需要确保两点：「事务性」和不能（尽可能少）影响目标数据的使用。这个问题主要出现在数据库系统，对于 ElasticSearch 和对象存储这种场景一般不会出现。&lt;/p&gt;

&lt;p&gt;「事务性」指的是对于要导入的数据，要么全部成功，要么全部失败，而不能出现只导入部分的情况。&lt;/p&gt;

&lt;p&gt;导入过程中，目标数据应该是可用的，或者受影响时间要尽可能短。比如不能出现长时间锁表，导致无法查询。&lt;/p&gt;

&lt;p&gt;可以在流程上进行优化：先导入到 staging 表，准备最终结果表，然后替换到目标表。导入 staging 表时可以不断删除重试，确保新数据完全导入后再进行下一步操作。全量导入时，可以直接把 staging 表重命名为目标表，或使用 &lt;code&gt;INSERT OVERWRITE&lt;/code&gt; 语句进行数据拷贝。增量导入时，要再建一个中间表用于存放结果数据，完成后使用重命名或数据拷贝的方式更新到目标表。&lt;/p&gt;

&lt;h2 id=&#34;局限性&#34;&gt;局限性&lt;/h2&gt;

&lt;p&gt;主要有两个局限性：1. 需要落盘；2. CSV.&lt;/p&gt;

&lt;p&gt;在某些场景下，落盘到文件可能会带来一些额外的性能损耗，不过在离线系统里，这个影响应该可以忽略。需要注意文件清理，否则可能用完整个磁盘空间。最大的问题应该是导出和导入没有完全解耦，必须部署在同一台机器，而且要确保使用相同的文件路径。因为这个状态，一定程度上限制了分布式水平扩展的能力（注意，只是单个表的同步需要在一台机器完成，多个表之间可以水平扩展）。&lt;/p&gt;

&lt;p&gt;使用 CSV 文件作为数据交换格式，其实是一种折衷方案，优点和缺陷并存。关于 CSV 格式，我在 &lt;a href=&#34;../../03/data-encoding&#34;&gt;这篇文章&lt;/a&gt; 里也有讨论。这里再总结一下不足：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无法区分数字和和碰巧由数字组成的字符串。不过这个可以通过额外的 schema 来解决，比如导出数据的同时，也导出一份 schema，或者在导入时由目标数据库的 schema 来决定。&lt;/li&gt;
&lt;li&gt;不支持二进制数据。&lt;/li&gt;
&lt;li&gt;可能会有转义的问题。&lt;/li&gt;
&lt;li&gt;无法区分空字符串和空值（&lt;code&gt;None&lt;/code&gt;, &lt;code&gt;NULL&lt;/code&gt;），一种解决方案是使用特殊值表示空值，如 &lt;code&gt;\N&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;整体来讲，使用 CSV 应该可以满足 90% 以上的使用场景。&lt;/p&gt;

&lt;p&gt;使用 Kafka 作为数据交换总线，可以突破这些限制，但同时也增加了系统的复杂度。可根据实际情况进行选择。&lt;/p&gt;

&lt;h2 id=&#34;show-me-the-code&#34;&gt;SHOW ME THE CODE!&lt;/h2&gt;

&lt;p&gt;我在公司用 Python 实现了这种方案，目前已经支持十来种数据源（有些数据源只有读或写），暂时没有准备开源。思路比实现重要，本文讨论了整体方案和一些核心问题，基本上没什么复杂的技术，还是不难实现的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>聊聊幂等</title>
      <link>http://liyangliang.me/posts/2019/03/idempotence/</link>
      <pubDate>Sun, 17 Mar 2019 23:38:00 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/03/idempotence/</guid>
      <description>&lt;p&gt;计算机领域有很多概念都来自数学，今天要讨论的幂等性就是其中之一。在程序世界，幂等的意义是对于某个操作，执行一次和多次所产生的影响应该相同。比如赋值操作是幂等的，&lt;code&gt;a = 1&lt;/code&gt; 无论运行多少次，最终的影响都是一样；而计数则不是。幂等在很多系统中都很重要，结合自己的经历，聊聊 HTTP 的幂等性和 ETL 场景里的幂等。&lt;/p&gt;

&lt;h2 id=&#34;http-的幂等性&#34;&gt;HTTP 的幂等性&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html&#34;&gt;HTTP RFC 规范&lt;/a&gt;里有关于幂等方法的讨论：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Methods can also have the property of &amp;ldquo;idempotence&amp;rdquo; in that (aside from error or expiration issues) the side-effects of N &amp;gt; 0 identical requests is the same as for a single request. The methods GET, HEAD, PUT and DELETE share this property. Also, the methods OPTIONS and TRACE SHOULD NOT have side effects, and so are inherently idempotent.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Restful 风格的 API 比较忠实的遵守了 HTTP 协议的各种规定，充分利用了 HTTP 方法和状态码的语义，用 URI 表示资源，&lt;code&gt;POST&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;, &lt;code&gt;PUT&lt;/code&gt; 和 &lt;code&gt;GET&lt;/code&gt; 来对应增删改查四种操作。这些方法里，除了 &lt;code&gt;POST&lt;/code&gt;，其它三个都是幂等的，我们分别从语义和实现的角度来讨论。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;GET&lt;/code&gt; 方法用于获取资源，可以获取一个（&lt;code&gt;GET /posts/1&lt;/code&gt;）或多个（&lt;code&gt;GET /posts&lt;/code&gt;）。在服务端实现上，其实就是根据资源标识（主键或全表）查询对应的数据。这个操作没有副作用，虽然可能会每次得到不同的结果，不管执行多少次，都不会对数据库的数据产生影响。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;DELETE&lt;/code&gt; 用于删除资源，&lt;code&gt;DELETE /posts/1&lt;/code&gt; 会触发服务端从数据库删除主键为 &lt;code&gt;1&lt;/code&gt; 的记录，调用一次和 N 次产生的副作用都是一致的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;POST&lt;/code&gt; 用于创建资源，服务器获取数据后会在数据库里新增一条记录，得到一个新的主键。在正常情况下，服务器不会预先检查数据是否存在，所有每次相同的请求都会导致新建一份资源（除非有唯一性约束）。因此 &lt;code&gt;POST&lt;/code&gt; 不具备幂等性，设计 API 时需要仔细考虑如何避免产生重复数据。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;PUT&lt;/code&gt; 通常用于更新资源，但实际上也可以创建，在 HTTP 规范里，&lt;code&gt;PUT&lt;/code&gt; 类似有些数据库里的 &lt;code&gt;UPSERT&lt;/code&gt;，即如果数据存在就更新，否则新建。两种场景的区别在于，资源标识是谁生成的。更新的场景一般是先从服务端获取了数据，客户端修改后提交更新；另一种场景则是客户端指定，如博客系统里 slug 是唯一的，而且通常由作者指定。不管是更新还是创建，由于存在主键或唯一性约束，执行多次都不会产生额外的副作用。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实现幂等性非常重要。在理想的世界里，所有的操作都能一次性成功；然而现实情况往往很复杂，网络波动可能导致请求失败，用户（客户端）可能会无意的触发多次重复请求。为了确保成功率，在失败时通常都会有重试机制，如果系统没有实现幂等，可能会产生难以预料的结果。在网上搜索幂等经常能看到支付、转账、取款的例子（这些例子也经常用于数据库事务），解决方案也类似，一般用 token (ticket) + 唯一性约束来实现。&lt;/p&gt;

&lt;h2 id=&#34;etl-与幂等&#34;&gt;ETL 与幂等&lt;/h2&gt;

&lt;p&gt;上文讨论 HTTP 幂等性时提到了很多关于数据库的操作，其中最重要就是数据去重，数据库层面一般由主键或唯一性约束来保证。在做 ETL 任务时，幂等也非常重要。&lt;/p&gt;

&lt;p&gt;一个常见的 ETL 场景是从生产系统（MySQL）把数据增量同步到 Hive，然后在 Hive 里对数据做处理后增量写到另一个表。全量更新比较容易，增量更新就一定要确保幂等，否则重试就会产生重复数据。ETL 任务不仅在失败的时候需要重跑，即使成功了也有可能会调整业务逻辑然后重新运行。所有 ETL 任务都应该实现幂等，即使是一次性的。&lt;/p&gt;

&lt;p&gt;Hive 里没有主键和唯一性约束的概念，所以需要想办法实现去重。其中一种思路是用分区表，每次增量更新都覆盖一个分区。但也有的数据并不适合做分区，比如商品信息表。虽然 Hive 没有主键和唯一性约束，但如果数据本身存在可以表示唯一记录的字段（多个也行），可以考虑使用 &lt;code&gt;FULL JOIN&lt;/code&gt; 或 &lt;code&gt;LEFT JOIN&lt;/code&gt; 的方式来实现。首先把新增数据保存到一个 staging 表，然后更新到 target 表。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;FULL JOIN&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- 两表合并，同时出现的记录优先取 staging 表的值，最终的影响是已存在则更新，否则插入

INSERT OVERWRITE TABLE target
SELECT COALESCE(a.id, b.id),
       COALESCE(a.name, b.name)
FROM staging a FULL JOIN target b ON a.id = b.id
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;LEFT JOIN&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- 找出仅在 target 表存在的记录，再加上 staging 的所有记录，最终的影响也是已存在则更新，否则插入

INSERT OVERWRITE TABLE target
SELECT a.id, a.name
FROM target a LEFT JOIN staging b ON a.id = b.id
WHERE b.id IS NULL

UNION ALL

SELECT * FROM staging
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这其实就是一种 MERGE 操作，两种方式都实现了幂等。有时候 staging 的数据是完全新增的，也不能使用 &lt;code&gt;INSERT INTO&lt;/code&gt;，因为多次执行会导致数据重复。这种技术不仅适用于 Hive，MySQL, PostgeSQL 这些数据库有主键和唯一性约束，但用 &lt;code&gt;JOIN&lt;/code&gt; 的方式往往会更高效简单。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/weidagang2046/archive/2011/06/04/idempotence.html&#34;&gt;理解HTTP幂等性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html&#34;&gt;RFC 2616, Hypertext Transfer Protocol &amp;ndash; HTTP/1.1, Method Definitions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gtoonstra.github.io/etl-with-airflow/principles.html?highlight=idempotency&#34;&gt;ETL Best Practices with airflow - ETL Principles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/896&#34;&gt;每个工程师都应该了解的：聊聊幂等&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>字节跳动（今日头条） 2018 校招后端第二批算法题</title>
      <link>http://liyangliang.me/posts/2019/03/2018-holiday/</link>
      <pubDate>Sun, 10 Mar 2019 22:24:51 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/03/2018-holiday/</guid>
      <description>&lt;p&gt;逛 V2EX 的时候无意间看到了有个叫 &lt;a href=&#34;https://www.nowcoder.com&#34;&gt;牛客网&lt;/a&gt; 的网站，里面有很多公司的笔试真题和大家分享的面经。
出于好奇，看了一下 &lt;a href=&#34;https://www.nowcoder.com/test/8537209/summary&#34;&gt;字节跳动（今日头条）的后端题&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;一共有 5 题，3 道编程，2 道问答。时候发现前面 4 题跟算法有关，其中 3 道要实现，1 道是纠错和优化，最后一题是系统设计。
做得比较差，只完成了前面两道算法题。用 Go 语言实现，代码如下。&lt;/p&gt;

&lt;h2 id=&#34;用户喜好&#34;&gt;用户喜好&lt;/h2&gt;

&lt;h3 id=&#34;问题&#34;&gt;问题&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;为了不断优化推荐效果，今日头条每天要存储和处理海量数据。假设有这样一种场景：我们对用户按照它们的注册时间先后来标号，对于一类文章，每个用户都有不同的喜好值，我们会想知道某一段时间内注册的用户（标号相连的一批用户）中，有多少用户对这类文章喜好值为k。因为一些特殊的原因，不会出现一个查询的用户区间完全覆盖另一个查询的用户区间(不存在L1&amp;lt;=L2&amp;lt;=R2&amp;lt;=R1)。&lt;/p&gt;

&lt;p&gt;输入描述:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;输入： 第1行为n代表用户的个数 第2行为n个整数，第i个代表用户标号为i的用户对某类文章的喜好度 第3行为一个正整数q代表查询的组数  第4行到第（3+q）行，每行包含3个整数l,r,k代表一组查询，即标号为l&amp;lt;=i&amp;lt;=r的用户中对这类文章喜好值为k的用户的个数。 数据范围n &amp;lt;= 300000,q&amp;lt;=300000 k是整型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;输出描述:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;输出：一共q行，每行一个整数代表喜好值为k的用户的个数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;分析&#34;&gt;分析&lt;/h3&gt;

&lt;p&gt;把题目转换成程序语言来描述就是，给定长度为 &lt;code&gt;n&lt;/code&gt; 的 &lt;code&gt;int&lt;/code&gt; 数组，查找指定下标范围 &lt;code&gt;[l, r]&lt;/code&gt; 内，值为 &lt;code&gt;k&lt;/code&gt; 的元素数量。&lt;/p&gt;

&lt;p&gt;一种算法是遍历数组&lt;code&gt;[l, r]&lt;/code&gt;，统计值为 &lt;code&gt;k&lt;/code&gt; 的数量。&lt;/p&gt;

&lt;p&gt;另外就是可以构建哈希表，以元素值为键，对应的下标（构成数组）为值。查找时快速取出所有的下标，统计 &lt;code&gt;[l, r]&lt;/code&gt; 的下标数量。
提交的是这种算法，代码如下。运行通过，耗时 2688ms, 内存 9560K, 险些超时。
后来网上搜了一下，查找 &lt;code&gt;l&lt;/code&gt; 和 &lt;code&gt;r&lt;/code&gt; 对应的下标可以使用二分查找算法，效率更高。&lt;/p&gt;

&lt;h3 id=&#34;代码&#34;&gt;代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

func main() {
	var n, q, l, r, k int
	_, _ = fmt.Scan(&amp;amp;n)

	table := make(map[int][]int)
	var v int
	for i := 0; i &amp;lt; n; i++ {
		_, _ = fmt.Scan(&amp;amp;v)
		indexes, ok := table[v]
		if !ok {
			indexes = make([]int, 0)
			table[v] = indexes
		}
		table[v] = append(indexes, i+1)
	}

	_, _ = fmt.Scan(&amp;amp;q)
	for i := 0; i &amp;lt; q; i++ {
		_, _ = fmt.Scan(&amp;amp;l, &amp;amp;r, &amp;amp;k)
		count := 0
		if indexes, ok := table[k]; ok {
			for _, idx := range indexes {
				if l &amp;lt;= idx &amp;amp;&amp;amp; idx &amp;lt;= r {
					count++
				}
				// 下标数组是有序的，如果到了 r 说明后面的都不符合条件，可以退出循环
				if idx &amp;gt; r {
					break
				}
			}
		}
		fmt.Println(count)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;手串&#34;&gt;手串&lt;/h2&gt;

&lt;h3 id=&#34;问题-1&#34;&gt;问题&lt;/h3&gt;

&lt;p&gt;时间限制：1秒 空间限制：65536K&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;作为一个手串艺人，有金主向你订购了一条包含n个杂色串珠的手串——每个串珠要么无色，要么涂了若干种颜色。为了使手串的色彩看起来不那么单调，金主要求，手串上的任意一种颜色（不包含无色），在任意连续的m个串珠里至多出现一次（注意这里手串是一个环形）。手串上的颜色一共有c种。现在按顺时针序告诉你n个串珠的手串上，每个串珠用所包含的颜色分别有哪些。请你判断该手串上有多少种颜色不符合要求。即询问有多少种颜色在任意连续m个串珠中出现了至少两次。&lt;/p&gt;

&lt;p&gt;输入描述:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;第一行输入n，m，c三个数，用空格隔开。(1 &amp;lt;= n &amp;lt;= 10000, 1 &amp;lt;= m &amp;lt;= 1000, 1 &amp;lt;= c &amp;lt;= 50) 接下来n行每行的第一个数num_i(0 &amp;lt;= num_i &amp;lt;= c)表示第i颗珠子有多少种颜色。接下来依次读入num_i个数字，每个数字x表示第i颗柱子上包含第x种颜色(1 &amp;lt;= x &amp;lt;= c)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;输出描述:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;一个非负整数，表示该手链上有多少种颜色不符需求。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;分析-1&#34;&gt;分析&lt;/h3&gt;

&lt;p&gt;跟第一题类似，也是构建哈希表，记录每种颜色出现过的位置（是个数组）。迭代这个数组，如果出现相邻两个元素差值小于 &lt;code&gt;m&lt;/code&gt;，就不符合需求。
需要注意的是最后一个元素，判断是否「套圈」。代码如下，运行时间 57ms, 内存 1892K.&lt;/p&gt;

&lt;h3 id=&#34;代码-1&#34;&gt;代码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

func main() {
	var n, m, c int
	_, _ = fmt.Scanln(&amp;amp;n, &amp;amp;m, &amp;amp;c)

	colorIndexes := make(map[int][]int, c)
	for i := 0; i &amp;lt; n; i++ {
		var colorCount int
		_, _ = fmt.Scan(&amp;amp;colorCount)

		for j := 0; j &amp;lt; colorCount; j++ {
			var color int
			_, _ = fmt.Scan(&amp;amp;color)
			indexes, ok := colorIndexes[color]
			if !ok {
				indexes = make([]int, 0)
				colorIndexes[color] = indexes
			}
			colorIndexes[color] = append(colorIndexes[color], i+1)
		}
	}

	result := 0
	for _, indexes := range colorIndexes {
		if len(indexes) &amp;lt;= 1 {
			continue
		}
		for i := 0; i &amp;lt; len(indexes); i++ {
			if i == len(indexes)-1 {
				if (indexes[i]+m)%n &amp;gt; indexes[0] {
					result++
					break
				}
			} else if indexes[i]+m &amp;gt; indexes[i+1] {
				result++
				break
			}
		}
	}
	fmt.Println(result)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;第三题没做出来，是个动态规划问题，没训练过。动态规划算法题很常见，可以学习一下。&lt;/li&gt;
&lt;li&gt;临时查了一下 Go 从 stdin 读取变量的方法。刚开始用了 &lt;code&gt;bufio.Reader&lt;/code&gt;，手动读入字符串、切分、转换成 int，特别蛋疼，而且效率很低。&lt;/li&gt;
&lt;li&gt;总体来说，对算法还是很不熟悉。比如第一题没想到用二分查找。这还是天然有序的，如果要自己排序，手写快排估计也够呛（不过可以用标准库&amp;hellip;）。&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title> Designing Data-Intensive Applications 读书笔记（1） —— 数据编码</title>
      <link>http://liyangliang.me/posts/2019/03/data-encoding/</link>
      <pubDate>Sat, 02 Mar 2019 16:40:45 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2019/03/data-encoding/</guid>
      <description>&lt;p&gt;最近一段时间都在读 &lt;em&gt;Designing Data-Intensive Applications&lt;/em&gt; 这本书，中文名叫《数据密集型应用系统设计》。进度比较慢，但感觉很有意思，获益匪浅。在读第四章 &lt;em&gt;Encoding and Evolution&lt;/em&gt; （数据编码与演化）时，脑海里时常浮现出自己的开发经历，颇有共鸣。因此准备结合书本内容和自身体验，总结成文字作为记录。这一篇主要讨论编码。&lt;/p&gt;

&lt;h2 id=&#34;编码和解码&#34;&gt;编码和解码&lt;/h2&gt;

&lt;p&gt;在程序世界里，数据通常有两种不同的表现形式：内存和文件（网络）。在内存中，数据保存在对象、结构体、列表、哈希表等结构中，这些数据结构针对 CPU 的高效访问和操作进行了优化。而把数据写入文件或通过网络发送时，需要将其转换成字节序列。&lt;/p&gt;

&lt;p&gt;从内存中的表示到字节序列的转化称为编码或序列化，反之称为解码或反序列化。&lt;/p&gt;

&lt;h2 id=&#34;编码格式&#34;&gt;编码格式&lt;/h2&gt;

&lt;p&gt;只要程序发生 IO 或其他程序进行数据交换时，就需要进行编解码。每种场景的需求和特点各异，随着时间推移，诞生了很多中编码格式。从通用性的角度来看，可以划分为两大类：语言特定的格式和通用格式。&lt;/p&gt;

&lt;h3 id=&#34;语言特定的格式&#34;&gt;语言特定的格式&lt;/h3&gt;

&lt;p&gt;很多语言都有特定的编码格式，并且以标准库的形式提供编码和解码功能。我使用过的有 Python 的 pickle 和 Go 的 gob. 这些库的主要好处是使用方便，功能强大。以 Python 的 pickle 为例，不仅能处理常见的数据格式，&lt;a href=&#34;https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled&#34;&gt;还能处理函数、类和对象&lt;/a&gt;. 但也存在一些问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;跨语言共享非常困难。语言特定的格式就类似于一种私有加密算法，其他程序（语言）基本上无法理解。2013 年曾做过用 Go 重构一个 Python 应用的项目。项目里用到了 Redis，但是缓存的数据都是用 pickle 序列化的，Go 语言无法解码。当时刚参加工作，经验不足，不知道 pickle 是 Python 特有的，刚开始还找了很久 Go 的解码库（当然没找到）。后来经老大提醒，把缓存全部改成 JSON.&lt;/li&gt;
&lt;li&gt;存在安全隐患。为了在相同的对象类型中恢复数据，解码过程要能实例化任意的类，就有可能执行一些危险的代码。&lt;a href=&#34;https://www.synopsys.com/blogs/software-security/python-pickling/&#34;&gt;Understanding Python pickling and how to use it securely&lt;/a&gt; 用例子讲述了 Python pickle 的安全隐患和一些可行的放缓措施。&lt;/li&gt;
&lt;li&gt;书中还提到了多版本的兼容性和编解码效率问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;通用格式&#34;&gt;通用格式&lt;/h3&gt;

&lt;p&gt;计算机上运行的程序由各种各样的编程语言实现，因此必然需要一些通用和标准格式来支持不同语言之间的数据交换。这些格式可以分为两种：文本格式和二进制格式。&lt;/p&gt;

&lt;h4 id=&#34;文本格式&#34;&gt;文本格式&lt;/h4&gt;

&lt;p&gt;常见的文本格式有 JSON、XML 和 CSV，其中 CSV 可以泛化为分隔符文本文件。这些编码格式应用非常广泛，基本上所有语言都能正确编码和解码。而且可读性良好， 很适合人类阅读理解。&lt;/p&gt;

&lt;p&gt;这些格式解决了跨语言的障碍，但也有一些的问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对数字的处理存在缺陷。XML 和 CSV 无法区分数字和碰巧由数字组成的字符串；JSON 有字符串和数字类型，但不区分整数和浮点数。书里还提到 JavaScript 在处理大于 &lt;code&gt;2**53&lt;/code&gt; 的数字时会有精度丢失的现象，但这只能说时 JavaScript 语言的问题，不是 JSON 的不足（JSON 只是一种文本格式）。不过我确实在实际工作中被这个问题坑过一次：从 TiDB 同步数据到 ElasticSearch，在 Kibana 查看时总是会有些 BIGINT (int64) 类型的数据和 TiDB 对应不上（ElasticSearch 存储的是对的）。查明原因后，为了方便查看，不得不把类型转换成字符串再重新同步。&lt;/li&gt;
&lt;li&gt;不支持二进制数据。用 Python 开发了一个异构数据源的数据同步系统（项目代号为 pigeon），为了方便扩展和解耦，把同步过程拆成了 dump 和 load 两个步骤，用 CSV 文件作为数据交换格式。在大部分情况下这种设计能很好的工作，但最大的缺陷就是不支持二进制数据。各种数据库系统都有二进制类型，而且也非常有用（存储图片、压缩或加密的数据等）。一种可行的方案是用 base64 把二进制字符串编码成文本字符串，但会带来 33% 的数据膨胀。&lt;/li&gt;
&lt;li&gt;XML 和 JSON 的每条记录都要保存元素标记、字段名等信息，导致大量冗余。CSV 相对来说更加紧凑，最多用第一行保存每一列的字段名称。但不管是否有冗余，相对二进制格式而言，都会占用大量磁盘空间，当数据量大时，就要使用压缩算法进行压缩保存。&lt;/li&gt;
&lt;li&gt;CSV 没有模式，其实就是一种分隔符文件，当数据内部存在分隔符就可能会带来麻烦。虽然可以使用转义字符和 quoting，但并不是所有解析器都能正确解析。使用 pigeon 的时候就发现，MySQL 对 CSV 的容错性似乎不如 Python 的标准库 &lt;code&gt;csv&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;用 Python 写入 CSV 时，会把 &lt;code&gt;None&lt;/code&gt; 编码成空字符串，从而导致解码时无法区分。因此在 pigeon 里大部分场景下会把 &lt;code&gt;None&lt;/code&gt; 编码为 &lt;code&gt;NULL&lt;/code&gt; 或 &lt;code&gt;\N&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;尽管存在这些或那些缺陷，JSON、XML 和 CSV 的应用非常广泛，编解码工具也很成熟丰富。在 Web 开发领域，传统的 Web Service 大量使用 XML，随着 Web 技术的发展和， JSON 变得越来越流行. 在数据库和数据分析领域，则经常使用 CSV 来作为数据交换格式，基本上常见的数据库都原生支持导入 CSV 文件（这也是 pigeon 选择 CSV 的重要原因之一）。&lt;/p&gt;

&lt;h4 id=&#34;二进制格式&#34;&gt;二进制格式&lt;/h4&gt;

&lt;h5 id=&#34;json-和-xml-的二进制变体&#34;&gt;JSON 和 XML 的二进制变体&lt;/h5&gt;

&lt;p&gt;因为以上原因，也催生了很多这些文本格式的二进制变体。如 JSON 系的 MessagePack、BSON、BJSON、UBJSON、BISON，XML 系的 WBXML 和 Fast Infoset. 这些格式被很多细分领域所采用，但都没有 JSON 和 XML 那样广泛。&lt;/p&gt;

&lt;p&gt;MessagePack（和其他同类二进制编码）对空间缩减有限（书中的例子是 81 字节到 66 字节），而且牺牲了可读性，作者似乎认为这并不值得。不过另一个好处是，一般二进制的解析速度会更快，还有一些格式扩展了数据类型，比如可以区分整数和浮点数，或者增加了对二进制字符串的支持。&lt;/p&gt;

&lt;h5 id=&#34;thrift-和-protocol-buffers&#34;&gt;Thrift 和 Protocol Buffers&lt;/h5&gt;

&lt;p&gt;&lt;a href=&#34;https://thrift.apache.org/&#34;&gt;Apache Thrift&lt;/a&gt; 和 &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt; 分别诞生自 Facebook 和 Google，都在 2007~2008 期间贡献到开源社区。两种格式都需要定义 schema (IDL, Interface definition language)，而且都有对应的代码生成工具，可以自动生成多种语言的解析代码。&lt;/p&gt;

&lt;p&gt;Thrift 和 Protocol Buffers 类似，每个字段用标签（tag, 数字 1, 2, 3&amp;hellip;）表示，所以更加紧凑，可以节省大量空间。由于编码不会引用字段名，所以只要保证标签不变， schema 里的字段名可以随意更改（JSON 和 XML 不行）。此外每个字段都有明确的数据类型，还有 &lt;code&gt;optional&lt;/code&gt; 和 &lt;code&gt;required&lt;/code&gt; 约束，可以用于数据合法性校验。&lt;/p&gt;

&lt;p&gt;Thrift 有 BinaryProtocol 和 CompactProtocol 两种编码格式，书中的例子生成的二进制序列分别是 59 字节和 34 字节。Protocol Buffers 的结果是 33 字节。&lt;/p&gt;

&lt;p&gt;因为这些编码格式更紧凑、高效，能自动生成客户端和服务端代码，往往用于实现高性能的 RPC 服务。其实 Thrift 本身就是一个 RPC 框架，Hadoop 生态里的组件就大量使用 Thrift. Protocol Buffers 没有实现 RPC 框架，但 Google 基于此开发了 &lt;a href=&#34;https://grpc.io/&#34;&gt;gRPC&lt;/a&gt;，应用也十分广泛，比如 TiDB 组件的内部通信就用了 gRPC.&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;跟其他技术（比如数据库）一样，每种格式都有各自的优点和缺陷，抛开使用场景单纯讨论优劣是没有意义的。下表是结合书中内容和自己的理解，从几个维度定性的比较了这些格式的特点。不一定对，仅供参考。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;编码格式&lt;/th&gt;
&lt;th&gt;可读性&lt;/th&gt;
&lt;th&gt;schema&lt;/th&gt;
&lt;th&gt;性能&lt;/th&gt;
&lt;th&gt;空间&lt;/th&gt;
&lt;th&gt;代码生成&lt;/th&gt;
&lt;th&gt;复杂度&lt;/th&gt;
&lt;th&gt;适用场景举例&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;JSON&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;td&gt;有，复杂&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;大&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;很低&lt;/td&gt;
&lt;td&gt;Web&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;XML&lt;/td&gt;
&lt;td&gt;较好&lt;/td&gt;
&lt;td&gt;有，复杂&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;很大&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;配置, UI, SOAP&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CSV&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;关系型数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;MessagePack&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;较高&lt;/td&gt;
&lt;td&gt;较小&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;Web&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Thrift&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;很高&lt;/td&gt;
&lt;td&gt;很小&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;RPC&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Protocol Buffers&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;很高&lt;/td&gt;
&lt;td&gt;很小&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;RPC&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>Python 日期和时间处理</title>
      <link>http://liyangliang.me/posts/2018/06/python-date-time/</link>
      <pubDate>Sat, 02 Jun 2018 16:03:26 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/06/python-date-time/</guid>
      <description>

&lt;p&gt;2012 年大四的时候写过一篇 &lt;a href=&#34;http://liyangliang.me/posts/2012/10/python-timestamp-to-timestr&#34;&gt;Python 时间戳和日期相互转换&lt;/a&gt;，当时是初学 Python，对标准库也理解不深；随便找到一种解决方案就记录下来并发到博客上了。现在回看起来，其实太过繁琐了。然而从 Google Analytics 后台看，这竟然是点击率第二的文章，着实让我感到诧异。本着对读者负责的态度，有必要结合这些年的开发经验，再写一篇日期和时间处理的博客。&lt;/p&gt;

&lt;p&gt;首先再次回答「Python 时间戳和日期相互转换」的问题。&lt;/p&gt;

&lt;h2 id=&#34;时间戳转日期&#34;&gt;时间戳转日期&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime
import time

t = time.time()
print(&#39;Timestamp&#39;, t)

dt = datetime.datetime.fromtimestamp(t)
print(&#39;Datetime&#39;, dt)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Timestamp 1527927420.684622
Datetime 2018-06-02 16:17:00.684622
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;日期转时间戳&#34;&gt;日期转时间戳&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime

now = datetime.datetime.now()
print(&#39;Datetime&#39;, now)
print(&#39;Timestamp&#39;, now.timestamp())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Datetime 2018-06-02 16:18:42.170874
Timestamp 1527927522.170874
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>CentOS 7 FirewallD</title>
      <link>http://liyangliang.me/posts/2018/06/centos7-firewalld/</link>
      <pubDate>Sat, 02 Jun 2018 15:11:15 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/06/centos7-firewalld/</guid>
      <description>&lt;h2 id=&#34;背景故事&#34;&gt;背景故事&lt;/h2&gt;

&lt;p&gt;线上服务器一直没有开启防火墙，没有约束用起来倒也省事。部署 Hadoop 集群（CDH 发行版）的时候，所有网上看过的教程和笔记（包括 CDH 官方文档），全部都提到了部署过程中要关闭防火墙；极少数教程会提到如果有需要，可以在部署完成后再开启；然而没有任何教程在最后真正开启了防火墙。&lt;/p&gt;

&lt;p&gt;因为没有防火墙，其实也发生过几次安全事故：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;某天某台服务器 CPU 利用率很高，后来发现是因为被人利用 rundeck 的漏洞植入了一个挖矿程序；&lt;/li&gt;
&lt;li&gt;某天有个跑在 Docker 里的 Redis 出现故障，经查也是被植入了挖矿程序&lt;/li&gt;
&lt;li&gt;某天发现有台机器上有个废弃的 MySQL 跑在公网上，日志里面几乎全是尝试登录的记录&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这几次事故虽然没有导致财产损失，但是公网太可怕，没有防火墙就是在外面裸奔，随时可能受到攻击。Hadoop 集群所有服务都是绑定到 &lt;code&gt;0.0.0.0&lt;/code&gt;，加上没有开启认证，很容易被拖库。&lt;/p&gt;

&lt;h2 id=&#34;firewalld&#34;&gt;FirewallD&lt;/h2&gt;

&lt;p&gt;最先想到的是用 iptables，之前也有使用经历，然而这玩意儿实在太复杂，概念、规则太多，一直没弄懂。CentOS 7 默认安装了 &lt;a href=&#34;http://www.firewalld.org/&#34;&gt;FirewallD&lt;/a&gt;，使用起来非常方便，也很好理解。网上的介绍和教程很多，不赘述。直接介绍我的使用策略。&lt;/p&gt;

&lt;p&gt;FirewallD 有很多种 zone policy，直接使用默认的 &lt;code&gt;public&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;首先内网之间必须能相互访问，否则各种集群的节点之间无法通信，会导致集群无法使用。我们有两套内网环境，一个是机房服务器之间，IP 网段是 &lt;code&gt;172.16.24.0/24&lt;/code&gt;；另一个是本地和服务器之间，通过 openvpn 连接，有两个 IP 段 &lt;code&gt;10.8.0.0/24&lt;/code&gt; 和 &lt;code&gt;10.8.1.0/24&lt;/code&gt;. 参考 &lt;a href=&#34;http://xuxping.com/2017/04/04/hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/&#34;&gt;这篇文章&lt;/a&gt;进行配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=172.16.24.0/24 accept&#39;
sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=10.8.0.0/24 accept&#39;
sudo firewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 source address=10.8.1.0/24 accept&#39;
sudo firewall-cmd  --reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其次常用服务、端口也需要开启：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --permanent --add-service=openvpn

sudo firewall-cmd --permanent --add-port=5000
sudo firewall-cmd --permanent --add-port=8080
sudo firewall-cmd --permanent --add-port=8088
sudo firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置完成之后可以查看 &lt;code&gt;/etc/firewalld/zones/public.xml&lt;/code&gt; 文件进一步确认开启的 service、source 和 port. 挑个端口用 &lt;code&gt;telnet&lt;/code&gt; 测试：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; telnet &amp;lt;public-ip&amp;gt; 21050

Trying &amp;lt;public-ip&amp;gt;...
telnet: connect to address &amp;lt;public-ip&amp;gt;: Connection refused
telnet: Unable to connect to remote host

&amp;gt; telnet 172.16.24.123 21050

Trying 172.16.24.123...
Connected to 172.16.24.123.
Escape character is &#39;^]&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;firewalld-docker&#34;&gt;FirewallD &amp;amp; Docker&lt;/h2&gt;

&lt;p&gt;如果先运行 &lt;code&gt;dockerd&lt;/code&gt; 再运行 &lt;code&gt;firewalld&lt;/code&gt;, 会导致 Docker 无法正常工作，用 Docker 部署的程序无法访问了。这个问题在网上有很多讨论，Docker 的 GitHub 主页就有&lt;a href=&#34;https://github.com/moby/moby/issues/16137&#34;&gt;一个 issue&lt;/a&gt;.
我是这么解决的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo firewall-cmd --permanent --zone=trusted --change-interface=docker0
sudo firewall-cmd --reload
sudo service docker restard
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是把 &lt;code&gt;docker0&lt;/code&gt; 网卡添加到 &lt;code&gt;trusted&lt;/code&gt; zone，再重启 &lt;code&gt;dockerd&lt;/code&gt;. 操作完成后 Docker 服务恢复正常，但是 &lt;code&gt;firewalld&lt;/code&gt; 进程却意外退出了，大量这种日志：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -n -L DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -n -L DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -n -L DOCKER-ISOLATION&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C DOCKER-ISOLATION -j RETURN&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C POSTROUTING -m addrtype --src-type LOCAL -o docker0 -j MASQUERADE&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -D FORWARD -i docker0 -o docker0 -j DROP&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -i docker0 -o docker0 -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -i docker0 ! -o docker0 -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C PREROUTING -m addrtype --dst-type LOCAL -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t nat -C OUTPUT -m addrtype --dst-type LOCAL -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -o docker0 -j DOCKER&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -t filter -C FORWARD -j DOCKER-ISOLATION&#39; failed: iptables: No chain/target/match by that name.
ERROR: COMMAND_FAILED: &#39;/sbin/iptables -w2 -D FORWARD -i docker0 -o docker0 -j DROP&#39; failed: iptables: Bad rule (does a matching rule exist in that chain?).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参照 &lt;a href=&#34;https://github.com/moby/moby/issues/16137#issuecomment-271615192&#34;&gt;这个&lt;/a&gt; 和 &lt;a href=&#34;https://stackoverflow.com/questions/33600154/docker-not-starting-could-not-delete-the-default-bridge-network-network-bridg/33604859#33604859&#34;&gt;这个&lt;/a&gt; 做法均无法消除这种错误日志，但是配置的防火墙规则都生效了。&lt;/p&gt;

&lt;h2 id=&#34;ansible-role&#34;&gt;Ansible Role&lt;/h2&gt;

&lt;p&gt;把以上配置写成 Ansible 任务进行自动化：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;---

- name: stop iptables and disable iptables on boot
  service: name=iptables state=stopped enabled=no
  ignore_errors: true

- name: ensure firewalld installed
  yum: name=firewalld state=present

- name: enable firewalld
  service: name=firewalld state=started enabled=yes

- name: set public as default zone policy
  command: firewall-cmd --set-default-zone=public

- name: ensure private network is not blocked
  firewalld:
    rich_rule: &#39;rule family=ipv4 source address={{ item }} accept&#39;
    permanent: true
    state: enabled
  with_items:
      - 172.16.24.0/24
      - 10.8.0.0/24
      - 10.8.1.0/24

- name: enable common services
  firewalld:
    service: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - http
    - https
    - ssh
    - ntp
    - openvpn

- name: enable ports
  firewalld:
    port: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - 58890/tcp
    - 58880/tcp
    - 5000/tcp
    - 8080/tcp
    - 8088/tcp
    - 8888/tcp

- name: enable docker interface
  firewalld:
    zone: trusted
    interface: docker0
    permanent: true
    state: enabled

- name: enable docker ports
  firewalld:
    port: &#39;{{ item }}&#39;
    permanent: true
    state: enabled
  with_items:
    - 4243/tcp

# 有些机器可能没有运行 dockerd，简单的通过 ignore_errors 来跳过
- name: restart docker daemon
  service: name=docker state=restarted
  ignore_errors: true

- name: reload firewalld
  service: name=firewalld state=reloaded

# 有时候会出现 firewalld 进程意外退出的情况，具体原因待查
- name: enable firewalld
  service: name=firewalld state=started enabled=yes
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.firewalld.org/&#34;&gt;FirewallD 官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-firewalld-on-centos-7&#34;&gt;DigitalOcean: How To Set Up a Firewall Using FirewallD on CentOS 7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linode.com/docs/security/firewalls/introduction-to-firewalld-on-centos/&#34;&gt;Linode: Introduction to FirewallD on CentOS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/moby/moby/issues/16137&#34;&gt;GitHub: Docker vs. firewalld on CentOS 7 #16137&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/ansible/latest/modules/firewalld_module.html&#34;&gt;Ansible firewalld&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Redshift Snippets</title>
      <link>http://liyangliang.me/posts/2018/02/redshift-snippets/</link>
      <pubDate>Sun, 04 Feb 2018 19:36:03 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2018/02/redshift-snippets/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;查询所有 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM stv_sessions;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;终止 session&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT pg_terminate_backend(32281);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即，调用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 函数，传入 process_id。&lt;/p&gt;

&lt;p&gt;权限：普通用户只能终止自己的 session，超级用户能终止任意 session.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查询正在运行的 queries&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类似 MySQL 的 &lt;code&gt;SHOW PROCESSLIST&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT stv_recents.userid, stv_recents.status, stv_recents.starttime,
       stv_recents.duration, stv_recents.user_name, stv_recents.db_name,
       stv_recents.query, stv_recents.pid
FROM stv_recents
WHERE stv_recents.status = &#39;Running&#39;::bpchar;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;创建数据库时报错：&lt;code&gt;source database &amp;quot;template1&amp;quot; is being accessed by other users&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：&lt;code&gt;template1&lt;/code&gt; 数据库被其他 session 占用，锁住了。&lt;/p&gt;

&lt;p&gt;解决方法：先从 &lt;code&gt;stv_sessions&lt;/code&gt; 表查找 &lt;code&gt;template1&lt;/code&gt; 相关的 session，然后用 &lt;code&gt;pg_terminate_backend&lt;/code&gt; 杀掉。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;备份数据到 S3&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UNLOAD (&#39;SELECT * FROM public.category&#39;) TO &#39;s3://redshift-backup/unload/public/category/category_&#39;
access_key_id &#39;&amp;lt;access_key_id&amp;gt;&#39; secret_access_key &#39;&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; ADDQUOTES ESCAPE ALLOWOVERWRITE;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;从 S3 加载数据&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY public.category FROM &#39;s3://redshift-backup/unload/public/category&#39;
CREDENTIALS &#39;aws_access_key_id=&amp;lt;access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;secret_access_key&amp;gt;&#39;
DELIMITER &#39;|&#39; REMOVEQUOTES ESCAPE REGION &#39;cn-north-1&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;定义 Python UDF&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文档: &lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;&lt;a href=&#34;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&#34;&gt;http://docs.aws.amazon.com/redshift/latest/dg/udf-python-language-support.html&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE FUNCTION f_hash(value varchar) returns varchar immutable as $$
    def sha256_hash(value):
        import hashlib, base64
        return base64.urlsafe_b64encode(hashlib.sha256(value or &#39;&#39;).digest())
    return sha256_hash(value)
$$ language plpythonu;

SELECT address, mobile_no, f_hash(address), f_hash(mobile_no)
FROM leqi_orders LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;查看表所占磁盘等信息&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT BTRIM(pgdb.datname::character varying::text) AS &amp;quot;database&amp;quot;,
       BTRIM(a.name::character varying::text) AS &amp;quot;table&amp;quot;,
       (b.mbytes::numeric::numeric(18,0) / part.total::numeric::numeric(18,0) * 100::numeric::numeric(18,0))::numeric(5,2) AS pct_of_total,
       a.&amp;quot;rows&amp;quot;,
       b.mbytes,
       b.unsorted_mbytes
FROM stv_tbl_perm a
  JOIN pg_database pgdb ON pgdb.oid = a.db_id::oid
  JOIN (
    SELECT stv_blocklist.tbl,
           SUM(
             CASE
               WHEN stv_blocklist.unsorted = 1 OR stv_blocklist.unsorted IS NULL AND 1 IS NULL THEN 1
               ELSE 0
             END
           ) AS unsorted_mbytes,
           COUNT(*) AS mbytes
    FROM stv_blocklist
    GROUP BY stv_blocklist.tbl
  ) b ON a.id = b.tbl
  JOIN (
    SELECT SUM(stv_partitions.capacity) AS total
    FROM stv_partitions
    WHERE stv_partitions.part_begin = 0
  ) part ON 1 = 1
WHERE a.slice = 0
ORDER BY b.mbytes DESC, a.db_id, a.name;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查询结果样例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;database  table pct_of_total  rows  mbytes  unsorted_mbytes
roma	mda_price_idx	0	50005	10	10
roma	mda_vendor	0	4	10	10
roma	mda_vendor	0	8	10	7
roma	sku_bodytype	0	9	10	7
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Pyenv 使用笔记</title>
      <link>http://liyangliang.me/posts/2017/06/pyenv-notes/</link>
      <pubDate>Tue, 20 Jun 2017 15:09:27 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/06/pyenv-notes/</guid>
      <description>&lt;p&gt;应用使用虚拟环境是每个 Python 程序员都应该要掌握的技能。
&lt;a href=&#34;https://github.com/pyenv/pyenv&#34;&gt;pyenv&lt;/a&gt; 是一个非常好用的 Python 环境管理工具。有这些主要特性：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;方便的安装、管理不同版本的 Python，而且不需要 sudo 权限，不会污染系统的 Python 版本&lt;/li&gt;
&lt;li&gt;可以修改当前用户使用的默认 Python 版本&lt;/li&gt;
&lt;li&gt;集成 virtualenv，自动安装、激活&lt;/li&gt;
&lt;li&gt;命令行自动补全&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;详细内容见 &lt;a href=&#34;https://github.com/pyenv/pyenv&#34;&gt;Github - pyenv/pyenv&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;安装-pyenv&#34;&gt;安装 pyenv&lt;/h2&gt;

&lt;p&gt;最简单的方式是使用 &lt;a href=&#34;https://github.com/pyenv/pyenv-installer&#34;&gt;pyenv-installer&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在 &lt;code&gt;~/.bashrc&lt;/code&gt; 或 &lt;code&gt;~/.zshrc&lt;/code&gt; 中添加如下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=&amp;quot;~/.pyenv/bin:$PATH&amp;quot;
eval &amp;quot;$(pyenv init -)&amp;quot;
eval &amp;quot;$(pyenv virtualenv-init -)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;常用命令&#34;&gt;常用命令&lt;/h2&gt;

&lt;p&gt;完整的命令行列表可以参考 &lt;a href=&#34;https://github.com/pyenv/pyenv/blob/master/COMMANDS.md&#34;&gt;pyenv/COMMANDS.md&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;安装 Python&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv install 3.6.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会为当前用户下载和安装 3.6.0，安装过程可以使用镜像加速，详见下文。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新建虚拟环境&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv virtualenv 3.6.0 py36
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;设置当前路径使用的 Python 环境&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;pyenv local py36
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令会在当前路径创建一个 &lt;code&gt;.python-version&lt;/code&gt; 文件，文件内容就是 &lt;code&gt;py36&lt;/code&gt;，即环境名称。所以一般需要把 &lt;code&gt;.python-version&lt;/code&gt; 添加到 gitignore.&lt;/p&gt;

&lt;p&gt;下次进入该目录时，会自动激活虚拟环境；离开后自动退出。&lt;/p&gt;

&lt;h2 id=&#34;搭建镜像&#34;&gt;搭建镜像&lt;/h2&gt;

&lt;p&gt;pyenv 默认从 Python 官网下载安装包，比较慢；也支持镜像网站，可以自己搭建。&lt;/p&gt;

&lt;h3 id=&#34;搭建镜像-1&#34;&gt;搭建镜像&lt;/h3&gt;

&lt;p&gt;其实就是把安装包下载好，放到服务器上，用 Nginx 搭建一个下载服务。但安装包的文件名必须是文件的 SHA256 值。
如 Python-3.6.0.tar.xz 安装包应该保存为 b0c5f904f685e32d9232f7bdcbece9819a892929063b6e385414ad2dd6a23622&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建目录 &lt;code&gt;/data/pythons&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;下载安装包，从 &lt;a href=&#34;http://mirrors.sohu.com/python/&#34;&gt;搜狐的开源镜像&lt;/a&gt; 下载 &lt;code&gt;.tar.xz&lt;/code&gt; 格式的安装包。&lt;/li&gt;
&lt;li&gt;计算 SHA256（可以使用 &lt;code&gt;sha256sum&lt;/code&gt; 命令），重命名文件&lt;/li&gt;
&lt;li&gt;配置 Nginx&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
    listen 8000;
    root /data/pythons;
    autoindex on;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果没有或不想使用 Nginx，也可以用 Python 运行一个简易的 HTTP 服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python3 -m http.server
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用镜像&#34;&gt;使用镜像&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;export PYTHON_BUILD_MIRROR_URL=http://localhost:8000
pyenv install 3.6.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以把 &lt;code&gt;export PYTHON_BUILD_MIRROR_URL=http://localhost:8000&lt;/code&gt; 添加到 &lt;code&gt;~/.bashrc&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;安装其他版本时，pyenv 会回退到从官网下载。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Centos 7 安装配置 Rundeck</title>
      <link>http://liyangliang.me/posts/2017/06/centos7-install-rundeck/</link>
      <pubDate>Tue, 20 Jun 2017 14:59:27 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/06/centos7-install-rundeck/</guid>
      <description>&lt;h2 id=&#34;通过-yum-安装&#34;&gt;通过 yum 安装：&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install java-1.8.0
$ sudo rpm -Uvh http://repo.rundeck.org/latest.rpm
$ sudo yum install rundeck
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果已经安装了 Java，第一步可以略过。安装过程中有几个步骤需要确认，一路同意（输入 y）即可。&lt;/p&gt;

&lt;p&gt;安装完成后可以立即运行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service rundeckd start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但生产环境还是要修改一些默认配置。上面的安装过程会添加一个名为 rundeck 的用户和组。配置文件位于 &lt;code&gt;/etc/rundeck&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo su - rundeck
$ cd /etc/rundeck/
$ ll
-rw-r-----. 1 rundeck rundeck  738 Apr 20 07:47 admin.aclpolicy
-rw-r-----. 1 rundeck rundeck 1104 Apr 20 07:47 apitoken.aclpolicy
-rw-r-----. 1 rundeck rundeck  511 Apr 20 07:47 cli-log4j.properties
-rw-r-----. 1 rundeck rundeck 1438 Jun 19 16:52 framework.properties
-rw-r-----. 1 rundeck rundeck  136 Apr 20 07:47 jaas-loginmodule.conf
-rw-r-----. 1 rundeck rundeck 7538 Apr 20 07:47 log4j.properties
-rw-r-----. 1 rundeck rundeck 2889 Apr 20 07:47 profile
-rw-r-----. 1 rundeck rundeck  549 Apr 20 07:47 project.properties
-rw-r-----. 1 rundeck rundeck 1065 Jun 20 11:54 realm.properties
-rw-r-----. 1 rundeck rundeck  579 Jun 20 11:56 rundeck-config.properties
drwxr-x---. 2 rundeck rundeck   27 Jun 19 16:52 ssl
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;修改-admin-用户密码&#34;&gt;修改 admin 用户密码&lt;/h2&gt;

&lt;p&gt;用户信息在 &lt;code&gt;realm.properities&lt;/code&gt; 文件，默认有一个 admin 用户，密码也是 admin. 配置格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;username&amp;gt;: &amp;lt;password&amp;gt;[,&amp;lt;rolename&amp;gt; ...]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;默认的配置是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin:admin,user,admin,architect,deploy,build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改密码，并使用 MD5 替换明文密码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ java -cp /var/lib/rundeck/bootstrap/jetty-all-9.0.7.v20131107.jar org.eclipse.jetty.util.security.Password admin Abcd1234
Abcd1234
OBF:1cb01ini1ink1inm1iks1iku1ikw1caa
MD5:325a2cc052914ceeb8c19016c091d2ac
CRYPT:adMpLenKdpR12
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令会生成几种算法加密后的密码，添加到 &lt;code&gt;realm.properities&lt;/code&gt; 文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admin:MD5:325a2cc052914ceeb8c19016c091d2ac,user,admin,architect,deploy,build
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;配置使用-mysql-数据库&#34;&gt;配置使用 MySQL 数据库&lt;/h2&gt;

&lt;p&gt;首先得要有个 MySQL 实例，安装过程不赘述。&lt;/p&gt;

&lt;p&gt;配置过程详见 &lt;a href=&#34;http://rundeck.org/docs/administration/setting-up-an-rdb-datasource.html&#34;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建 rundeck 用户和数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ mysql -u root -p

mysql&amp;gt; create database rundeck;
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; grant ALL on rundeck.* to &#39;rundeckuser&#39;@&#39;localhost&#39; identified by &#39;rundeckpassword&#39;;
Query OK, 1 row affected (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后可以使用 &lt;code&gt;rundeckuser&lt;/code&gt; 登录，测试是否能正常连接。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;修改 Rundeck 配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编辑 &lt;code&gt;rundeck-config.properties&lt;/code&gt; 文件，修改后的内容如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#dataSource.url = jdbc:h2:file:/var/lib/rundeck/data/rundeckdb;MVCC=true
dataSource.url = jdbc:mysql://localhost/rundeck?autoReconnect=true
dataSource.username = rundeckuser
dataSource.password = rundeckpassword
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;修改-grails-serverurl&#34;&gt;修改 &lt;code&gt;grails.serverURL&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo service rundeckd start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行 Rundeck 服务，打开 &lt;a href=&#34;http://your-server-host:4440/&#34;&gt;http://your-server-host:4440/&lt;/a&gt; 并用 admin 用户登录。登录成功后，被跳转到了 &lt;a href=&#34;http://localhost:4440/menu/home&#34;&gt;http://localhost:4440/menu/home&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;编辑 &lt;code&gt;rundeck-config.properties&lt;/code&gt; 文件，把 &lt;code&gt;grails.serverURL&lt;/code&gt; 改成正确的地址即可。&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/manual/index.html&#34;&gt;User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/administration/index.html&#34;&gt;Administrator Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://rundeck.org/docs/api/index.html&#34;&gt;API Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Flask 应用国际化</title>
      <link>http://liyangliang.me/posts/2017/05/flask-i18n/</link>
      <pubDate>Wed, 10 May 2017 17:48:17 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/flask-i18n/</guid>
      <description>&lt;h2 id=&#34;babel&#34;&gt;Babel&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Babel is an integrated collection of utilities that assist in internationalizing and localizing Python applications, with an emphasis on web-based applications.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;文档：&lt;a href=&#34;http://babel.pocoo.org/en/latest/&#34;&gt;http://babel.pocoo.org/en/latest/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码：&lt;a href=&#34;https://github.com/python-babel/babel&#34;&gt;https://github.com/python-babel/babel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;flask-babel&#34;&gt;Flask-Babel&lt;/h2&gt;

&lt;p&gt;Flask 的 i18n 扩展，集成 babel、pytz 等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文档：&lt;a href=&#34;https://pythonhosted.org/Flask-Babel/&#34;&gt;https://pythonhosted.org/Flask-Babel/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码：&lt;a href=&#34;https://github.com/python-babel/flask-babel&#34;&gt;https://github.com/python-babel/flask-babel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装：&lt;code&gt;pip install Flask-Babel&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;babel 配置文件：babel.cfg&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[python: **.py]
[jinja2: **.html]
extensions=jinja2.ext.autoescape,jinja2.ext.with_,webassets.ext.jinja2.AssetsExtension
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Flask-Babel 配置：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;BABEL_DEFAULT_LOCALE = &#39;zh_CN’                  # locale 选项，默认 &#39;en&#39;
BABEL_DEFAULT_TIMEZONE = &#39;Asia/Shanghai&#39;        # 时区，默认 &#39;UTC&#39;
BABEL_TRANSLATION_DIRECTORIES = &#39;translations&#39;  # 翻译文件所在目录，默认 &#39;translations&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;生成翻译文件模版：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -o messages.pot .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果使用了 &lt;code&gt;lazy_gettext()&lt;/code&gt; 这样的函数，需要在上面的命令行参数指定：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -k lazy_gettext -o messages.pot .
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;生成翻译文件:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel init -i messages.pot -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;编辑 translations/zh_CN/LC_MESSAGES/messages.po 文件，手动翻译。po 文件内容形如：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#: forms.py:65 forms.py:78
#: templates/flask_user/emails/invite_child_user_message.html:9
msgid &amp;quot;Username&amp;quot;
msgstr &amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中：
  - &lt;code&gt;#:&lt;/code&gt; 注释内容是 ‘文件名:行号’，即所有出现过的地方
  - &lt;code&gt;msgid&lt;/code&gt; 是需要翻译的内容
  - &lt;code&gt;msgstr&lt;/code&gt; 是翻译后的内容，如果留空，则会显示原文，即 msgid&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更新翻译文件（一般只需要 init 一次）：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel update -i messages.pot -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;编译&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel compile -d translations
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;工作流&#34;&gt;工作流&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ pybabel extract -F babel.cfg -o messages.pot .
$ pybabel init -i messages.pot -d translations     # 第一次
$ pybabel update -i messages.pot -d translations   # 更新
# 手动翻译
$ pybabel compile -d translations
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>EC2 挂载 EBS</title>
      <link>http://liyangliang.me/posts/2017/05/mount-ebs-to-ec2/</link>
      <pubDate>Wed, 10 May 2017 17:41:54 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/mount-ebs-to-ec2/</guid>
      <description>&lt;p&gt;创建 EC2 实例的时候可以选择添加 EBS 卷，在实例运行后，需要手动挂载上去。&lt;/p&gt;

&lt;p&gt;详情见 &lt;a href=&#34;http://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ebs-using-volumes.html&#34;&gt;EBS 的文档&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;用-lsblk-命令查看所有可用的磁盘及其安装点&#34;&gt;用 &lt;code&gt;lsblk&lt;/code&gt; 命令查看所有可用的磁盘及其安装点&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
`-xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  30G  0 disk
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;xvda1&lt;/code&gt; 是根设备，挂载到了 &lt;code&gt;/&lt;/code&gt;；&lt;code&gt;xvdb&lt;/code&gt; 是刚才添加的 EBS 卷，还没有挂载。&lt;/p&gt;

&lt;h2 id=&#34;确定是否需要在卷上创建文件系统&#34;&gt;确定是否需要在卷上创建文件系统。&lt;/h2&gt;

&lt;p&gt;如果是新的 EBS，是一个原始的块存储设备，需要先创建文件系统才能安装使用。从快照还原的卷可能已经含有文件系统。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo file -s /dev/xvdb
/dev/xvdb: data

$ sudo file -s /dev/xvda1
/dev/xvda1: Linux rev 1.0 ext4 filesystem data, UUID=9fbb7c51-0409-4b50-ad40-068dcfe4bc89, volume name &amp;quot;cloudimg-rootfs&amp;quot; (needs journal recovery) (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到 &lt;code&gt;/dev/xvdb&lt;/code&gt; 上面还没有文件系统，需要手动创建:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkfs -t ext4 /dev/xvdb
mke2fs 1.42.13 (17-May-2015)
Creating filesystem with 7864320 4k blocks and 1966080 inodes
Filesystem UUID: 2a0dae23-7b6e-42ec-95e1-df58f29520a4
Superblock backups stored on blocks:
     32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
     4096000

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

$ sudo file -s /dev/xvdb
/dev/xvdb: Linux rev 1.0 ext4 filesystem data, UUID=2a0dae23-7b6e-42ec-95e1-df58f29520a4 (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意：&lt;code&gt;mkfs&lt;/code&gt; 会格式化卷，删除所有数据。&lt;/p&gt;

&lt;h2 id=&#34;创建安装点-也就是要挂载的位置&#34;&gt;创建安装点，也就是要挂载的位置:&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir /data
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;挂载&#34;&gt;挂载&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sudo mount /dev/xvdb /data/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;用-df-命令磁盘空间&#34;&gt;用 &lt;code&gt;df&lt;/code&gt; 命令磁盘空间&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            489M     0  489M   0% /dev
tmpfs           100M  3.1M   97M   4% /run
/dev/xvda1      7.8G  1.9G  5.5G  26% /
tmpfs           496M     0  496M   0% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           496M     0  496M   0% /sys/fs/cgroup
tmpfs           100M     0  100M   0% /run/user/1000
/dev/xvdb        30G   44M   28G   1% /data
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>MySQL 数据导入到 Redshift</title>
      <link>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift/</link>
      <pubDate>Wed, 10 May 2017 17:36:29 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/transfer-data-from-mysql-to-redshift/</guid>
      <description>&lt;h2 id=&#34;设计表&#34;&gt;设计表&lt;/h2&gt;

&lt;p&gt;首先是设计表结构。建表语法差别不大，有一些地方可以注意一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Redshift 貌似没有无符号类型，所以要把 unsigned 类型的字段修改成相应的 INT 或 BIGINT 类型。&lt;/li&gt;
&lt;li&gt;FLOAT 类型改成 REAL 或 FLOAT4&lt;/li&gt;
&lt;li&gt;把索引语句去掉，保留主键、外键、唯一性约束，Redshift 不会检查这些约束，但是查询时会用于优化。&lt;/li&gt;
&lt;li&gt;Redshift 的 CHAR 类型只能包含单字节 ASCII 字符，对于非 ASCII 数据需要把 CHAR 改成 VARCHAR 类型&lt;/li&gt;
&lt;li&gt;有可能 MySQL 中存的是 unicode，而 Redshift 中存的是 bytes，所以 VARCHAR 的长度也要调整，避免溢出。最简单的，可以用 MySQL 的字段长度 * 3.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于 sort key, dist key 等设计，只属于 Redshift 范畴，参考官网文档即可。&lt;/p&gt;

&lt;h2 id=&#34;加载数据&#34;&gt;加载数据&lt;/h2&gt;

&lt;p&gt;因为 Redshift 推荐使用 &lt;code&gt;COPY&lt;/code&gt; 命令从 S3 加载数据，所以首先得要从 MySQL 中导出数据，然后上传到 CSV.&lt;/p&gt;

&lt;p&gt;以导出 CSV 为例，需要注意使用 &lt;code&gt;&amp;quot;&lt;/code&gt; 符号作为转义字符，而不是 &lt;code&gt;\&lt;/code&gt;. 另外最好用 &lt;code&gt;&amp;quot;&lt;/code&gt; 把每个值都 wrap 起来，免得有些多行字符串导致出错。导出后可以压缩成 gzip 格式，在上传 S3 的时候可以快一些。&lt;/p&gt;

&lt;p&gt;Redshift 的 &lt;code&gt;COPY&lt;/code&gt; 例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY syns_bigdata
FROM &#39;s3://some-bucket/some_filename.csv.gz&#39;
credentials &#39;aws_access_key_id=&amp;lt;aws_access_key_id&amp;gt;;aws_secret_access_key=&amp;lt;aws_secret_access_key&amp;gt;&#39;
region &#39;cn-north-1&#39; CSV GZIP NULL AS &#39;NULL&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;语法很简单，需要注意的有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;aws_access_key_id&lt;/code&gt; 和 &lt;code&gt;aws_secret_access_key&lt;/code&gt; 要有访问 S3 的权限&lt;/li&gt;
&lt;li&gt;指定 region&lt;/li&gt;
&lt;li&gt;指定文件格式，&lt;code&gt;CSV GZIP&lt;/code&gt; 表示是 gzip 压缩的 CSV 文件&lt;/li&gt;
&lt;li&gt;可以用 &lt;code&gt;NULL AS&lt;/code&gt; 语句指定 NULL 值&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>在 AWS 上安装 Tableau Server</title>
      <link>http://liyangliang.me/posts/2017/05/install-tableau-server-on-aws-ec2/</link>
      <pubDate>Wed, 10 May 2017 17:23:55 CST</pubDate>
      <author>Yangliang Li</author>
      <guid>http://liyangliang.me/posts/2017/05/install-tableau-server-on-aws-ec2/</guid>
      <description>&lt;h2 id=&#34;启动-ec2-实例&#34;&gt;启动 EC2 实例&lt;/h2&gt;

&lt;p&gt;先根据 Tableau Server 的使用情况确定需要的配置，从而确定实例类型。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AMI: Microsoft Windows Server 2012 R2 Base（简体中文）&lt;/li&gt;
&lt;li&gt;类型: m4.4xlarge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动、配置步骤略去不表，有两点需要注意：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VPC 需要开启 3389 端口用于远程登录（RDP）&lt;/li&gt;
&lt;li&gt;密钥对会用于解密登录密码&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安装-tableau-server&#34;&gt;安装 Tableau Server&lt;/h2&gt;

&lt;p&gt;从 Tableau 官网下载然后安装，配置、激活过程比较简单，略去不表。&lt;/p&gt;

&lt;h2 id=&#34;可选-安装-mysql-驱动&#34;&gt;（可选）安装 MySQL 驱动&lt;/h2&gt;

&lt;p&gt;在 &lt;a href=&#34;https://www.tableau.com/zh-cn/support/drivers&#34;&gt;这个页面&lt;/a&gt;可以找到所有数据源需要的驱动程序.&lt;/p&gt;

&lt;p&gt;下载好驱动程序，如 mysql-connector-odbc-5.3.7-winx64.msi，双击安装，提示错误。搜索了一番，应该是缺少 Visual C++ 的运行库。试过 Visual C++ Redistributable for Visual Studio 2012 Update 4 和 Visual C++ Redistributable Packages for Visual Studio 2013，最后发现后者才有用。&lt;/p&gt;

&lt;p&gt;安装完 &lt;a href=&#34;https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=40784&#34;&gt;Visual C++ Redistributable Packages for Visual Studio 2013&lt;/a&gt; 之后，可以成功安装mysql-connector-odbc-5.3.7-winx64.msi 。&lt;/p&gt;

&lt;h2 id=&#34;安装-aws-命令行程序&#34;&gt;安装 AWS 命令行程序&lt;/h2&gt;

&lt;p&gt;从这里下载：&lt;a href=&#34;https://s3.amazonaws.com/aws-cli/AWSCLI64.msi&#34;&gt;https://s3.amazonaws.com/aws-cli/AWSCLI64.msi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装完后打开 cmd，运行 &lt;code&gt;aws configure&lt;/code&gt; 进行配置，要有上传 S3 的权限。完成后可以运行 &lt;code&gt;aws s3 ls&lt;/code&gt; 验证。&lt;/p&gt;

&lt;h2 id=&#34;编写备份脚本&#34;&gt;编写备份脚本&lt;/h2&gt;

&lt;p&gt;自动备份并且把备份文件上传到 S3。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@echo OFF
set Binpath=&amp;quot;C:\Program Files\Tableau\Tableau Server\10.2\bin&amp;quot;
set Backuppath=&amp;quot;C:\Backups\Tablea Server\nightly&amp;quot;
echo %date% %time%: *** Housekeeping started ***

rmdir %Backuppath% /S /Q

%Binpath%\tabadmin backup %Backuppath%\ts_backup -d --no-config
timeout 5

%Binpath%\tabadmin cleanup

echo %date% %time%: Uploading to S3

aws s3 cp %Backuppath% s3://tableau-server-backup/ --recursive --exclude &amp;quot;*&amp;quot; --include &amp;quot;ts_backup-*.tsbak&amp;quot;

echo %date% %time%: *** Housekeeping completed ***
timeout 5
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;从备份恢复&#34;&gt;从备份恢复&lt;/h2&gt;

&lt;p&gt;如果是从其他的 Tableau Server 迁移过来，可以使用备份文件迁移数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Users\Administrator&amp;gt;&amp;quot;C:\Program Files\Tableau\Tableau Server\10.2\bin\tabadmi
n.bat&amp;quot; restore --no-config Downloads\ts_backup-2017-04-05.tsbak
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;restore 操作会关闭 Tableau Server，恢复完成后需要手动开启。&lt;/p&gt;

&lt;h2 id=&#34;自动备份&#34;&gt;自动备份&lt;/h2&gt;

&lt;p&gt;使用 Task Scheduler 实现，详情见官方文档：&lt;a href=&#34;http://technet.microsoft.com/en-us/library/cc766428.aspx&#34;&gt;http://technet.microsoft.com/en-us/library/cc766428.aspx&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
